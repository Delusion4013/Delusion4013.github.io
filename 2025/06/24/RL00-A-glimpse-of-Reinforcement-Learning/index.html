<!DOCTYPE html>
<html lang="en,zh-CN,default" data-theme="auto">
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0">

  

  <title>RL00 - A glimpse of Reinforcement Learning | Chenkai&#39;s Blog</title>

  <!-- Meta Description -->
  
    <meta name="description" content="This post summarizes reinforcement learning from classic tabular
methods to ML-based approximations and recent LLM applications like
RLHF.">
  

  <!-- Keywords -->
  
    <meta name="keywords" content="Data Science, Reinforcement Learning">
  

  <!-- Author -->
  <meta name="author" content="Chenkai">

  <!-- Canonical URL -->
  
    <link rel="canonical" href="https://delusion4013.github.io/2025/06/24/RL00-A-glimpse-of-Reinforcement-Learning/">
  

  <!-- Favicon -->
  
    <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
    <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
    <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
  

  <!-- Theme Color -->
  <meta name="theme-color" content="#ffffff" media="(prefers-color-scheme: light)">
  <meta name="theme-color" content="#1a1a1a" media="(prefers-color-scheme: dark)">

  <!-- Open Graph -->
  
    

<meta property="og:type" content="article">
<meta property="og:title" content="RL00 - A glimpse of Reinforcement Learning">
<meta property="og:url" content="https://delusion4013.github.io/2025/06/24/RL00-A-glimpse-of-Reinforcement-Learning/">

  <meta property="og:description" content="This post summarizes reinforcement learning from classic tabular
methods to ML-based approximations and recent LLM applications like
RLHF.">


<meta property="og:site_name" content="Chenkai&#39;s Blog">
<meta property="og:locale" content="en">


  <meta property="article:published_time" content="2025-06-24T00:42:24.000Z">
  
    <meta property="article:modified_time" content="2025-12-18T11:46:46.593Z">
  
  <meta property="article:author" content="Chenkai">

  
    
      <meta property="article:tag" content="Data Science">
    
      <meta property="article:tag" content="Reinforcement Learning">
    
  

  
    
      <meta property="article:section" content="Notes">
    
  


  

  <!-- Twitter Card -->
  
    

<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:title" content="RL00 - A glimpse of Reinforcement Learning">

  <meta name="twitter:description" content="This post summarizes reinforcement learning from classic tabular
methods to ML-based approximations and recent LLM applications like
RLHF.">




  

  <!-- Schema.org -->
  
    


<script type="application/ld+json">
[{"@context":"https://schema.org","@type":"BlogPosting","headline":"RL00 - A glimpse of Reinforcement Learning","description":"This post summarizes reinforcement learning from classic tabular\nmethods to ML-based approximations and recent LLM applications like\nRLHF.","url":"https://delusion4013.github.io/2025/06/24/RL00-A-glimpse-of-Reinforcement-Learning/","datePublished":"2025-06-24T00:42:24.000Z","dateModified":"2025-12-18T11:46:46.593Z","author":{"@type":"Person","name":"Chenkai"},"publisher":{"@type":"Organization","name":"Chenkai's Blog","logo":{"@type":"ImageObject","url":"https://delusion4013.github.io/img/my-favicon-32x32.png"}},"mainEntityOfPage":{"@type":"WebPage","@id":"https://delusion4013.github.io/2025/06/24/RL00-A-glimpse-of-Reinforcement-Learning/"},"keywords":"Data Science, Reinforcement Learning","wordCount":1250,"articleSection":["Notes"]},{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Home","item":"https://delusion4013.github.io"},{"@type":"ListItem","position":2,"name":"Notes","item":"https://delusion4013.github.io/categories/Notes/"},{"@type":"ListItem","position":3,"name":"RL00 - A glimpse of Reinforcement Learning","item":"https://delusion4013.github.io/2025/06/24/RL00-A-glimpse-of-Reinforcement-Learning/"}]}]
</script>


  

  <!-- RSS Feed -->
  
    <link rel="alternate" type="application/rss+xml" title="Chenkai&#39;s Blog" href="/atom.xml">
  

  <!-- CSS -->
  <link rel="stylesheet" href="/css/main.9a7d283b.css">

  <!-- Syntax Highlighting -->
  <link rel="stylesheet" href="/css/highlight.css">

  <!-- Custom CSS -->
  <link rel="stylesheet" href="/css/custom.css">

  <!-- Prevent FOUC - Inline theme toggle script -->
  <script>
    (function() {
      const storageKey = 'papermod-theme';
      const defaultTheme = 'auto';

      function getSystemTheme() {
        return window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';
      }

      function getSavedTheme() {
        try {
          return localStorage.getItem(storageKey);
        } catch (e) {
          return null;
        }
      }

      function setTheme(theme) {
        if (theme === 'auto') {
          theme = getSystemTheme();
        }
        document.documentElement.setAttribute('data-theme', theme);
      }

      // Apply theme immediately
      const savedTheme = getSavedTheme();
      const initialTheme = savedTheme || defaultTheme;
      setTheme(initialTheme);
    })();
  </script>

  <!-- Preload fonts (optional - add your font files here) -->
  <!-- <link rel="preload" href="/fonts/your-font.woff2" as="font" type="font/woff2" crossorigin> -->
<meta name="generator" content="Hexo 5.4.2"></head>

<body>
  <header class="header">
  <nav class="nav">
    <div class="logo">
      <a href="/" accesskey="h" title="Chenkai&#39;s Blog (Alt + H)">
        
          <img src="/img/my-favicon-32x32.png" alt="Chenkai&#39;s Blog" class="logo-image">
        
        <span class="logo-text">Chenkai&#39;s Blog</span>
      </a>
    </div>

    
      <ul class="menu" id="menu">
        
          
          <li>
            <a href="/"  title="Home">
              <span>Home</span>
            </a>
          </li>
        
          
          <li>
            <a href="/archives"  title="Archives">
              <span>Archives</span>
            </a>
          </li>
        
          
          <li>
            <a href="/tags"  title="Tags">
              <span>Tags</span>
            </a>
          </li>
        
          
          <li>
            <a href="/categories"  title="Categories">
              <span>Categories</span>
            </a>
          </li>
        
          
          <li>
            <a href="/about"  title="About">
              <span>About</span>
            </a>
          </li>
        
      </ul>
    

    <div class="nav-actions">
      
        <button class="search-button" id="search-button" title="Search (Alt + /)">
          <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
            <circle cx="11" cy="11" r="8"></circle>
            <path d="m21 21-4.35-4.35"></path>
          </svg>
        </button>
      

      
        <button class="theme-toggle" id="themeToggle" title="Toggle theme (Alt + T)">
          <svg class="moon" xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
            <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
          </svg>
          <svg class="sun" xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
            <circle cx="12" cy="12" r="5"></circle>
            <line x1="12" y1="1" x2="12" y2="3"></line>
            <line x1="12" y1="21" x2="12" y2="23"></line>
            <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
            <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
            <line x1="1" y1="12" x2="3" y2="12"></line>
            <line x1="21" y1="12" x2="23" y2="12"></line>
            <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
            <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
          </svg>
        </button>
      

      <button class="menu-toggle" id="menuToggle" title="Menu">
        <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
          <line x1="3" y1="12" x2="21" y2="12"></line>
          <line x1="3" y1="6" x2="21" y2="6"></line>
          <line x1="3" y1="18" x2="21" y2="18"></line>
        </svg>
      </button>
    </div>
  </nav>
</header>


  <main class="main">
    


  <article class="post-single">
    
      <nav class="breadcrumbs" aria-label="breadcrumb">
  <ol>
    <li>
      <a href="/">
        <svg class="icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
          <path d="M3 9l9-7 9 7v11a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2z"></path>
          <polyline points="9 22 9 12 15 12 15 22"></polyline>
        </svg>
        Home
      </a>
    </li>

    
      
        <li>
          <span class="separator">/</span>
          <a href="/categories/Notes/">Notes</a>
        </li>
      
    

    <li>
      <span class="separator">/</span>
      <span class="current">RL00 - A glimpse of Reinforcement Learning</span>
    </li>
  </ol>
</nav>

    

    

    

    <header class="post-header">
      <h1 class="post-title">RL00 - A glimpse of Reinforcement Learning</h1>
      <div class="post-meta">
  
    <span class="post-meta-item">
      <svg class="icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
        <rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect>
        <line x1="16" y1="2" x2="16" y2="6"></line>
        <line x1="8" y1="2" x2="8" y2="6"></line>
        <line x1="3" y1="10" x2="21" y2="10"></line>
      </svg>
      <time datetime="2025-06-24T00:42:24.000Z">
        2025-06-24
      </time>
    </span>
  

  

  
    
    <span class="post-meta-item">
      <svg class="icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
        <circle cx="12" cy="12" r="10"></circle>
        <polyline points="12 6 12 12 16 14"></polyline>
      </svg>
      <span>33 min read</span>
    </span>
  

  

  
    <span class="post-meta-item">
      <svg class="icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
        <path d="M20 21v-2a4 4 0 0 0-4-4H8a4 4 0 0 0-4 4v2"></path>
        <circle cx="12" cy="7" r="4"></circle>
      </svg>
      <span>Chenkai</span>
    </span>
  

  
    <span class="post-meta-item post-categories">
      <svg class="icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
        <path d="M22 19a2 2 0 0 1-2 2H4a2 2 0 0 1-2-2V5a2 2 0 0 1 2-2h5l2 3h9a2 2 0 0 1 2 2z"></path>
      </svg>
      
        <a href="/categories/Notes/" class="category-link">Notes</a>
      
    </span>
  
</div>

    </header>

    
      


  <aside class="toc-container"
         role="navigation"
         aria-label="Table of Contents">
    <div class="toc-header">
      <button class="toc-toggle"
              aria-label="Toggle table of contents"
              aria-expanded="false"
              aria-controls="toc-content">
        <svg class="icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" aria-hidden="true">
          <line x1="8" y1="6" x2="21" y2="6"></line>
          <line x1="8" y1="12" x2="21" y2="12"></line>
          <line x1="8" y1="18" x2="21" y2="18"></line>
          <line x1="3" y1="6" x2="3.01" y2="6"></line>
          <line x1="3" y1="12" x2="3.01" y2="12"></line>
          <line x1="3" y1="18" x2="3.01" y2="18"></line>
        </svg>
        <span>Table of Contents</span>
      </button>
    </div>
    <nav class="toc-content" id="toc-content">
      <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#general-definition-and-applications"><span class="toc-text">General definition and
applications</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#intuition-definition"><span class="toc-text">Intuition &amp; Definition</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#components"><span class="toc-text">Components</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#applications"><span class="toc-text">Applications</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#from-tabular-methods-to-approximated-methods"><span class="toc-text">From Tabular
methods to Approximated methods</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#tabular-solution-methods"><span class="toc-text">Tabular solution Methods</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#approximate-solution-method"><span class="toc-text">Approximate solution method</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#rl-nowadays"><span class="toc-text">RL nowadays</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#rl-with-deep-learning"><span class="toc-text">RL with Deep Learning</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#rl-with-large-language-models"><span class="toc-text">RL with Large Language
Models</span></a></li></ol></li></ol>
    </nav>
  </aside>


    

    <div class="post-content">
      <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><p>This post summarizes reinforcement learning from classic tabular
methods to ML-based approximations and recent LLM applications like
RLHF.</p>
<span id="more"></span>
<h2 id="general-definition-and-applications">General definition and
applications</h2>
<h3 id="intuition-definition">Intuition &amp; Definition</h3>
<p>If you were asked, <em>“How did you learn to ride a bike or solve a
math problem?”</em>, your answer would likely involve
<strong>interaction</strong>. When learning to ride a bike, for
instance, you probably didn’t follow a step-by-step guide detailing
exact body movements. Instead, you engaged directly with the
environment—the bike, the road, your own balance—learning through trial
and error: falling, adjusting, and gradually figuring out what works.
This kind of learning—driven by feedback from experience—is at the heart
of reinforcement learning.</p>
<p>In more formal terms, <strong>reinforcement learning (RL)</strong> is
learning what to do - how to map situations to actions - so as to
maximize a numerical reward signal. The learner is not told which
actions to take, but instead must discover which actions yield the most
reward by trying them. This separates RL from supervised learning and
unsupervised learning. a third paradigm</p>
<p>Reinforcement Learning (RL) differs from supervised learning (SL) in
<strong>learning method</strong>: SL learns from a fixed dataset of
labeled examples, where each input has a known correct output provided
by an external supervisor. In contrast, RL learns through
<strong>interaction with the environment</strong>, receiving feedback in
the form of rewards rather than explicit labels, and improving behavior
via trial and error. RL also differs from unsupervised learning (USL) in
<strong>learning objective</strong>: USL seeks to discover hidden
patterns or structures in unlabeled data (e.g., clustering or
dimensionality reduction), whereas RL aims to <strong>optimize a policy
that maximizes cumulative rewards</strong>.</p>
<h3 id="components">Components</h3>
<p>Reinforcement learning (RL) is structured around two central
entities: the <strong>agent</strong> and the
<strong>environment</strong>, connected through a feedback loop
illustrated in the diagram <img
src="https://s2.loli.net/2025/06/24/SDBTILyEKAV5UFb.png"
alt="basic-rl-loop" /> At each timestep <span
class="math inline">\(t\)</span>, the agent receives an observation
<span class="math inline">\(o_t\)</span> from the environment, takes an
action <span class="math inline">\(a_t\)</span>, and subsequently
receives a reward <span class="math inline">\(r_{t+1}\)</span>. The
environment, in turn, processes the action, updates its state, and emits
the next observation <span class="math inline">\(o_{t+1}\)</span> along
with the reward signal <span class="math inline">\(r_{t+1}\)</span>.</p>
<p>Beyond this basic interaction loop, an RL learning system comprises
several core components:</p>
<ul>
<li>a <strong>policy</strong> <span class="math inline">\(\pi\)</span>,
which maps states to actions and defines the agent's behavior;</li>
<li>a <strong>reward signal</strong>, which evaluates the immediate
desirability of actions taken;</li>
<li>a <strong>value function</strong>, which estimates the expected
cumulative reward and thus guides long-term decision-making;</li>
<li>optionally, a <strong>model of the environment</strong>, which
allows the agent to simulate and plan by predicting future states and
rewards.</li>
</ul>
<p>Together, these elements enable the agent to learn from experience
and improve its performance over time.</p>
<h3 id="applications">Applications</h3>
<p>Reinforcement learning shines in domains that require continuous
decision-making and adaptation. In <strong>robotics</strong>, RL trains
agents to control complex systems—such as <em>robotic arms</em> grasping
objects or <em>mobile robots</em> navigating unpredictable
terrains—through trial and error. On <strong>factory floors</strong>, it
optimizes processes like <em>automated control and supply-chain
logistics</em>, improving efficiency and resilience . In
<strong>finance</strong>, RL algorithms drive <em>algorithmic trading
and portfolio management</em> by learning strategies to buy, sell, or
hold assets, maximizing risk-adjusted returns . And in
<strong>gaming</strong>, RL systems such as Deep Q-Networks and
<em>AlphaZero</em> have mastered Go, StarCraft II, and Dota 2,
demonstrating extraordinary planning and strategic reasoning.</p>
<h2 id="from-tabular-methods-to-approximated-methods">From Tabular
methods to Approximated methods</h2>
<h3 id="tabular-solution-methods">Tabular solution Methods</h3>
<p>At first glance, "tabular methods" might conjure dull images of
exhaustive spreadsheets and tedious searches. So why are we still
intrigued by them? Simple: they distill reinforcement learning down to
its purest form, clearly revealing the fundamental mechanics behind RL
algorithms.</p>
<p>What are the scope of tabular methods then?</p>
<p>We start with a basic model - <strong>Multi-armed bandits</strong>
model as a representation of single state situation where <strong>value
functions</strong> are introduced, along with the classical exploration
vs. exploitation challenge.</p>
<p>Then we move on to more general problem formulation - (finite)
<strong>Markov Decision Process</strong> (MDP), introducing multiple
states into the problem formation. Now, our learning becomes sequential
and goal-oriented, reflecting real-world decision-making as we interact
repeatedly with our environment.</p>
<p>To solve MDP problem we introduced <strong>3 new
methods</strong>:</p>
<ul>
<li><strong>Dynamic Programming</strong></li>
<li><strong>Monte Carlo(MC) Method</strong></li>
<li><strong>Temporal Difference(TD) learning</strong></li>
</ul>
<figure>
<img src="https://s2.loli.net/2025/06/24/fpnHGZcXyb2rYsR.png"
alt="DP-vs-MC-vs-TD" />
<figcaption aria-hidden="true">DP-vs-MC-vs-TD</figcaption>
</figure>
<p>As the pros and cons of each method was discovered, variation of the
above 3 methods are proposed, like MC+TD via multi-step bootstrapping,
TD+model learning &amp; planning, which will be discussed in later
post.</p>
<h3 id="approximate-solution-method">Approximate solution method</h3>
<p>The number of <strong>distinct states grows exponentially</strong> in
most realistic tasks, so storing a separate value for each state–action
pair is impossible, therefore we introduced approximate solution method
to search for a good approximate solution with limited computational
resources.</p>
<p>The problem with large state spaces is not just the memory needed for
large tables, but the time and data needed to fill them accurately. In
many of our target tasks, almost every state encountered will never have
been seen before. This propose challenges to the policy's
<strong>generalization capability</strong>. As key RL components are all
functions:</p>
<ul>
<li><em>State update function</em>s map observations to states</li>
<li><em>Value function</em>s map states to values</li>
<li><em>Policies</em> map states to actions</li>
<li><em>Models</em> map states and actions to next states and rewards.
to achieve generalization, we can reuse the tool - <strong>function
approximation</strong> - studied in supervised learning.</li>
</ul>
<p>There are a bunch of function approximator can be used:</p>
<ul>
<li>state aggregation (feature engineering) - represent state by a
feature vector</li>
<li>linear function (regression, nearest-neighbors, etc)
<ul>
<li>tabular function (look-up tables) are special case where <span
class="math inline">\(n\)</span> = number of states and where <span
class="math inline">\(w_i\)</span> is the value of each state <span
class="math inline">\(s_i\)</span>. <span class="math display">\[
v_{\mathbf w}(s)=
\begin{bmatrix}
w_1\\
\vdots\\
w_n
\end{bmatrix}^{\top}
\begin{bmatrix}
\mathbf 1\!\left(s=s_1\right)\\
\vdots\\
\mathbf 1\!\left(s=s_n\right)
\end{bmatrix}
\]</span></li>
</ul></li>
<li>non-linear function (neural network, decision tree, etc)</li>
</ul>
<p>As for the general methodology, we can <strong>approximate value
function</strong>:</p>
<ul>
<li><em>On-policy semi-gradient TD</em> &amp; <em>SARSA</em></li>
<li><em>Deep Q-Network (DQN)</em></li>
<li>Experience-replay variants</li>
</ul>
<p>or perform <strong>direct policy approximate</strong>:</p>
<ul>
<li><em>REINFORCE (Monte-Carlo Policy Gradient)</em> &amp; other
policy-gradient methods</li>
<li><em>Trust-Region Policy Optimisation (TRPO)</em> series
<ul>
<li>TRPO enforces a KL-divergence trust region via conjugate-gradient
solving.</li>
<li><em>Proximal Policy Optimisation (PPO)</em> – replaces TRPO’s
constraint with a simple clip or penalty surrogate; the current default
in many toolkits.</li>
</ul></li>
<li><em>Deterministic Policy Gradient (DPG) &amp; Deep DPG (DDPG)</em> –
actor outputs a deterministic action; critic supplies its gradient,
enabling continuous-action control.</li>
<li><em>Advantage Actor–Critic (A2C/A3C)</em> – many lightweight actors
share a global critic (or run asynchronously) to parallelise on-policy
learning.</li>
</ul>
<h2 id="rl-nowadays">RL nowadays</h2>
<h3 id="rl-with-deep-learning">RL with Deep Learning</h3>
<p>Deep learning has super-charged reinforcement learning by providing
expressive neural representations for policies, value functions, and
environment models. <strong>Trajectory Transformer</strong> (Janner et
al., <em>NeurIPS 2021</em>) shows how discretising continuous
trajectories into tokens effectively quantises the state-action space,
letting a plain Transformer do offline planning via sequence modelling,
also brought the influential Transformer work into RL context.</p>
<p>Meanwhile, <strong>Dyna-style architectures</strong> integrate
model-free Q-learning with a learned neural world-model whose simulated
roll-outs supply extra training data, blending model-based and
model-free updates in one deep RL loop.</p>
<p>At the high end, <strong>AlphaGo</strong> and its successor AlphaZero
couple deep convolutional policy/value nets with Monte-Carlo tree search
and self-play, achieving super-human performance in Go, chess, and
shogi—powerfully illustrating how CNN features and scalable RL jointly
push decision-making beyond human expertise.</p>
<h3 id="rl-with-large-language-models">RL with Large Language
Models</h3>
<p>Reinforcement Learning (RL), once a niche playground for gamers and
simulation enthusiasts aiming for super-human performance in video
games, has burst into the mainstream by joining forces with Large
Language Models (LLMs). Techniques such as RLHF, RLAIF, and RLVR have
transformed RL from a specialized skillset into a crucial step toward
training the next generation of AI—accelerating progress in the pursuit
of AGI. As RL insights merge seamlessly with LLMs, a dynamic new era in
artificial intelligence is unfolding, where machines not only learn but
actively align with human values, preferences, and intentions.</p>

    </div>

    <footer class="post-footer">
      
        <div class="post-tags">
  <svg class="icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
    <path d="M20.59 13.41l-7.17 7.17a2 2 0 0 1-2.83 0L2 12V2h10l8.59 8.59a2 2 0 0 1 0 2.82z"></path>
    <line x1="7" y1="7" x2="7.01" y2="7"></line>
  </svg>
  <span class="tags-label">Tags:</span>
  <ul class="tags-list">
    
      <li>
        <a href="/tags/Data-Science/" class="tag-link">#Data Science</a>
      </li>
    
      <li>
        <a href="/tags/Reinforcement-Learning/" class="tag-link">#Reinforcement Learning</a>
      </li>
    
  </ul>
</div>

      

      
  

  <div class="share-buttons">
    <span class="share-label">
      <svg class="icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
        <circle cx="18" cy="5" r="3"></circle>
        <circle cx="6" cy="12" r="3"></circle>
        <circle cx="18" cy="19" r="3"></circle>
        <line x1="8.59" y1="13.51" x2="15.42" y2="17.49"></line>
        <line x1="15.41" y1="6.51" x2="8.59" y2="10.49"></line>
      </svg>
      Share
    </span>

    <div class="share-buttons-list">
      
        
          <a href="https://twitter.com/intent/tweet?text=RL00%20-%20A%20glimpse%20of%20Reinforcement%20Learning&url=https%3A%2F%2Fdelusion4013.github.io%2F2025%2F06%2F24%2FRL00-A-glimpse-of-Reinforcement-Learning%2F"
             target="_blank"
             rel="noopener noreferrer"
             class="share-button share-twitter"
             title="Share on Twitter"
             aria-label="Share on Twitter">
            <svg viewBox="0 0 24 24" fill="currentColor">
              <path d="M18.244 2.25h3.308l-7.227 8.26 8.502 11.24H16.17l-5.214-6.817L4.99 21.75H1.68l7.73-8.835L1.254 2.25H8.08l4.713 6.231zm-1.161 17.52h1.833L7.084 4.126H5.117z"/>
            </svg>
          </a>
        
      
        
          <a href="https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fdelusion4013.github.io%2F2025%2F06%2F24%2FRL00-A-glimpse-of-Reinforcement-Learning%2F"
             target="_blank"
             rel="noopener noreferrer"
             class="share-button share-facebook"
             title="Share on Facebook"
             aria-label="Share on Facebook">
            <svg viewBox="0 0 24 24" fill="currentColor">
              <path d="M24 12.073c0-6.627-5.373-12-12-12s-12 5.373-12 12c0 5.99 4.388 10.954 10.125 11.854v-8.385H7.078v-3.47h3.047V9.43c0-3.007 1.792-4.669 4.533-4.669 1.312 0 2.686.235 2.686.235v2.953H15.83c-1.491 0-1.956.925-1.956 1.874v2.25h3.328l-.532 3.47h-2.796v8.385C19.612 23.027 24 18.062 24 12.073z"/>
            </svg>
          </a>
        
      
        
          <a href="https://www.linkedin.com/sharing/share-offsite/?url=https%3A%2F%2Fdelusion4013.github.io%2F2025%2F06%2F24%2FRL00-A-glimpse-of-Reinforcement-Learning%2F"
             target="_blank"
             rel="noopener noreferrer"
             class="share-button share-linkedin"
             title="Share on LinkedIn"
             aria-label="Share on LinkedIn">
            <svg viewBox="0 0 24 24" fill="currentColor">
              <path d="M20.447 20.452h-3.554v-5.569c0-1.328-.027-3.037-1.852-3.037-1.853 0-2.136 1.445-2.136 2.939v5.667H9.351V9h3.414v1.561h.046c.477-.9 1.637-1.85 3.37-1.85 3.601 0 4.267 2.37 4.267 5.455v6.286zM5.337 7.433c-1.144 0-2.063-.926-2.063-2.065 0-1.138.92-2.063 2.063-2.063 1.14 0 2.064.925 2.064 2.063 0 1.139-.925 2.065-2.064 2.065zm1.782 13.019H3.555V9h3.564v11.452zM22.225 0H1.771C.792 0 0 .774 0 1.729v20.542C0 23.227.792 24 1.771 24h20.451C23.2 24 24 23.227 24 22.271V1.729C24 .774 23.2 0 22.222 0h.003z"/>
            </svg>
          </a>
        
      
        
          <a href="https://reddit.com/submit?url=https%3A%2F%2Fdelusion4013.github.io%2F2025%2F06%2F24%2FRL00-A-glimpse-of-Reinforcement-Learning%2F&title=RL00%20-%20A%20glimpse%20of%20Reinforcement%20Learning"
             target="_blank"
             rel="noopener noreferrer"
             class="share-button share-reddit"
             title="Share on Reddit"
             aria-label="Share on Reddit">
            <svg viewBox="0 0 24 24" fill="currentColor">
              <path d="M12 0A12 12 0 0 0 0 12a12 12 0 0 0 12 12 12 12 0 0 0 12-12A12 12 0 0 0 12 0zm5.01 4.744c.688 0 1.25.561 1.25 1.249a1.25 1.25 0 0 1-2.498.056l-2.597-.547-.8 3.747c1.824.07 3.48.632 4.674 1.488.308-.309.73-.491 1.207-.491.968 0 1.754.786 1.754 1.754 0 .716-.435 1.333-1.01 1.614a3.111 3.111 0 0 1 .042.52c0 2.694-3.13 4.87-7.004 4.87-3.874 0-7.004-2.176-7.004-4.87 0-.183.015-.366.043-.534A1.748 1.748 0 0 1 4.028 12c0-.968.786-1.754 1.754-1.754.463 0 .898.196 1.207.49 1.207-.883 2.878-1.43 4.744-1.487l.885-4.182a.342.342 0 0 1 .14-.197.35.35 0 0 1 .238-.042l2.906.617a1.214 1.214 0 0 1 1.108-.701zM9.25 12C8.561 12 8 12.562 8 13.25c0 .687.561 1.248 1.25 1.248.687 0 1.248-.561 1.248-1.249 0-.688-.561-1.249-1.249-1.249zm5.5 0c-.687 0-1.248.561-1.248 1.25 0 .687.561 1.248 1.249 1.248.688 0 1.249-.561 1.249-1.249 0-.687-.562-1.249-1.25-1.249zm-5.466 3.99a.327.327 0 0 0-.231.094.33.33 0 0 0 0 .463c.842.842 2.484.913 2.961.913.477 0 2.105-.056 2.961-.913a.361.361 0 0 0 .029-.463.33.33 0 0 0-.464 0c-.547.533-1.684.73-2.512.73-.828 0-1.979-.196-2.512-.73a.326.326 0 0 0-.232-.095z"/>
            </svg>
          </a>
        
      
        
          <a href="https://api.whatsapp.com/send?text=RL00%20-%20A%20glimpse%20of%20Reinforcement%20Learning%20https%3A%2F%2Fdelusion4013.github.io%2F2025%2F06%2F24%2FRL00-A-glimpse-of-Reinforcement-Learning%2F"
             target="_blank"
             rel="noopener noreferrer"
             class="share-button share-whatsapp"
             title="Share on WhatsApp"
             aria-label="Share on WhatsApp">
            <svg viewBox="0 0 24 24" fill="currentColor">
              <path d="M17.472 14.382c-.297-.149-1.758-.867-2.03-.967-.273-.099-.471-.148-.67.15-.197.297-.767.966-.94 1.164-.173.199-.347.223-.644.075-.297-.15-1.255-.463-2.39-1.475-.883-.788-1.48-1.761-1.653-2.059-.173-.297-.018-.458.13-.606.134-.133.298-.347.446-.52.149-.174.198-.298.298-.497.099-.198.05-.371-.025-.52-.075-.149-.669-1.612-.916-2.207-.242-.579-.487-.5-.669-.51-.173-.008-.371-.01-.57-.01-.198 0-.52.074-.792.372-.272.297-1.04 1.016-1.04 2.479 0 1.462 1.065 2.875 1.213 3.074.149.198 2.096 3.2 5.077 4.487.709.306 1.262.489 1.694.625.712.227 1.36.195 1.871.118.571-.085 1.758-.719 2.006-1.413.248-.694.248-1.289.173-1.413-.074-.124-.272-.198-.57-.347m-5.421 7.403h-.004a9.87 9.87 0 01-5.031-1.378l-.361-.214-3.741.982.998-3.648-.235-.374a9.86 9.86 0 01-1.51-5.26c.001-5.45 4.436-9.884 9.888-9.884 2.64 0 5.122 1.03 6.988 2.898a9.825 9.825 0 012.893 6.994c-.003 5.45-4.437 9.884-9.885 9.884m8.413-18.297A11.815 11.815 0 0012.05 0C5.495 0 .16 5.335.157 11.892c0 2.096.547 4.142 1.588 5.945L.057 24l6.305-1.654a11.882 11.882 0 005.683 1.448h.005c6.554 0 11.890-5.335 11.893-11.893a11.821 11.821 0 00-3.48-8.413z"/>
            </svg>
          </a>
        
      
        
          <a href="https://telegram.me/share/url?url=https%3A%2F%2Fdelusion4013.github.io%2F2025%2F06%2F24%2FRL00-A-glimpse-of-Reinforcement-Learning%2F&text=RL00%20-%20A%20glimpse%20of%20Reinforcement%20Learning"
             target="_blank"
             rel="noopener noreferrer"
             class="share-button share-telegram"
             title="Share on Telegram"
             aria-label="Share on Telegram">
            <svg viewBox="0 0 24 24" fill="currentColor">
              <path d="M11.944 0A12 12 0 0 0 0 12a12 12 0 0 0 12 12 12 12 0 0 0 12-12A12 12 0 0 0 12 0a12 12 0 0 0-.056 0zm4.962 7.224c.1-.002.321.023.465.14a.506.506 0 0 1 .171.325c.016.093.036.306.02.472-.18 1.898-.962 6.502-1.36 8.627-.168.9-.499 1.201-.82 1.23-.696.065-1.225-.46-1.9-.902-1.056-.693-1.653-1.124-2.678-1.8-1.185-.78-.417-1.21.258-1.91.177-.184 3.247-2.977 3.307-3.23.007-.032.014-.15-.056-.212s-.174-.041-.249-.024c-.106.024-1.793 1.14-5.061 3.345-.48.33-.913.49-1.302.48-.428-.008-1.252-.241-1.865-.44-.752-.245-1.349-.374-1.297-.789.027-.216.325-.437.893-.663 3.498-1.524 5.83-2.529 6.998-3.014 3.332-1.386 4.025-1.627 4.476-1.635z"/>
            </svg>
          </a>
        
      

      <!-- Copy Link Button -->
      <button class="share-button share-copy" id="copy-link-button" title="Copy link" aria-label="Copy link">
        <svg class="copy-icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
          <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path>
          <path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path>
        </svg>
        <svg class="check-icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" style="display: none;">
          <polyline points="20 6 9 17 4 12"></polyline>
        </svg>
      </button>
    </div>
  </div>



      
        <nav class="post-nav">
  

  
    <a href="/2024/07/19/Complete-walk-through-of-hypothesis-testing/" class="post-nav-item post-nav-next" rel="next">
      <div class="post-nav-content">
        <span class="post-nav-label">Next</span>
        <span class="post-nav-title">Complete walk through of general hypothesis testing</span>
      </div>
      <svg class="icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
        <line x1="5" y1="12" x2="19" y2="12"></line>
        <polyline points="12 5 19 12 12 19"></polyline>
      </svg>
    </a>
  
</nav>

      

      
        <script>
// Code copy functionality is initialized in main.js
// This partial is just a marker that code copy buttons should be enabled
</script>

      
    </footer>
  </article>

  

<aside class="related-posts">
  <h3 class="related-posts-title">Related Posts</h3>
  <div class="related-posts-list">
    
      <article class="related-post-item">
        
        <div class="related-post-content">
          <h4 class="related-post-title">
            <a href="/2024/07/05/Complete-walk-through-of-confidence-intervals/">
              Complete walk through of confidence intervals
            </a>
          </h4>
          <div class="related-post-meta">
            <time datetime="2024-07-05T12:42:34.000Z">
              2024-07-05
            </time>
            
              <span class="related-post-separator">•</span>
              <span class="related-post-category">
                Notes
              </span>
            
          </div>
          
            <p class="related-post-excerpt">
              In this article, I will provide a complete walk through of a popular
concept in data science intervi...
            </p>
          
        </div>
      </article>
    
      <article class="related-post-item">
        
        <div class="related-post-content">
          <h4 class="related-post-title">
            <a href="/2024/01/26/SQL-cheatsheet/">
              Dealing with structured data - SQL cheatsheet
            </a>
          </h4>
          <div class="related-post-meta">
            <time datetime="2024-01-26T06:13:51.000Z">
              2024-01-26
            </time>
            
              <span class="related-post-separator">•</span>
              <span class="related-post-category">
                Notes
              </span>
            
          </div>
          
            <p class="related-post-excerpt">
              SQL (Structured Query Language) is the backbone of relational
databases. This guide breaks SQL into ...
            </p>
          
        </div>
      </article>
    
      <article class="related-post-item">
        
        <div class="related-post-content">
          <h4 class="related-post-title">
            <a href="/2023/11/21/Recommender-overview/">
              Recommender Series 1 - Overview
            </a>
          </h4>
          <div class="related-post-meta">
            <time datetime="2023-11-21T02:37:56.000Z">
              2023-11-21
            </time>
            
              <span class="related-post-separator">•</span>
              <span class="related-post-category">
                Notes
              </span>
            
          </div>
          
            <p class="related-post-excerpt">
              In this article, I will give an overall introduction about
recommenders, including how the recommend...
            </p>
          
        </div>
      </article>
    
  </div>
</aside>


  


  </main>

  <footer class="footer">
  <div class="footer-container">
    
      <div class="social-icons">
        
          <a href="https://github.com/Delusion4013" target="_blank" rel="noopener noreferrer" title="github">
            
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" width="20" height="20">
                <path d="M12 0C5.37 0 0 5.37 0 12c0 5.31 3.435 9.795 8.205 11.385.6.105.825-.255.825-.57 0-.285-.015-1.23-.015-2.235-3.015.555-3.795-.735-4.035-1.41-.135-.345-.72-1.41-1.23-1.695-.42-.225-1.02-.78-.015-.795.945-.015 1.62.87 1.845 1.23 1.08 1.815 2.805 1.305 3.495.99.105-.78.42-1.305.765-1.605-2.67-.3-5.46-1.335-5.46-5.925 0-1.305.465-2.385 1.23-3.225-.12-.3-.54-1.53.12-3.18 0 0 1.005-.315 3.3 1.23.96-.27 1.98-.405 3-.405s2.04.135 3 .405c2.295-1.56 3.3-1.23 3.3-1.23.66 1.65.24 2.88.12 3.18.765.84 1.23 1.905 1.23 3.225 0 4.605-2.805 5.625-5.475 5.925.435.375.81 1.095.81 2.22 0 1.605-.015 2.895-.015 3.3 0 .315.225.69.825.57A12.02 12.02 0 0024 12c0-6.63-5.37-12-12-12z"/>
              </svg>
            
          </a>
        
          <a href="/atom.xml" target="_blank" rel="noopener noreferrer" title="rss">
            
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" width="20" height="20">
                <path d="M4 11a9 9 0 0 1 9 9"></path>
                <path d="M4 4a16 16 0 0 1 16 16"></path>
                <circle cx="5" cy="19" r="1"></circle>
              </svg>
            
          </a>
        
      </div>
    

    <div class="footer-info">
      

      <div class="copyright">
        &copy; 2020 - 2025 Chenkai
      </div>

      
        <div class="powered-by">
          
            Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>
          
          
            <span class="separator">|</span>
          
          
            Theme <a href="https://github.com/yourusername/hexo-theme-papermod" target="_blank" rel="noopener">PaperMod</a>
          
        </div>
      
    </div>
  </div>
</footer>


  
    <button class="scroll-top" id="scrollTop" title="Back to top (Alt + G)">
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" width="24" height="24">
    <path d="m18 15-6-6-6 6"/>
  </svg>
</button>

  

  
    
  <div class="search-overlay" id="search-overlay">
    <div class="search-container">
      <div class="search-header">
        <div class="search-input-wrapper">
          <svg class="search-icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
            <circle cx="11" cy="11" r="8"></circle>
            <path d="m21 21-4.35-4.35"></path>
          </svg>
          <input
            type="text"
            id="search-input"
            class="search-input"
            placeholder="Search..."
            autocomplete="off"
            spellcheck="false"
          />
          <button class="search-close" id="search-close" aria-label="Close">
            <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
              <line x1="18" y1="6" x2="6" y2="18"></line>
              <line x1="6" y1="6" x2="18" y2="18"></line>
            </svg>
          </button>
        </div>
        <div class="search-hint">
          <kbd>⌘</kbd><kbd>K</kbd> or <kbd>Ctrl</kbd><kbd>K</kbd> to open, <kbd>Esc</kbd> to close
        </div>
      </div>

      <div class="search-results" id="search-results"></div>
    </div>
  </div>


  

  <!-- Scripts -->
  <script src="/js/main.02905c6e.js"></script>
  <script src="/js/theme-toggle.4f90f5d1.js"></script>

  
    <script src="/js/lazy-load.3cd2f9b0.js" defer></script>
  

  

  
    <script src="/js/search.31192334.js"></script>
  

  
    <script src="/js/toc-scroll.788c21d9.js"></script>
  

  
    <script src="/js/scroll-top.d4531bf8.js" defer></script>
  

  
    <script src="/js/reading-progress.58e925ba.js" defer></script>
  

  
    
  <script>
    // Keyboard shortcuts (AccessKeys)
    const shortcuts = {
      'h': () => window.location.href = '/',
      't': () => {
        const themeToggle = document.getElementById('themeToggle');
        if (themeToggle) themeToggle.click();
      },
      'c': () => {
        const tocContainer = document.querySelector('.toc-container');
        if (tocContainer) {
          tocContainer.classList.toggle('toc-open');

          // Update ARIA state
          const tocToggle = tocContainer.querySelector('.toc-toggle');
          if (tocToggle) {
            const isOpen = tocContainer.classList.contains('toc-open');
            tocToggle.setAttribute('aria-expanded', isOpen ? 'true' : 'false');
          }
        }
      },
      'g': () => {
        window.scrollTo({ top: 0, behavior: 'smooth' });
      },
      '/': () => {
        const searchButton = document.getElementById('searchButton');
        if (searchButton) searchButton.click();
      },
    };

    document.addEventListener('keydown', (e) => {
      if (e.altKey && shortcuts[e.key]) {
        e.preventDefault();
        shortcuts[e.key]();
      }
    });
  </script>


  

  




  <!-- Math Rendering -->
  
  

  
    <script>
      if (!window.MathJax) {
        window.MathJax = {
          tex: {
            inlineMath: [['$', '$'], ['\\(', '\\)']],
            displayMath: [['$$', '$$'], ['\\[', '\\]']],
            tags: 'ams',
            processEscapes: true,
            processEnvironments: true
          },
          chtml: {
            scale: 1.0,
            minScale: 0.5,
            matchFontHeight: true
          },
          options: {
            skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            ignoreHtmlClass: 'tex2jax_ignore',
            processHtmlClass: 'tex2jax_process'
          },
          startup: {
            pageReady: function() {
              return MathJax.startup.defaultPageReady().then(function() {
                console.log('MathJax rendering complete');
              });
            }
          }
        };
      }
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" id="MathJax-script" async></script>
  



  <!-- Mermaid Diagrams -->
  
  

  
    <script type="module">
      import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js';

      // Get current theme
      const isDark = document.documentElement.getAttribute('data-theme') === 'dark';
      const mermaidTheme = 'default';

      // Initialize Mermaid
      mermaid.initialize({
        startOnLoad: true,
        theme: isDark && mermaidTheme === 'default' ? 'dark' : mermaidTheme,
        securityLevel: 'loose',
        fontFamily: 'var(--font-sans)',
        themeCSS: `
          .node rect,
          .node circle,
          .node ellipse,
          .node polygon {
            fill: var(--bg-secondary);
            stroke: var(--border);
            stroke-width: 2px;
          }
          .node text {
            fill: var(--text-primary);
          }
          .edgePath .path {
            stroke: var(--border);
            stroke-width: 2px;
          }
          .edgeLabel {
            background-color: var(--bg-primary);
            color: var(--text-primary);
          }
        `
      });

      // Re-render when theme changes
      const observer = new MutationObserver((mutations) => {
        mutations.forEach((mutation) => {
          if (mutation.type === 'attributes' && mutation.attributeName === 'data-theme') {
            const newIsDark = document.documentElement.getAttribute('data-theme') === 'dark';
            const newTheme = newIsDark && mermaidTheme === 'default' ? 'dark' : mermaidTheme;

            mermaid.initialize({
              theme: newTheme
            });

            // Re-render all mermaid diagrams
            document.querySelectorAll('.mermaid').forEach((el, index) => {
              const id = `mermaid-${Date.now()}-${index}`;
              const graphDefinition = el.textContent;
              mermaid.render(id, graphDefinition).then(({ svg }) => {
                el.innerHTML = svg;
              });
            });
          }
        });
      });

      observer.observe(document.documentElement, {
        attributes: true,
        attributeFilter: ['data-theme']
      });

      console.log('Mermaid initialized');
    </script>
  


</body>
</html>
