<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>Discussion about LLMs and Multi-modality</title>
    <link href="/2023/03/21/Discussion-about-LLMs-and-Multi-modality/"/>
    <url>/2023/03/21/Discussion-about-LLMs-and-Multi-modality/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><p>In this post, I would discuss some of my thoughts on Multi-modalityand future LLMs directions.</p><span id="more"></span><h1 id="multi-modality">Multi-modality</h1><ul><li>Since OpenAI (GPT-4) and Baidu (Wen Xin Yi Yan) released LLMs withdifferent design for multi-modality. GPT-4 unifies the embeddingrepresentation between text and images, while WXYY seems to unify theability to generate different medium content (text, image, voice andvideo).</li><li>In my point of view, multi-modality should support machine'scomprehension by encoding different medium into a unified latent space,bridging the information between different modality. It is a progressivesimulation of human's learning approach, from reading only to read andsee.</li><li>In Xiaotong Fei's perspective (Chinese anthropologist andsociologist) from nearly 80 years ago, written language has intrinsicdeficiency which could convey only incomplete and ambiguous meaningscompare to real life situation. For example, we could tell from voicewho is visiting us, or from body language to understand other's emotion.It is therefore natural to gradually integrate the ability to take inand understand different medium as AI develops.</li><li>By quoting Xiaotong Fei's ideas years ago, I want to emphasize thatwe could to draw inspirations from studies which tries to explain howhuman learns and perceives. <strong>Artificial</strong> Intelligence,should always be rooted in the study of human intelligence.</li></ul><h1 id="where-is-llm-heading">Where is LLM heading?</h1><ul><li>Current Situation<ul><li>Not hitting human-level intelligence yet. Though it perform well inexams and chatting, it is still not good tasks like few-shot learning,long text comprehension and factual generation.</li></ul></li></ul><h3 id="future-directions">Future directions</h3><p>Guesses based on current LLM's deficiency.</p><ul><li>Multimodal comprehension<ul><li>to enable different interaction methods.</li></ul></li><li>Explainability<ul><li>Understanding different part of LLMs, why and how they draw certainconclusions, could help eliminating hallucination.</li></ul></li><li>Safety<ul><li>Fact-based, combined with thought chain for inference<ul><li>Generate more accurate content could prepare AI for more responsiblepositions.</li></ul></li><li>Detecting AI generated content.<ul><li>Being able to judge AI generated content is essential when thegenerated content contains hallucination.</li><li>Related Research - <a href="https://arxiv.org/abs/2301.07597">Guo etal., 2023</a></li></ul></li><li>Ensure data privacy during training / fine-tuning<ul><li>Debates about what data could be used during training. Consensusneeds to be drawn.</li></ul></li></ul></li><li>Decrease model size<ul><li>Model distill technology, lower the cost of use.</li></ul></li><li>Bionic Structure?<ul><li>For now, LLMs seems to be stacking transformers (or say GPUs) toachieve better performance. I suppose we could improve the performanceby using different networks to mimic human brain's architecture. Thisreverse-engineering process may be hard, but is worthwhile as it couldalso bring better understanding of ourselves.</li></ul></li><li>Advanced Reinforcement?<ul><li>With the improved multi-modality comprehension, we could expect moreintuitive learning mechanism for the <ahref="https://openai.com/research/learning-from-human-preferences">RLHF</a>proposed.</li></ul></li></ul><h1 id="what-could-down-stream-companies-do">What could down-streamcompanies do?</h1><ul><li>Model As A Service<ul><li>Integrate LLM API as additional service - help the company focus onsolving domain specific tasks.<ul><li>Advantage: keeping fact part - controllable</li><li>Disadvantage: sense of fragmentation between own service &amp; APIservice if the performance gap is huge.</li></ul></li><li>Or just use the basic models as the entire product<ul><li>Disadvantage: restricted controllability &amp; steerability</li></ul></li></ul></li><li>Fine-tuning domain-specific model<ul><li>Use domain specific data (as it's protected)</li><li>For example<ul><li>with psychological counseling conversation data to mimic thestyle.</li><li>with git messages &amp; comments &amp; stackoverflow data as acoding copilot</li><li>with structured financial statements &amp; annotated analyticalreport as a finance advisor</li></ul></li><li>Haven't seen much examples in practice</li></ul></li></ul>]]></content>
    
    
    <categories>
      
      <category>Computer Science</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Artificial Intelligence</tag>
      
      <tag>Generative AI</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>How to use diffusion web ui?</title>
    <link href="/2023/03/07/How-to-use-diffusion-web-ui/"/>
    <url>/2023/03/07/How-to-use-diffusion-web-ui/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><p>In this article, I will provide a walkthrough of common features onweb ui and how to use them to produce better quality pictures as youwish. I will be covering two main aspects: txt2img and img2img,introduce the basic parameter setting and possible usages.</p><span id="more"></span><h1 id="text-to-images---txt2img">Text to images - txt2img</h1><h2 id="prompt">Prompt</h2><ul><li>The cue passed to model for image generation.</li><li>Separated into 2 parts in webui:<ul><li>positive prompt (what you want) and negative prompt (what should beavoid)</li></ul></li></ul><h3 id="how-to-write-good-prompts">How to write good prompts?</h3><ul><li><p>Templates &gt; “A <em>[type of picture]</em> of a <em>[mainsubject]</em>, *[style cues]**” <ahref="https://strikingloo.github.io/stable-diffusion-vs-dalle-2#appendix-a-stable-diffusion-prompt-guide">Ref1</a><br />- E.g. <code>A portrait of a 25 y.o. young man, uhd</code></p></li><li><p>Commonly used tags</p><ul><li>Positive tags: <code>masterpiece</code>, <code>1girl</code>,<code>highres</code>, <code>ultra detail</code>, etc.<ul><li>Discover the tags that fits your need on <ahref="https://civitai.com/">Diffusion Model site</a>'s exampleprompts.</li><li>Or found interesting prompts use the <ahref="https://lexica.art/">search engine</a></li></ul></li><li>Style tags/templates<ul><li><p><ahref="https://civitai.com/models/4201/realistic-vision-v13-fantasyai">RealisticImage</a> - <code>RAW photo</code>, <code>8k uhd</code></p><ul><li><p>Postive Prompts</p><p><figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs txt">RAW photo, *subject*, (high detailed skin:1.2), 8k uhd, dslr, soft lighting, high quality, film grain, Fujifilm XT3<br></code></pre></td></tr></table></figure></p></li><li><p>Negative Prompts</p><p><figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs txt">(deformed iris, deformed pupils, semi-realistic, cgi, 3d, render, sketch, cartoon, drawing, anime:1.4), text, close up, cropped, out of frame, worst quality, low quality, jpeg artifacts, ugly, duplicate, morbid, mutilated, extra fingers, mutated hands, poorly drawn hands, poorly drawn face, mutation, deformed, blurry, dehydrated, bad anatomy, bad proportions, extra limbs, cloned face, disfigured, gross proportions, malformed limbs, missing arms, missing legs, extra arms, extra legs, fused fingers, too many fingers, long neck<br></code></pre></td></tr></table></figure></p></li></ul></li></ul></li><li>Commonly used negative tags: <figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs txt">lowres, ((bad anatomy)), ((bad hands)), text, missing finger, extra digits, fewer digits, blurry, ((mutated hands and fingers)), (poorly drawn face), ((mutation)), ((deformed face)), (ugly), ((bad proportions)), ((extra limbs)), extra face, (double head), (extra head), ((extra feet)), monster, logo, cropped, worst quality, low quality, normal quality, jpeg, humpbacked, long body, long neck, ((jpeg artifacts))<br></code></pre></td></tr></table></figure></li></ul></li></ul><h3 id="take-aways---ref">Take aways - <ahref="https://docs.google.com/document/d/17VPu3U2qXthOpt2zWczFvf-AH6z37hxUbvEe1rJTsEc/edit#">Ref</a></h3><ul><li><p>Anything unspecified may be randomly generated</p><ul><li>Sometimes even said ones could be interpreted wrongly. Try toincrease the tag's weight using the format<code>(style_or_attribute_name: 1.x)</code>, this would assign a weight<code>1.x</code> to the specified tag.</li></ul></li><li><p>Try visually well-defined objects</p><ul><li>E.g. Wizard, priest, angle, rockstar, temple, farm, etc.</li></ul></li><li><p>Try describing a style</p><ul><li><strong>Try:</strong> cyberpunk, psychedelic, surreal, vaporwave,alien, solarpunk, modern, ancient, futuristic, retro, realistic,dreamlike, funk art, abstract, pop art, impressionism, minimalism</li></ul></li><li><p>Try invoking unique artists for style (deprecated instable-diffusion-2.0)</p><ul><li><strong>Try:</strong> Hiroshi Yoshida, Max Ernst, Paul Signac,Salvador Dali, James Gurney, M.C. Escher, Thomas Kinkade, IvanAivazovsky, Italo Calvino, Norman Rockwell, Albert Bierstadt, Giorgio deChirico, Rene Magritte, Ross Tran, Marc Simonetti, John Harris, Hilma afKlint, George Inness, Pablo Picasso, William Blake, Wassily Kandinsky,Peter Mohrbacher, Greg Rutkowski, Paul Signac, Steven Belledin, StudioGhibli</li></ul></li><li><p>Try different medium (the type of picture)</p><ul><li><strong>Try:</strong> painting, drawing, sketch, pencil drawing,woodblock print, matte painting, child's drawing, charcoal drawing, anink drawing, oil on canvas, graffiti, watercolor painting, fresco, stonetablet, cave painting, sculpture, work on paper, needlepoint</li></ul></li><li><p>Avoid indirect (e.g. <code>a hat that is not red</code>), usepositive term (e.g. <code>a blue hat</code>)</p></li><li><p>Use <ahref="https://promptomania.com/stable-diffusion-prompt-builder/">thissite</a> to get visual cue for generating prompts on differentstyles.</p></li></ul><h2 id="settings-paramters">Settings &amp; Paramters</h2><h3 id="models">Models</h3><ul><li>models and its accessories provide customizations for differentstyles.</li><li>Pick your model up on <a href="https://civitai.com/">civitai</a> andput it under <code>stable-diffusion-webui/models/stable-diffusion</code>folder to load.</li></ul><h3 id="sampling-methods">Sampling Methods</h3><ul><li>Sampling methods are the algorithms used to produce images.</li><li>Even though I used stable diffusion for some time, I could hardlytell a definitive difference between different samplers.</li><li>It is suggested to use the same sampler as the model's exampleprompt does, or use popular ones like <code>Euler a</code>,<code>DDIM</code>, <code>DPM</code> family.</li><li><imgsrc="../../../../Documents/KnowledgeBase/assets/imgs/1661440027115223-8631669.jpg" /></li><li><ahref="https://wandb.ai/agatamlyn/basic-intro/reports/Stable-Diffusion-and-the-Samplers-Mystery--VmlldzoyNTc4MDky">Reffor samples’ job</a></li></ul><h3 id="sampling-steps">Sampling steps</h3><ul><li>Number of steps used to generate images. Larger number takes longerto generate. Normally set between <code>20~80</code></li><li>Note: Not bigger value the better. Some sampling methods'performance does not increase as the value increases.</li></ul><h3 id="cfg-scale">CFG scale</h3><ul><li>Classifier Free Guidance scale - Restricts how strongly thegenerated image should conform the prompt.</li><li>Lower values -&gt; less restricted / more creative result</li></ul><h3 id="batch-size">Batch size</h3><ul><li>Specify how many image to create in a single batch.</li><li>High VRAM needed. For consumer level graphics card, it's better toincrease the batch count for multiple generations. (Trade VRAM spacewith time)</li></ul><h3 id="batch-count">Batch count</h3><ul><li>Specify how many batches to generate.</li></ul><h3 id="seed">Seed</h3><ul><li>A random variable that controls the output.</li><li>With same settings (including seed), you could reproduce theresult.</li></ul><h1 id="images-to-images---img2img">Images to images - img2img</h1><ul><li>In img2img tab, images could be used as input as the guide forgeneration.<ul><li>You could use realistic photo to generate your animationfigure.</li><li>Or use hand-drawn draft to create good looking pictures.</li></ul></li></ul><h2 id="unique-parameter">Unique parameter</h2><h3 id="resize-mode">Resize mode</h3><ul><li>This defines the behavior when the input image size is not same asthe one you indicated.</li></ul><h3 id="denoising-strength">Denoising strength</h3><ul><li>This defines the similarity between the generated image and theoriginal one. The larger / the closer to <code>1</code>, the image wouldlikely to take less features fro the original input.</li></ul><h2 id="possible-usage">Possible Usage</h2><ul><li>Upscaling images (Could use the high res fix instead)</li><li>Turn your photo into different styles<ul><li>Use your image as input, adding prompt, choose the right stylemodel, and AI will do the magic.</li></ul></li><li>Expand existing image (Outpaint)</li><li>Fix / Modify selected parts of the image (Inpaint)<ul><li>Mask the part you want to re-generate, modify the prompt a bit, youcould fix those faulty parts or let the AI inspires you.</li></ul></li><li>Modify the image by instructions (Not mature)<ul><li>This involves the <ahref="https://github.com/timothybrooks/instruct-pix2pix">wonderfulwork</a> presented by UC Berkeley <ahref="https://github.com/timothybrooks">Tim Brooks</a> and hisfellows.</li><li>Maybe it's the reason that I didn't get the correct format forinstructions, I could hardly use it on my own images, it performsperfectly well on examples though.</li></ul></li></ul><h1 id="wonderful-video-tutorials">Wonderful Video Tutorials</h1><ul><li><a href="https://www.youtube.com/watch?v=1_dViOW3Vy">StableDiffusion-Master AI Art: Installation, Prompts, txt2img-img2img,out/inpaint &amp;Resize Tutorial - By ChamferZone</a><ul><li>A Comprehensive tutorial for using stable diffusion throughweb-ui.</li></ul></li><li>Tutorials by <ahref="https://www.youtube.com/@sebastiankamph">Sebastian Kamph</a>,really brief but useful snippets.<ul><li>I enjoyed the <ahref="https://www.youtube.com/watch?v=vFZgPyCJflE">ControlNettutorial</a> a lot, really mind blowing!</li></ul></li></ul>]]></content>
    
    
    <categories>
      
      <category>Computer Science</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Artificial Intelligence</tag>
      
      <tag>Diffusion</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>How to set up your diffusion models?</title>
    <link href="/2023/02/28/How-to-set-up-your-diffusion-models/"/>
    <url>/2023/02/28/How-to-set-up-your-diffusion-models/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><p>In this article, I will present a step-by-step guide to launch thefamous stable diffusion webui on your own PC with an easy-to-useweb-ui.</p><span id="more"></span><h2 id="pre-requisite">Pre-requisite</h2><ul><li>Large AI models perform better on GPUs, check your GPU's version byrunning <code>nvidia-smi</code> command. This would allow you to checkyour CUDA version (kind of GPU driver), which will be used in laterpackage selection.<br /></li><li>Check you have installed <strong>Python</strong> and<strong>git</strong>.<ul><li>By command <code>python --version</code> &amp;&amp;<code>git --version</code> you could check whether they areinstalled.<br /></li><li>If you haven't installed Python, you could check the <ahref="https://www.python.org/downloads/windows/">official website</a> todownload the package(^^3.9+ version with installerrecommended!^^).<br /></li><li>If you haven't installed Git, check the <ahref="https://git-scm.com/downloads">Official website</a> to downloadthe package.</li></ul></li></ul><h2 id="choose-your-model">Choose your model</h2><ul><li><p>Models often require some time to be downloaded, so it's prudentto start downloading the models and then continuing to setup yourenvironment.</p></li><li><p>Here is some resources for diffusion models</p><ul><li><p><ahref="https://huggingface.co/stabilityai/stable-diffusion-2-1">Theofficial version of stable diffusion 2 on HuggingFace</a></p></li><li><p><a href="https://civitai.com/">A website with fine-tunedcheckpoints</a></p><blockquote><p>Fine-tune is a technique for further fitting the base AI models tothe given style or performing better on a specific task.</p></blockquote></li></ul></li></ul><h2 id="set-up-your-environment">Set up your environment</h2><p>One popular repository for diffusion is the <ahref="https://github.com/AUTOMATIC1111/stable-diffusion-webui">stable-diffusion-webuiby AUTOMATIC1111</a></p><ul><li>Run the command below under the directory where you want theapplication to be placed.</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">$ </span><span class="language-bash">git <span class="hljs-built_in">clone</span> https://github.com/AUTOMATIC1111/stable-diffusion-webui.git</span><br></code></pre></td></tr></table></figure><h3 id="automatic-download">Automatic Download</h3><ul><li>Following the instructions in the <code>README</code>, you couldeither run <code>webui-user.bat</code> (Windows Users) or<code>webui.sh</code> (linux user by <code>bash webui.sh</code>) toautomatically download the required packages</li></ul><h3 id="manual-download">Manual Download</h3><ul><li>Create a virtual environment for the required packages using conda.<ul><li>create a new conda environment with command<br /><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs shell">// You could change the word after -n <br>// to customize the environment name<br><span class="hljs-meta prompt_">$ </span><span class="language-bash">conda create -n diffusion</span><br><span class="hljs-meta prompt_">$ </span><span class="language-bash">conda activate diffusion</span><br></code></pre></td></tr></table></figure></li></ul></li><li>Download the corresponding <code>pytorch</code> package (the CUDAversion) using the command from <ahref="https://pytorch.org/get-started/previous-versions/">officialwebsite</a><ul><li>For example, if your CUDA version is 11.4, run the belowcommand<br /><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">$ </span><span class="language-bash">conda install pytorch==1.12.1 torchvision==0.13.1 torchaudio==0.12.1 cudatoolkit=11.3 -c pytorch</span><br></code></pre></td></tr></table></figure></li></ul></li><li>Run <code>python launch.py</code> and let the script install theother packages for you. Or you could run<code>pip install -r requirements.txt</code>.<ul><li>If failed to launch, you could<ul><li><ol type="1"><li>Manually download the repository<code>git clone https://github.com/Stability-AI/stablediffusion.git</code><br /></li><li>Install the required package according to <ahref="https://github.com/Stability-AI/stablediffusion#requirements">Requirements</a>- skip the pytorch installation</li><li>run <code>pip install -e .</code> in the directory</li></ol></li></ul></li></ul></li></ul><h2 id="place-your-models">Place your models</h2><ul><li>After you could run <code>python launch.py</code> with no error, putthe downloaded model under<code>stable-diffusion-webui/models/Stable-diffusion/</code> directory,then you should be able to adjust the model on the top leftcorner.<br /><img src="https://s2.loli.net/2023/02/28/r7U9BTv42g8QKqh.png"alt="diffusion-webui-example" /></li></ul><h2 id="you-are-ready-to-go">You are ready to go!</h2><ul><li>For prompt reference, you could dive into different communities anduse this wonderful <a href="https://lexica.art/">search engine</a>.</li><li>In a later article, I will present more detailed introductions tothe different components of diffusion models (like inference steps,sampling methods and so on). You could also reference to the wonderfultutorials on <ahref="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki">Stablediffusion webui wiki</a> for advanced features.</li></ul>]]></content>
    
    
    <categories>
      
      <category>Computer Science</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Artificial Intelligence</tag>
      
      <tag>Diffusion</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Thinking about Generative AI</title>
    <link href="/2023/02/14/Thinking-about-Generative-AI/"/>
    <url>/2023/02/14/Thinking-about-Generative-AI/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><p>In this post, I would give a brief introduction of recent populargenerative AIs, and then dicsuss some of its pros and cons.<span id="more"></span></p><h1 id="introduction-of-recent-popular-models">Introduction of recentpopular models</h1><p>In the past year, Generative AI (or AIGC) captured massive attentionfrom all over the world. From Stable-Diffusion to various versions ofText-to-image models in the first half, and ChatGPT to Bing-GPT in thesecond half, there seems a new level of intelligence has beenachieved.</p><p>Out of the spotlight, AlphaCode and CodeX has been used to boostprogrammer's productivity. AlphaTensor successfully discovered a newmatrix multiply algorithm. After several years of development in deeplearning field, Artificial Intelligence has made a remarkable stepforward in multiple areas.</p><p>For more generative AI, please refer to <ahref="http://arxiv.org/abs/2301.04655">Gozalo-Brizuela andGarrido-Merchan's Work</a>, in which they give an comprehensive overviewof different generative AIs and a brief introduction of various models.The categorization based on input and output of models split the recentresearch into 9 categories as follows:<br />- text-to-image<br />- text-to-3D model<br />- image-to-text (image summary)<br />- text-to-video<br />- text-to-audio (also called TTS)<br />- text-to-text (summary, comprehension, translation, etc..)<br />- text-to-code<br />- text-science<br />- Others</p><p>I am not going to give a detailed introduction to the technologybehind each model, but discusses the pros and cons of some of therepresentative models and what to do with this irreversible trend.</p><h1 id="diffusion-models---artists">Diffusion models - Artists</h1><ul><li>Some example images diffusion model generated - obtained from <ahref="https://lexica.art/">Lexica.art</a>, a wonderful image searchengine for generated images</li></ul><div class="row"><style>.column {float: left;width: 33.33%;padding: 5px;}.row::after {  content: "";  clear: both;  display: table;}</style><div class="column"><p><img src="https://s2.loli.net/2023/02/14/B4xU753OVfkSZ9a.jpg" alt="Example-diffusion-figure" display="inline" /></p></div><div class="column"><p><img src="https://s2.loli.net/2023/02/14/15VkeiltKU3PM7Y.jpg" alt="example-3d-art" display="inline" /></p></div><div class="column"><p><img src="https://s2.loli.net/2023/02/14/kX57Hc3C9ZdiTIY.jpg" alt="example-realistic" display="inline" /></p></div></div><ul><li>In case you haven't try these awesome models, below are someresources of ready-to-use models<ul><li>MidJourney <a href="https://discord.com/invite/midjourney">DiscordChannel</a><br /></li><li><a href="https://huggingface.co/spaces/camenduru/webui">HuggingFacemodel</a></li></ul></li></ul><h2 id="pros">Pros</h2><ul><li>Quick to draw.<ul><li>Compared to human artists, AI could generate an image in less than10s.<br /></li></ul></li><li>Adjustability.<ul><li>It may be hard to change the pose, the cloth or other details aboutthe figure, but for AI, changing a few tags could have this effect. Onecould use <code>impaint</code> to erase some part of the picture andre-generate. Modifying a few tags could also change the style of thepainting significantly.<br /></li></ul></li><li>Image-Image imitate capability.<ul><li>Take an image as input, generate a new image based on the given oneand the prompt. This feature allows people to create personalizedportrait for themselves.</li></ul></li></ul><h2 id="cons">Cons</h2><ul><li>Prompt engineering needed.<ul><li>As the model name (text-to-image) suggests, one need to provide adescription for the desired image. Though many products has encapsulatedsome prompt engineering work, it is still user's responsibility tounderstand the basic prompt structure and (know and )choose the tagsthey need for certain styles. Here are some guides for you to writeefficient prompts:<ul><li><ahref="https://wandb.ai/morgan/stable-diffusion/reports/Stable-Diffusion-Settings-and-Storing-Your-Images--VmlldzoyNTExMDgy">Stable-diffusiondemonstration blog</a><br /></li><li><ahref="https://strikingloo.github.io/stable-diffusion-vs-dalle-2#appendix-a-stable-diffusion-prompt-guide">Howto write smart prompt?</a><br /></li><li><ahref="https://docs.google.com/document/d/17VPu3U2qXthOpt2zWczFvf-AH6z37hxUbvEe1rJTsEc/edit#">Howto write diffusion prompt - Google docs</a><br /></li><li><ahref="https://huggingface.co/spaces/Gustavosta/MagicPrompt-Stable-Diffusion">PromptGenerator</a><br /></li></ul></li></ul></li><li>Serious copyright issues<ul><li>This topic is much debated, and most AI companies are vague aboutrights of the generated images (correct me if I got this wrong). Laws orindustry rules are still unclear about to which extent of resemblanceshould we consider an image is plagiarized. Some may debate that it isplagiarism for using copyright protected images as the traininginput!<br /></li></ul></li><li>Unsure quality<ul><li>If you are using raw models, it is common to get poorly drawn hands,fused fingers or more than 2 feet figures. The impact of differentsampling method, CFG scale (how strictly model adhere to prompt) andsampling steps is significant. These things all add up to unsure qualityfor unskilled user of diffusion models.<br /></li><li>A possible negative prompts I collected on the internet:<br /><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs text"># Negative prompts<br>    <br>(poorly drawn hands), (poorly drawn face), weird, (((fat))), ((cropped)), ((fused fingers)), ((too many fingers)), (malformed limbs), (((bad anatomy))), ((ugly)), out of frame, blurry, gross propotions, distorted face, distorted body, ((distorted fingers)), missing leg, more than 2 leg, more than 2 feet, more than 2 arms, text, ui, signature, icon, watermark, misplaced limbs, leg too big, leg too small, fused hands, fused arms, distorted backgroud, fused buildings, ((finger too short)), more than 1 right hand, more than 1 left hand, wrong direction of limbs, wrong direction of legs, wrong direction of feet, misplaced facial features, unbalanced facial features, ((body too long)), ((arm too short)), (poorly drawn joint), misplaced joint, wrong joint angle, disappearing legs, disappearing arms, disappearing limbs, ((fused limbs)), thumb too long, fingers too long, missing hands, missing arms, ((misplaced animal tail)),less than 2 ears, ((more than 2 ears)),(watermark)<br></code></pre></td></tr></table></figure></li></ul></li></ul><h2 id="what-to-do-against-visual-generations">What to do against VisualGenerations?</h2><ul><li>With the rapid development of text to image models, what's theunique advantages of humans that could hardly be replaced in the shorttime (as for now)? How to cope with such situation?<br /></li><li><ol type="1"><li>Embrace the change, use as an assistant / inspiration explorationtool<br /></li></ol><ul><li>For expert artists, it is expected that AI generated art couldhardly replace them in the foreseeable future with theirconsistent-quality creations and zero copyright risks. It is the rookiesin this field that AI could easily replace, outstanding through bothspeed and quality.<br /></li><li>Moreover, the latest model is still based on probability theory,which means AI still have a long way to go to actually have a human-likesense of aesthetics. Like many novels and movies suggests, human's<strong>creativity</strong> by combining different things together isstill outperforming artificial intelligence. Therefore, we could embracethe development of AI models, use them to flourish relevant industries(like game or movie making), to assist artists themselves to explore newideas, or sharing quick prototypes with clients to achieve accordanceabout the requirements.<br /></li></ul></li><li><ol start="2" type="1"><li>Solve the Copyright issue!!!!<br /></li></ol><ul><li>It is <strong>never</strong> excessive to discuss this issue andbuild consensus between artists and AI developers. What rights could AIgenerated content have, how should those contents be judged asplagiarism and whether models are allowed to train on these imagesshould be discussed throughly.</li></ul></li></ul><h1 id="chatgpt---search-engine"><ahref="https://chat.openai.com/">ChatGPT</a> - Search Engine</h1><ul><li>For the second half of the year, ChatGPT sweeps the attention of thepublic with its spectacular performance. Some even claims that ChatGPTcould replace the search engine as a general AI assistant. (Now Bing hasintegrate with GPT-4 perhaps even better)</li></ul><h2 id="pros-1">Pros</h2><ul><li>Fantastic comprehension of instructions and obeying them.<ul><li>As many may have tried, ChatGPT could understand instructionsranging from writing a poem to write a simple program. With promptengineering (yeah, again), you could even change the ChatGPT into a <ahref="https://www.youtube.com/watch?v=f4jlE8qmEMo&amp;ab_channel=AminBoulouma%F0%9F%A4%96">commandline interface</a> or a <ahref="https://discord.com/channels/974519864045756446/1074379722521317407/1074379722521317407">cutechatbot</a> that only reply to you using emoticons.<br /></li></ul></li><li>Long context support<ul><li>As a conversational AI, the ability to have long-range contextsupport is essential. ChatGPT is the most successful product thatimplements context support among all large language models I know.<br /></li></ul></li><li>Ability to fuse content for increasing productivity(compared tosearch engines to some extent)<ul><li>This ability kinds of automate the search engine's job. When we havea question, we type it in search engine, read through the first fewarticles and deduce the result ourselves. ChatGPT has the capability ofsimplifying the latter process, by performing passage summarization andcomprehension task to generate an answer.<br /></li><li>It also empowers copywriters who could combine their companiesproduct with various marketing templates with a few lines ofinstructions.<br /></li><li>With code writing integration, ChatGPT also empowers programmers towrite code more efficiently with code templates, package suggestion anddebug hints.</li></ul></li></ul><h2 id="cons-1">Cons</h2><ul><li>Bad support for factual questions on specific domains<ul><li>As a natural defect of probabilistic model, questions based onactual fact on specific domains may be wrong. For example, if you queryabout a specific domain in scientific research, ChatGPT may concatincorrect author with papers, or even made up one.<br /></li></ul></li><li>Lack of in-depth User comprehension<ul><li>Though it is not OpenAI's responsibility to build this module, onecould hardly deny that a well-designed chatbot could perform better thanChatGPT in understanding the customer and react accordingly, whichsuggest the need of further tuning for customer-oriented industry likecompanion chatbot.<br /></li></ul></li><li>Cost of Training / Finetuning<ul><li>This may not be a problem for most down-stream companies using APIsto access the language model, however, this may result in monopoly inthe large language model area. The cost of training would then betransferred to down-stream users of models.</li></ul></li></ul><h2 id="what-to-do">What to do?</h2><ul><li>Against LLMs' weaknesses<ul><li>explainability study of LLM<ul><li>Poor explainability has been a problem since large language modelbecame the new paradigm. If we could understand how attention mechanismunderstand certain input, it could a huge improvement to mastering theblack box model.<br /></li></ul></li><li>Factual response research<ul><li>As ChatGPT has some defect in factual response generation, it may bevaluable to study how to combine knowledge with the generation model. Apromising direction is to use knowledge graphs (<ahref="https://delusion4013.github.io/2023/02/02/Knowledge-Graph-An-Introduction/">myintroduction to KGs</a>), which explicitly defines knowledge with clearstructure. Knowledge Graph based Question Answering (KGQA) seemsprospective in generating controllable and correct answers.</li></ul></li></ul></li><li>What could comapnies do to build competitive products?<ul><li>Ability to understand the user<ol type="1"><li>This includes the recognition of the user's current mood</li><li>Understanding of the person from past interaction datacollection</li><li>Reasoning about the user profile after big data analysis</li></ol></li><li>Content expertise and richness in verticals (psychologicalcounseling, healing as an example)<ol type="1"><li>Multiple rounds of dialogues for different life scenarios</li><li>Development of common counseling scenarios</li><li>R&amp;D of generative models based on consulting corpus (to belaunched)</li></ol></li><li>Customization support for specific business<ol type="1"><li>ChatGPT as a large model, the deployment cost and continued trainingcost are not small. From this perspective, we can sell customized smallmodel services, segmentation, and compete with ChatGPT in the niche areaof expertise.</li><li>Based on the optimized knowledge base, use different knowledge basesto support different roles of chatbots and adapt to differentscenarios.</li></ol></li></ul></li></ul>]]></content>
    
    
    <categories>
      
      <category>Computer Science</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Artificial Intelligence</tag>
      
      <tag>Generative AI</tag>
      
      <tag>Diffusion</tag>
      
      <tag>ChatGPT</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>An introduction to KMP algorithm</title>
    <link href="/2023/02/10/An-introduction-to-KMP-algorithm/"/>
    <url>/2023/02/10/An-introduction-to-KMP-algorithm/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><p>In this post, I will introduce the string matching problem, and aclever solution - KMP algorithm. I start from the brute force method andshowed how to deduce KMP. <span id="more"></span></p><h1 id="introduction">Introduction</h1><h2 id="string-matching-problem">String Matching Problem</h2><ul><li>Given strings <code>S</code>(length <code>m</code>) and<code>T</code> (length <code>n</code>), find <code>T</code> in<code>S</code>. The string <code>T</code> called<strong>pattern</strong>.</li><li>Wide Applications, essential role in various real-world problems.<ul><li>Text processing: spell checking, text classification, informationretrieval (especially in NLP field).</li><li>Pattern recognition: bioinformatics, speech recognition</li><li>Database management: used to searching and retrievingefficiently.</li></ul></li></ul><h2 id="kmp-algorithm">KMP algorithm</h2><ul><li>This is an algorithm designed for the above problem, which is timeefficient.</li><li>Summary of key ideas in KMP (for those are familiar with stringmatching problem):<ul><li>reduce the total comparison round --&gt; utilize the informationgained after each failed comparison</li><li>exploit the information of the pattern string --&gt; maintain anarray for storing useful information.</li></ul></li></ul><h1 id="brute-force-method">Brute Force method</h1><ul><li>Before dig into KMP algorithm, let's look at the method whichdefines the lower limit of the performance. <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Brute force algorithm for string matching</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">bruteForce</span>(<span class="hljs-params">S, P</span>):<br>  <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(S) - <span class="hljs-built_in">len</span>(P) + <span class="hljs-number">1</span>):<br>    <span class="hljs-keyword">if</span> S[i : i + <span class="hljs-built_in">len</span>(P)] == P:<br>      <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;Find a matching point at position <span class="hljs-subst">&#123;i&#125;</span>&#x27;</span>) <span class="hljs-comment"># f-string</span><br></code></pre></td></tr></table></figure><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs C"><span class="hljs-type">void</span> <span class="hljs-title function_">bruteForce</span><span class="hljs-params">(<span class="hljs-type">char</span> *s, <span class="hljs-type">char</span> *p)</span> &#123;<br>  <span class="hljs-type">int</span> lenS = <span class="hljs-built_in">strlen</span>(s), lenP = <span class="hljs-built_in">strlen</span>(p);<br>  <br>  <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt;= lenS - lenP; i++) &#123;<br>  boolean flag = <span class="hljs-literal">true</span>;<br>    <br>    <span class="hljs-keyword">for</span> <span class="hljs-title function_">int</span><span class="hljs-params">(j = <span class="hljs-number">0</span>; p[j] != <span class="hljs-string">&#x27;\0&#x27;</span>; j++)</span> &#123;<br>      <span class="hljs-keyword">if</span>(s[i+j] != p[j]) &#123;<br>        flag = <span class="hljs-literal">false</span>;<br>        <span class="hljs-keyword">break</span>;<br>      &#125;<br>    &#125;<br>    <br>    <span class="hljs-keyword">if</span>(flag) <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;Find a matching point at position %d\n&quot;</span>, i);<br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure></li><li>The intuition is pretty straight forward,<ul><li><ol type="1"><li>we match the string character by character, if no failed matchingtill the end of the pattern string, then a successful matching wasfound.</li><li>Then for the entire string, we place the pattern string at the startof each character in <code>S</code> string, then perform the above thestep.</li></ol></li></ul></li></ul><h2 id="analysis">Analysis</h2><ul><li>The step <code>1</code> takes <code>|P|</code> (length of patternstring, usually marked as <code>n</code>) time, and the step<code>2</code> takes <code>|S|</code> (length of original string) time,we could easily conclude the time complexity is <spanclass="math inline">\(O(|P| \cdot |S| )\)</span>.</li><li>Why is it so slow? Or where could we improve?<ul><li>Apparently we could not optimize the comparison process at step<code>1</code> , to check a match we need to perform a fullcomparison.</li><li>Naturally we turned to think if we could reduce the round formatching in step <code>2</code>. Look at the example below:<ul><li><figure><img src="https://s2.loli.net/2023/02/10/VOC5L6uESbXt7UD.png"alt="image.png" /><figcaption aria-hidden="true">image.png</figcaption></figure></li><li><p>After the above failed comparison, the brute force would start anew round of comparison at <code>S[1]</code>,<code>S[2]</code>. Theseattempts is obvious to fail. The KMP algorithm therefore proposes amechanism to <strong>skip these impossible matching</strong>.</p></li><li><p>The resulting process should be like this: (white colored meanscomparison skipped):</p></li><li><figure><img src="https://s2.loli.net/2023/02/10/sQcdCexKumNHASr.png"alt="image.png" /><figcaption aria-hidden="true">image.png</figcaption></figure></li></ul></li></ul></li></ul><h1 id="deducing-the-kmp-algorithm">Deducing the KMP algorithm</h1><h2 id="partial-matching-table">Partial Matching Table</h2><ul><li>Following the intuition of <strong>skipping impossiblematching</strong>, we need to find a mechanism to decide which onesshould be skipped. The KMP algorithm proposed a structure called<strong>partial matching table</strong>, which stores the information weneed.<ul><li>The partial matching table has the same length as the patternstring, denoted as <code>next[]</code>. Given the length of<code>P</code> is <code>n</code>, <code>next[i]</code> represents<ul><li>If <strong>substring</strong> <code>p[0..i]</code> has a pair ofidentical prefix and suffix (<code>p[0..k-1] == p[i-(k-1),..i]</code>),then <code>next[i] = k</code></li><li>For example<ul><li>for the pattern string <code>abcabcd</code>,we have<code>next[i] = [0,0,0,1,2,3,0]</code>. When <code>i = 5</code>, thestring is <code>abcabc</code>, therefore we could get identical pair<code>abc</code>, where the length is <code>3</code></li></ul></li></ul></li></ul></li><li>You may have noticed, with <code>next[]</code> array calculated, wecould skip impossible matchings by referencing the <code>next[]</code>array. As shown in below example<ul><li><figure><img src="https://s2.loli.net/2023/02/10/XxyiPhSFUrsYJpe.png"alt="image.png" /><figcaption aria-hidden="true">image.png</figcaption></figure></li><li><p>When we failed the first match at <code>P[3]</code>, we replacethe <code>P[1]</code> on the mismatched index and restart the matching.When failed the second match at <code>P[6]</code>, we replace<code>P[3]</code> on the mismatched index.</p></li><li><p>From above we could conclude, we utilize the identical prefix andsuffix for skipping some comparisons. Say the mismatch occurs at<code>P[i]</code>, then between <code>P[0]~P[i-1]</code>, the former<code>next[i-1]</code> character(s) should be the same as the latter<code>next[i-1]</code> character(s), so we could replace the suffix withthe prefix. In conclusion, we could realign <code>P[next[i-1]]</code>with <code>P[i]</code>.</p></li><li><p>In other word, the <code>next[]</code> array provides referencefor how to skip comparison and how many comparison to skip.<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Suppose we have calculated the next[] array</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">search</span>():<br>  s_pointer = <span class="hljs-number">0</span><br>  p_pointer = <span class="hljs-number">0</span><br>  <br>  <span class="hljs-keyword">while</span> s_pointer &lt; <span class="hljs-built_in">len</span>(s):<br>    <span class="hljs-keyword">if</span> s[s_pointer] == p[p_pointer]: <span class="hljs-comment"># If matched, increment both pointers</span><br>      s_pointer += <span class="hljs-number">1</span><br>      p_pointer += <span class="hljs-number">1</span><br>    <span class="hljs-keyword">elif</span> p_pointer: <span class="hljs-comment"># mismatched at p[p_pointer], move p_pointer</span><br>      p_pointer = <span class="hljs-built_in">next</span>[p_pointer-<span class="hljs-number">1</span>]<br>    <span class="hljs-keyword">else</span>:<span class="hljs-comment"># mismatcher at p[0]</span><br>      s_pointer += <span class="hljs-number">1</span><br>      <br>    <span class="hljs-keyword">if</span> p_pointer == <span class="hljs-built_in">len</span>(p):<br>      <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;The matching start point is <span class="hljs-subst">&#123;s_pointer - p_pointer&#125;</span>&#x27;</span>)<br>      p_pointer = <span class="hljs-built_in">next</span>[p_pointer - <span class="hljs-number">1</span>]<br>      <br></code></pre></td></tr></table></figure></p></li><li><p>How to analysis the complexity of this step?</p><ul><li>We could use amortized analysis, the <code>s_pointer</code> couldincrement at most <code>len(s)</code> times, therefore the timecomplexity is <span class="math inline">\(O(n)\)</span>.</li></ul></li></ul></li></ul><h2 id="calculating-partial-matching-table">Calculating Partial MatchingTable</h2><ul><li><p>Now we have drawn the overall picture of KMP algorithm. The onlyproblem remained is how to calculate the <code>next[]</code>array.</p></li><li><p>An easy way to come up with: <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">calNext</span>(<span class="hljs-params">x</span>):<br>  <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(x, <span class="hljs-number">0</span>, -<span class="hljs-number">1</span>):<br>    <span class="hljs-keyword">if</span> p[<span class="hljs-number">0</span>:i] == p[x+<span class="hljs-number">1</span>-i : x+<span class="hljs-number">1</span>]: <span class="hljs-comment"># Note that p[0..x] has length x+1</span><br>      <span class="hljs-keyword">return</span> i<br>  <span class="hljs-keyword">return</span> <span class="hljs-number">0</span><br><br><span class="hljs-built_in">next</span> = [calNext(x) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(p))]<br></code></pre></td></tr></table></figure></p><ul><li>However, the complexity of algorithm is <spanclass="math inline">\(O(m^2)\)</span>, as for each entry <code>x</code>, we perform <code>x</code> times check.</li></ul></li><li><p>An optimized way, consider using <strong>recursion</strong>.</p><ul><li>Suppose we already know <code>next[x-1]</code>, we want to calculate<code>next[x]</code><ul><li>if <code>P[x] == P[next[x-1]]</code> --&gt;<code>next[x] = next[x-1] + 1</code></li><li>if <code>P[x] != P[next[x-1]]</code><ul><li><p>To simply, we denote <code>next[x-1]</code> as<code>pre</code></p></li><li><figure><img src="https://s2.loli.net/2023/02/10/E7Wgry2QIAKLamq.png"alt="image.png" /><figcaption aria-hidden="true">image.png</figcaption></figure></li><li><p>When this two character does not match, we should shorten the<code>pre</code> and try the match again. We could utilize the propertyof <code>next[]</code> array - <code>P[0]~P[pre - 1]</code>(<code>A</code>) is <strong>identical to</strong><code>P[x - pre] ~ P[x-1]</code> (<code>B</code>).</p></li><li><p>To shorten <code>pre</code>, we need to find the a<code>k</code>, which maximizes the length, where<code>prefix(A,k) == suffix(B,k)</code>.</p></li><li><p>Remember <code>A</code> and <code>B</code> is identical, then wetransform the problem to find the longest common prefix and suffix of<code>A</code>! which is exactly <code>next[pre-1]</code>.</p></li><li><figure><img src="https://s2.loli.net/2023/02/10/RtKNxSHg65wOWp4.png"alt="image.png" /><figcaption aria-hidden="true">image.png</figcaption></figure></li><li><p>Therefore we conclude: Iterate <code>pre = next[pre-1]</code>,until <code>P[next[x-1]] == P[x]</code> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-built_in">next</span> = []<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">calNext</span>():<br>  <span class="hljs-built_in">next</span>.append(<span class="hljs-number">0</span>)<span class="hljs-comment"># Base case</span><br>  x = <span class="hljs-number">1</span><br>  pre = <span class="hljs-number">0</span><br>  <br>  <span class="hljs-keyword">while</span> x &lt; <span class="hljs-built_in">len</span>(p):<br>    <span class="hljs-keyword">if</span> p[pre] == p[x]: <br>      pre += <span class="hljs-number">1</span><br>      x += <span class="hljs-number">1</span><br>    <span class="hljs-keyword">elif</span> pre:<br>      pre = <span class="hljs-built_in">next</span>[pre-<span class="hljs-number">1</span>]<br>    <span class="hljs-keyword">else</span>:<br>      <span class="hljs-built_in">next</span>.append(<span class="hljs-number">0</span>)<br>      x += <span class="hljs-number">1</span><br></code></pre></td></tr></table></figure></p></li><li><p>We could find the code looks similar to the one developedearlier. It is because they actually share the same essence.<code>search()</code> method perform string matching between<code>S</code> and <code>P</code>, where <code>calNext()</code> performstring matching between <code>P</code> and <code>P</code>!</p></li><li><p>Similar to previous algorithm, the time complexity is <spanclass="math inline">\(O(m)\)</span>.</p></li></ul></li></ul></li></ul></li><li><p>In conclusion, we conquer the string matching problem with timecomplexity <span class="math inline">\(O(m+n)\)</span>!</p></li><li><p>Salute to the designers of this algorithm: <ahref="https://en.wikipedia.org/wiki/Donald_Knuth">DonaldKnuth</a>(K), <ahref="https://en.wikipedia.org/wiki/James_H._Morris">James H.Morris</a>(M), <ahref="https://en.wikipedia.org/wiki/Vaughan_Pratt">VaughanPratt</a>(P).</p></li></ul><h1 id="references">References</h1><ul><li><ahref="https://www.zhihu.com/question/21923021/answer/1032665486">ChineseExplanation of this Algorithm</a></li><li><ahref="https://en.wikipedia.org/wiki/Knuth%E2%80%93Morris%E2%80%93Pratt_algorithm">KMPalgorithm - WikiPedia</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>Computer Science</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Algorithm</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Knowledge Graph, An Introduction</title>
    <link href="/2023/02/02/Knowledge-Graph-An-Introduction/"/>
    <url>/2023/02/02/Knowledge-Graph-An-Introduction/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><p>In this post, I would provide an introduction to Knowledge graph,provide information about its definition, construction, storage andapplication.</p><span id="more"></span><h2 id="definition">Definition</h2><h3 id="what-is-knowledge-graph-kg">What is Knowledge Graph (KG)?</h3><ul><li>Knowledge graph is a symbolic, structured semantic network used tostore entities and their relations.</li></ul><h3 id="basic-components">Basic Components</h3><ul><li>Entity<ul><li>The node in knowledge graph. Used to represent people, events orthings.<br /></li></ul></li><li>Relation<ul><li>The edge in knowledge graph. Used to represent relations betweendefined entities.<br /></li></ul></li><li>Property<ul><li>Additional information attached to node or relation.</li></ul></li></ul><h3 id="examples">Examples</h3><p>Based on different context, entity and relations could be varied.Below are three examples for possible designs.</p><h4 id="medical-kg">Medical KG</h4><ul><li>Entity - Disease, Drug, Food, Cure method, Department<br /></li><li>Relation<ul><li>Disease --[recommend_use]--&gt; drug<br /></li><li>Disease --[recommend_eat]--&gt; food<br /></li><li>Disease --[accompany_with]--&gt; Disease<br /></li></ul></li><li>Property<ul><li>Disease - cause, cure_last_time, susceptible_groups,...</li></ul></li></ul><h4 id="financial-kg">Financial KG</h4><ul><li>Entity - Company, Person (Management), Fund, Industry<br /></li><li>Relation<ul><li>Company --[has_manager]--&gt; Person<br /></li><li>Company --[in_industry]--&gt; Industry</li></ul></li></ul><h4 id="user-profile-kg">User Profile KG</h4><ul><li>Entity - User, Event (could be further divided to differentcategories based on user's interaction / data gathered), Company<br /></li><li>Relation<ul><li>User --[is_friend | is_lover]--&gt; User<br /></li><li>Event --[]--&gt; User<br /></li><li>User --[work_for]--&gt; Company<br /></li><li>Property<ul><li>User - name, gender, occupation, preferences<br /></li><li>Event - name, type, start/end_time, type_specific_information</li></ul></li></ul></li></ul><h2 id="construction">Construction</h2><h3 id="data-access">Data Access</h3><ul><li>Use open-source data or web-crawlers.</li></ul><h3 id="information-retrieval">Information Retrieval</h3><ul><li>Used for processing unstructured / semi-structured data byextracting useful information via NLP methods, which includes:<ul><li>Sentence segmentation<br /></li><li>Tokenization<br /></li><li>Part Of Speech (POS) tagging<br /></li><li>Named Entity Recognition<br /></li><li>Relation Retrieval</li></ul></li></ul><h3 id="knowledge-fusion">Knowledge Fusion</h3><ul><li>Used for intergrate incoming data and existing knowldge graph.</li></ul><p>Knowledge retrieved may contain inaccurate or redundant information,Coreference Resolution (to solve ambiguity brought by pronouns) andEntity Disambiguation (combine aliases for one thing) could be used toimprove the quality of knowledge map.</p><h3 id="knowledge-process">Knowledge Process</h3><ul><li>Used for discovering new relations.<ul><li>E.g. User Profile KG, users with identical properties may sharesimilar preferences.</li></ul></li></ul><p>The technology involed is called Knowledge Inference, which could beimplemented using logic / graph algorithm / deep learning.</p><h2 id="storage">Storage</h2><ul><li><p>RDF (Resource Description Framework)</p><ul><li><p>Text format, easy modification, poor readability<br /></p></li><li><p>A glimpse of RDF file (from <ahref="https://github.com/Ebiquity/uco2">this repo</a>):</p><p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><code class="hljs xml"><span class="hljs-meta">&lt;?xml version=<span class="hljs-string">&quot;1.0&quot;</span>?&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">rdf:RDF</span></span><br><span class="hljs-tag">    <span class="hljs-attr">xmlns:rdf</span>=<span class="hljs-string">&quot;http://www.w3.org/1999/02/22-rdf-syntax-ns#&quot;</span></span><br><span class="hljs-tag">    <span class="hljs-attr">xmlns:owl</span>=<span class="hljs-string">&quot;http://www.w3.org/2002/07/owl#&quot;</span></span><br><span class="hljs-tag">    <span class="hljs-attr">xmlns:asset</span>=<span class="hljs-string">&quot;http://www.daedafusion.com/Asset#&quot;</span></span><br><span class="hljs-tag">    <span class="hljs-attr">xmlns:xsd</span>=<span class="hljs-string">&quot;http://www.w3.org/2001/XMLSchema#&quot;</span></span><br><span class="hljs-tag">    <span class="hljs-attr">xmlns:edt</span>=<span class="hljs-string">&quot;http://www.daedafusion.com/editor_annotation#&quot;</span></span><br><span class="hljs-tag">    <span class="hljs-attr">xmlns:rdfs</span>=<span class="hljs-string">&quot;http://www.w3.org/2000/01/rdf-schema#&quot;</span></span><br><span class="hljs-tag">  <span class="hljs-attr">xml:base</span>=<span class="hljs-string">&quot;http://www.daedafusion.com/Asset&quot;</span>&gt;</span><br>  <span class="hljs-tag">&lt;<span class="hljs-name">owl:Ontology</span> <span class="hljs-attr">rdf:about</span>=<span class="hljs-string">&quot;&quot;</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">owl:imports</span> <span class="hljs-attr">rdf:resource</span>=<span class="hljs-string">&quot;http://www.daedafusion.com/editor_annotation&quot;</span>/&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">rdfs:label</span> <span class="hljs-attr">xml:lang</span>=<span class="hljs-string">&quot;en-US&quot;</span>&gt;</span>ARGOS Asset Ontology<span class="hljs-tag">&lt;/<span class="hljs-name">rdfs:label</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">rdfs:comment</span> <span class="hljs-attr">xml:lang</span>=<span class="hljs-string">&quot;en-US&quot;</span>&gt;</span>Editor Annotation ontology defines a set of annotations that provide a graphical editor information about how to create corresponding IRI&#x27;s for new instances created along with information that is used to control how properties appear in the editor. <br><br>Copyright (c) 2014, DaedaFusion, LLC.  All rights reserved.<span class="hljs-tag">&lt;/<span class="hljs-name">rdfs:comment</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">owl:versionInfo</span> <span class="hljs-attr">rdf:datatype</span>=<span class="hljs-string">&quot;http://www.w3.org/2001/XMLSchema#string&quot;</span></span><br><span class="hljs-tag">    &gt;</span>1.0.0.0<span class="hljs-tag">&lt;/<span class="hljs-name">owl:versionInfo</span>&gt;</span><br>  <span class="hljs-tag">&lt;/<span class="hljs-name">owl:Ontology</span>&gt;</span><br>  <span class="hljs-tag">&lt;<span class="hljs-name">owl:Class</span> <span class="hljs-attr">rdf:ID</span>=<span class="hljs-string">&quot;Asset&quot;</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">rdfs:subClassOf</span>&gt;</span><br>      <span class="hljs-tag">&lt;<span class="hljs-name">owl:Restriction</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">owl:cardinality</span> <span class="hljs-attr">rdf:datatype</span>=<span class="hljs-string">&quot;http://www.w3.org/2001/XMLSchema#nonNegativeInteger&quot;</span></span><br><span class="hljs-tag">        &gt;</span>1<span class="hljs-tag">&lt;/<span class="hljs-name">owl:cardinality</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">owl:onProperty</span>&gt;</span><br>          <span class="hljs-tag">&lt;<span class="hljs-name">owl:DatatypeProperty</span> <span class="hljs-attr">rdf:ID</span>=<span class="hljs-string">&quot;mimeType&quot;</span>/&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">owl:onProperty</span>&gt;</span><br>      <span class="hljs-tag">&lt;/<span class="hljs-name">owl:Restriction</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">rdfs:subClassOf</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">rdfs:comment</span> <span class="hljs-attr">xml:lang</span>=<span class="hljs-string">&quot;en-US&quot;</span>&gt;</span>Characterizes a digital asset<span class="hljs-tag">&lt;/<span class="hljs-name">rdfs:comment</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">rdfs:label</span> <span class="hljs-attr">xml:lang</span>=<span class="hljs-string">&quot;en-US&quot;</span>&gt;</span>Asset<span class="hljs-tag">&lt;/<span class="hljs-name">rdfs:label</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">rdfs:subClassOf</span> <span class="hljs-attr">rdf:resource</span>=<span class="hljs-string">&quot;http://www.w3.org/2002/07/owl#Thing&quot;</span>/&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">edt:namespacePrefix</span> <span class="hljs-attr">rdf:datatype</span>=<span class="hljs-string">&quot;http://www.w3.org/2001/XMLSchema#string&quot;</span></span><br><span class="hljs-tag">    &gt;</span>argos<span class="hljs-tag">&lt;/<span class="hljs-name">edt:namespacePrefix</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">rdfs:isDefinedBy</span> <span class="hljs-attr">rdf:resource</span>=<span class="hljs-string">&quot;&quot;</span>/&gt;</span><br>  <span class="hljs-tag">&lt;/<span class="hljs-name">owl:Class</span>&gt;</span><br>  <span class="hljs-tag">&lt;<span class="hljs-name">owl:ObjectProperty</span> <span class="hljs-attr">rdf:about</span>=<span class="hljs-string">&quot;#locatorURI&quot;</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">rdfs:comment</span> <span class="hljs-attr">xml:lang</span>=<span class="hljs-string">&quot;en-US&quot;</span>&gt;</span>Specifies the location from where the asset was ingested<span class="hljs-tag">&lt;/<span class="hljs-name">rdfs:comment</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">edt:namespacePrefix</span> <span class="hljs-attr">rdf:datatype</span>=<span class="hljs-string">&quot;http://www.w3.org/2001/XMLSchema#string&quot;</span></span><br><span class="hljs-tag">    &gt;</span>argos<span class="hljs-tag">&lt;/<span class="hljs-name">edt:namespacePrefix</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">rdfs:label</span> <span class="hljs-attr">xml:lang</span>=<span class="hljs-string">&quot;en-US&quot;</span>&gt;</span>Location URI<span class="hljs-tag">&lt;/<span class="hljs-name">rdfs:label</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">rdfs:domain</span> <span class="hljs-attr">rdf:resource</span>=<span class="hljs-string">&quot;#Asset&quot;</span>/&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">rdfs:isDefinedBy</span> <span class="hljs-attr">rdf:resource</span>=<span class="hljs-string">&quot;&quot;</span>/&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">rdfs:range</span> <span class="hljs-attr">rdf:resource</span>=<span class="hljs-string">&quot;http://www.w3.org/2002/07/owl#Thing&quot;</span>/&gt;</span><br>  <span class="hljs-tag">&lt;/<span class="hljs-name">owl:ObjectProperty</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">rdf:RDF</span>&gt;</span><br></code></pre></td></tr></table></figure></p></li></ul></li><li><p>Graph Database - A more common practice</p><ul><li>Database format, Cypher modification, Good readability &amp;usability</li></ul><p><img src="https://s2.loli.net/2023/02/02/BXbT3knwVClKoJE.jpg" alt="Guide: Example Datasets - Developer Guides" style="zoom: 33%;" /></p></li></ul><h2 id="applications">Applications</h2><ul><li><p>Search Engine / (KG)QA system</p><ul><li><p>QA system, query KG to find answers for a problem</p></li><li><p>Google's example, answer combined with KG (the left card)</p><figure><img src="https://s2.loli.net/2023/02/02/BLx7HoKfa1ZAWJu.png"alt="image-20230202220041875" /><figcaption aria-hidden="true">image-20230202220041875</figcaption></figure></li></ul></li><li><p>Conversational AI</p></li></ul><h2 id="resources">Resources</h2><ul><li><a href="https://github.com/totogo/awesome-knowledge-graph">GithubRepo - awesome-kg</a></li><li><a href="http://openkg.cn/home">Chinese KnowledgeGraph-OpenKG</a></li></ul><h2 id="general-evaluations">General Evaluations</h2><ul><li>Pros<ul><li>Little comprehension difficulty</li><li>Structured and explicit data for customized domain</li><li>Ability to support different purposes (knowledge query via KGQA,knowledge discovery via inference)</li></ul></li><li>Cons<ul><li>Difficult to migrate to other domain</li><li>Intensive data &amp; detailed process needed</li><li>As graph grows larger, efficiency may become a problem</li></ul></li></ul><h2 id="references">References</h2><ul><li><a href="https://en.wikipedia.org/wiki/Knowledge_graph">WikiPedia -Knowledge Graph</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>Computer Science</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Artificial Intelligence</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Introduction to ZettleKasten - Your Personal Knowledge Management System</title>
    <link href="/2022/12/07/Introduction-to-ZettleKasten-Managing-your-note-and-knowledge/"/>
    <url>/2022/12/07/Introduction-to-ZettleKasten-Managing-your-note-and-knowledge/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><p>In this post, I would provide a detailed introduction to ZettleKastenmethod, which I have been applying since I read the book <em>How to takesmart notes</em>.</p><span id="more"></span><h1 id="a-quick-overview---what-is-zettlekasten">A quick overview - Whatis ZettleKasten?</h1><p>ZettleKasten is a note taking and personal knowledge managementsystem, consists of basic component called 'Zettle'.</p><p>Zettel is the German word for a small piece of paper or a note. Itcan also refer to a brief written summary or an outline of a topic. Itis often used in the context of taking notes, making lists, ororganizing ideas. Suggestions about how to write structure and contentfor a Zettle is included in the third section.</p><p>This system, first adopted by the German sociologist and philosopherLuhmann, is centered on the idea of constructing a web of notes (alsonamed Zettles) as a way to promote more flexible interdisciplinarythinking.</p><p>This note-taking method is widely applied in different scenarios:academic research, writing, personal productivity improvement andcreative work.</p><h2 id="advantages-of-zettlekasten">Advantages of ZettleKasten</h2><p>Organizing notes in files + folders can lead to a <strong>rigid notestructure</strong> that makes it difficult to keep track of theinterrelationships between knowledge points.</p><p>Organizing notes in tabbed form (tags) is less practical with limitedcontent to see at one time.</p><p>A better way to organize notes and thoughts -- use a mesh structureto organize (as emphasized in ZettleKasten), relying not only on tags,but also on links to different Zettles.</p><p>More advantages are listed below:</p><ul><li><p>Better preservation and recall of information and knowledge witha unified structure.</p></li><li><p>Access to information and links between different topics, enoughto quickly find and use the knowledge and ideas contained inZettle.</p></li><li><p>Increase productivity and creativity by easily organizing andaccessing their knowledge and ideas, enabling flexible, dynamicthinking.</p></li><li><p>Can be integrated with other productivity tools, such as taskmanagement or time tracking software (Detail would be discussed inanother post coming soon)</p></li><li><p>Accumulating Zettles with similar structures could realize theCompound Interest effect for your personal knowledge.</p></li></ul><h1 id="features-of-zettlekasten">Features of ZettleKasten</h1><ul><li><p>Zettle (card) is smallest unit of the system.</p><ul><li>These Zettle include small ideas, notes that can be easily created,organized, and linked.</li></ul></li><li><p>Each Zettle uses a unique identifier that can help with theorganization and access of notes.</p><ul><li>Unique identifiers can use ID-like numbers + characters or be thekeywords/summary of the note's topic based on your choice.</li></ul></li><li><p>Emphasis is placed on <strong>creating links</strong> betweennotes and creating a web-like structure.</p></li><li><p>Review and update Zettle regularly to</p><ul><li><p>prevent ZettleKasten from progressing to linearstructures</p></li><li><p>guide the study/research to fill the gap/missing concept in yoursystem</p></li><li><p>spot links between different topics</p></li></ul></li></ul><h1 id="how-to-implement---principles-and-discussions">How to implement- principles and discussions</h1><h2 id="choice-of-software">Choice of Software</h2><p>There are a bunch of note taking apps which supports<em>wiki-links</em> or <em>bi-directional links</em>. Discussing thepros and cons of each of the listed software is beyond the scope of thispost. If you are interested in a detailed comparison of these apps,please leave a comment.</p><p>Typical Tools that are made for ZettleKasten:</p><ul><li><p><a href="https://roamresearch.com/">Roam Research</a></p></li><li><p><a href="https://obsidian.md/">Obsidian</a></p></li><li><p><a href="https://logseq.com/">LogSeq</a></p></li><li><p><a href="https://www.notion.so/">Notion</a></p></li><li><p><a href="https://www.zettlr.com/">Zettlr</a></p></li><li><p><ahref="https://github.com/siyuan-note/siyuan">Siyuan</a></p></li><li><p>...</p></li></ul><p>I personally recommend <strong>Obsidian</strong>, with its highlycustomizable plugins, rich forum and active community. If you prefer towork in a outline mode (like WorkFlowy), then LogSeq / Roam Research mayserve you well.</p><h2 id="how-to-write-zettle">How to write Zettle?</h2><p>As the basic component of ZettleKasten system, it is crucial tofollow a uniform format and some principles when keeping Zettles forlater note connection.</p><h3 id="principles">Principles</h3><p>Generally, A Zettle is a concept with a name that is as short andrecognizable as possible.Take bricks as example, good zettle should playthe same role as bricks when building your knowledge palace.</p><p>The Zettles should be:</p><p><strong>Spliceable</strong> - single block, one thing/concept at atime</p><ul><li>To achieve this, a good way is to check if you could find a concisetitle to summarise your zettle.</li><li>According to <em>How to take smart notes</em>, context is importantwhen understanding a concept. It is therefore a good practice to include(either by text or links to relevant zettles) sufficient backgroundinformation to explain this zettle’s concept.</li></ul><p><strong>Reusable</strong> - complete block, contain sufficientinformation to understand the concept itself</p><ul><li><p>This is complementary to the former principle, whereself-explainable Zettles allows you to create more complexsystem.</p></li><li><p>In practice, achieving this is often linked with</p><ul><li><p>formatting your notes’ meta data, containing the tags, creation,alias of your zettle.</p></li><li><p>naming your notes with recallable and distinguishable keywordscould also be helpful.</p></li></ul></li></ul><p><strong>Tractable</strong> - record the source of notes</p><ul><li>This means that you don't need to copy and paste the originalcontent; if you forget anything, you can go back to the source ofknowledge and review it.</li></ul><h3 id="different-types-of-zettles">Different Types of Zettles</h3><p>To help organizing and accessing notes, together with laterunderstanding and exploration of different concepts, Zettles could becategorized into <strong>3</strong> main types (as suggested in <em>Howto take smart notes</em>):</p><ol type="1"><li><p>Flash Notes</p><ul><li>Where you kept your ephemeral thoughts and review them on a dailybasis and merge them into your ZettleKasten where the below two types ofnotes belong.</li></ul></li><li><p>Literature Notes</p><ul><li>Where you kept your summary/paraphrase of the literature togetherwith <strong>link to original source</strong>. This is the bridge ofexternal source/knowledge with your own ZettleKasten/Knowledgesystem.</li></ul></li><li><p>Permanent Notes</p><ul><li>Where you kept your thoughts, your understanding of certain conceptsin your interested field.</li></ul></li></ol><p>There could be auxiliary type of notes called:</p><ol start="4" type="1"><li><p>Index Notes (Map Of Content, MOC)</p><ul><li>Where you keep track of a collection of note links on a topic or anarea to help you view the big picture.</li></ul></li></ol><p>The type of notes is not exclusive, you could use any numebr of typesas you like as long as it serves well for organizing and accessingzettles in your ZettleKasten system.</p><p>In mainstream double-linked note-taking Apps, metadata editing in theform of Frontmatter, etc. is supported. Categorization is possible byadding custom <code>category</code> entries, or by using different<mark>tag</mark>.</p><h2 id="creating-links-between-zettles">Creating links betweenzettles</h2><p>This is a crucial step when constructing your ZettleKasten System. Itis the <mark>mesh structure</mark> between Zettles that makeZettleKasten method stands out among other note taking/organizingmethods.</p><p>Following the Splicable principle, you could easily create links likein Wikipedia. Empty links (suggesting unknown concepts, unreadliteratures, etc.) could also be created to guide your furtherresearch.</p><p>Following the Reusable principle, you could split long notes intosmaller chunks. The ways of splitting notes varies, you could eithercreate a new note and attach the link to the original long note, orsimply use different headings to parse the note and refer to the blocklink (supported by most apps) later on. There are no strict rules forhow long a zettle should be, as long as it is recallable for you.</p><h2 id="regular-review">Regular review</h2><p>Review your notes on a regular basis is a fantastic way to keep youimprove. It is well studied that spaced repetition could help youremember things longer and clearer. Besides, review your note could alsoallow the discover of links between different zettles, and guide yourlater research or study.</p><p>As for spaced repetition, it is better used with <ahref="https://apps.ankiweb.net/">Anki</a>, which also takes in theformat of zettles, and has built in algorithm to help you review.</p><h1 id="workflow">Workflow</h1><p>ZettleKasten System could be integrated with multiple systems,include Task Management, Note taking and Writing. There arecorresponding workflows for each.</p><ul><li>Integrate with Task Management<ul><li>Usually the tasks embeds in your Flash Notes, where somethingtriggered your intention for something.</li><li>It is recommended to have a regular review process to capture allyour tasks into your task management system.<ul><li>Or you could simply use features from task management apps tocapture them in a separate inbox.</li></ul></li></ul></li><li>Integrate with Note taking<ul><li>Basically your notes will be generated from processing differentsource of input information. Though you may encounter different mediums,the basic principle is similar.</li><li>I have come up with the following workflow for processingliteratures and notes.<ol type="1"><li>Highlight key points while reading</li><li>Transfer all highlights (together with link to the original source)to a note.<ul><li>This feature could be achieved easily in Logseq without muchconfiguration.</li></ul></li><li>Create a literature note, paraphrasing highlights. Remember toinclude context to make it self-explainable.</li><li>If possible, split the literature note into smaller Zettles withatomic concepts.<ul><li>For example, in a paper <ahref="http://arxiv.org/abs/2005.00329">CDL: Curriculum Dual Learning forEmotion-Controllable Response Generation</a> which I read recently, Icreated notes on concept Curriculum Learning, Dual Learning andReinforcement Learning from the original literature note.</li></ul></li><li>Link them with current permanent notes if meaningful links exist.<ul><li>I have already created notes about different Natural LanguageGeneration metrics like BLEU, so I would link these two notes. With morepapers read, important concepts would arise naturally.</li></ul></li><li>Review important cards on a regular basis using spacedrepetition.</li></ol></li></ul></li><li>Integrate with Writing<ul><li>Writing is the time where you utilise your atomic notes to build acomprehensive view over some topic.</li><li>For more advices on how to integrate ZettleKasten System withwriting, please check the <ahref="https://www.amazon.com/How-Take-Smart-Notes-Nonfiction/dp/1542866502">Book- How to take smart notes - Sönke Ahrens</a></li></ul></li></ul><h1 id="further-reference-resources">Further reference resources</h1><ul><li><ahref="https://karl-voit.at/2020/06/14/Zettelkasten-concerns/">Blog PostZettelkasten-concerns - Public voiT</a><ul><li>The author presents a detailed comparison between org-mode andZettleKasten method, proposing some difficulties faced when usingZettleKasten methods. You could find some valuable insights about whicharea is not ZettleKasten appropriate for.</li></ul></li><li><ahref="https://www.amazon.com/How-Take-Smart-Notes-Nonfiction/dp/1542866502">Book- How to take smart notes - Sönke Ahrens</a><ul><li>Besides providing introdution of ZettleKasten methods, this bookprovide detailed explaination on how to integrate the ZettleKastenmethods with academic writing.</li></ul></li></ul>]]></content>
    
    
    <categories>
      
      <category>Informal Essays</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Methodology</tag>
      
      <tag>PersonalKnowledgeManagement</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Literature Note - Transformer</title>
    <link href="/2022/11/10/Literature-Note-Transformer/"/>
    <url>/2022/11/10/Literature-Note-Transformer/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><p>In this post, I would summarize key points from classic paper <ahref="http://arxiv.org/abs/1706.03762"><Attention is all you need></a>following its initial structure.</p><span id="more"></span><blockquote><p><strong>Important Links</strong></p><ul><li><a href="http://arxiv.org/abs/1706.03762">Paper link</a></li><li><a href="https://github.com/tensorflow/tensor2tensor">Codelink</a></li></ul></blockquote><blockquote><p><strong>Acknowledgements</strong></p><p>Special thanks to Mu LI, who provides a wonderful review <ahref="https://www.bilibili.com/video/BV1pu411o7BE/">video</a> on thisarticle.</p><p>Also thanks to Lilian, for this wonderful <ahref="https://lilianweng.github.io/posts/2020-04-07-the-transformer-family/">blog</a>connecting transformer's principle &amp; applications.</p></blockquote><h2 id="abstract">0. Abstract</h2><ul><li>Paper proposes a new simple network architecture, the Transformer,based solely on attention mechanisms</li><li>State-of-the-art result on <em>machine translation tasks</em></li><li>Advantages of transformer architecture<ul><li>More parallelizable &amp; require significantly less trainingtime</li><li>Generalize well to other tasks - see BERT, GPT</li></ul></li></ul><blockquote><p><strong>Writing tips</strong></p><p>When stating equal contribution using <code>*</code>, it's goodpractice to list briefly about each member's work done.</p></blockquote><h2 id="introduction">1. Introduction</h2><blockquote><p>Basically an extension to abstract</p></blockquote><ul><li><p>Recurrent neural networks /models'</p><ul><li><p><strong>Principle</strong> Generate a sequence of hidden states<span class="math inline">\(h_t\)</span>, as a function of the previoushidden state <span class="math inline">\(h_{t−1}\)</span> and the inputfor position <span class="math inline">\(t\)</span>.</p><figure><img src="https://s2.loli.net/2022/11/24/SxYCGEHjplryNwa.png"alt="RNN-calculation-example.png" /><figcaption aria-hidden="true">RNN-calculation-example.png</figcaption></figure></li><li><p><strong>Drawbacks</strong></p><ul><li>Parallelization preclusion by calculation method</li><li>High memory requirements for preserving historical information. /Possibility in forgetting early information after step by steppassing.</li></ul></li></ul></li><li><p>Attention Mechanism</p><ul><li>An integral part of sequence &amp; transduction models.</li><li>Allow the model to capture dependencies between in/out sequenceregardless of their distance.</li><li><mark>Most of them used in conjunction with a recurrentnetwork</mark></li></ul></li><li><p>Transformer's innovation</p><ul><li>“eschewing recurrence and instead relying entirely on an attentionmechanism”</li></ul></li></ul><h2 id="background">2. Background</h2><ul><li>Introduces previous attempts to reduce sequential computation -using CNN (convolutional neural networks)<ul><li>“difficult to learn dependencies between distant positions”, betweenlong sequences</li><li>Why Multi-Head Attention (instead of single head)?<ul><li>Attention mechanism eschewed convolution mechanism, losing theopportunity to model different patterns.</li><li>Using Multi-Head Attention mechanism is to <mark>simulate themulti-channel output of CNN.</mark></li></ul></li></ul></li><li>Previous success on self-attention</li><li>End-to-end memory networks’ scope and performance</li><li>Innovation point about Transformer.</li></ul><h2 id="model-architecture">3. Model Architecture</h2><p>Follows most competitive sequence transduction models, Transformeruses an <em>encoder-decoder structure</em>, where</p><ul><li>Encoder maps input sequence to a vector-like representation formodel usage.</li><li>Decoder generates output sequence one element at a time.</li></ul><p>The model is <strong>auto-regressive</strong>, using output fromprevious moment as additional input.</p><h3 id="encoder-decoder-stacks">3.1 Encoder &amp; Decoder Stacks</h3><figure><img src="https://s2.loli.net/2022/11/24/vdOCy9T3uxVQWlw.png"alt="Transformer-Architecture-from-Paper.png" /><figcaptionaria-hidden="true">Transformer-Architecture-from-Paper.png</figcaption></figure><ul><li>Encoder - Decoder, shown in the left and right halvesrespectively.</li><li>Each layer of <strong>encoder</strong> consists of two sub-layers -a multi-head attention mechanism &amp; a MLP. The residual connection(inspired by ResNet) is used within sub-layers. The<strong>LayerNorm</strong> technique is also implemented.<ul><li><strong>LayerNorm</strong> is a different normalization method fromBatch Normalization and is more suitable with models takingvariable-length inputs (temporal sequences), reducing the impact ofdifferent batch cuts (sequence length variations) on normalization.</li><li>Generally speaking, the difference lies in the data slicingmechanism. BN slices the data according to the batch and regularizes thefeature dimensions, while LN slices the data according to the inputsamples and regularizes different features of the same sample.</li></ul></li><li>In addition to encoder, decoder adds another layer, calculate themulti-head attention over the output of the encoder. A masking mechanismis used to prevent decoder uses output after position <spanclass="math inline">\(i\)</span> to predict the position <spanclass="math inline">\(i\)</span>.</li></ul><h3 id="attention">3.2 Attention</h3><p>Attention is a mechanism that model learns to <mark>make predictionsby selectively attending</mark> to a given set ofdata.<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup></p><p>Self-attention is a type of attention mechanism where the model makesprediction for one part of a data sample using other parts of theobservation about the same sample,... it is<mark>permutation-invariant</mark>; in other words, it is an operationon sets.<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup></p><ul><li>In transformer's Encoder, Query, Key, Value are identical vectorsgenerated by the embedding layer, therefore no trainable variablesinvolved.</li></ul><p>“An attention function can be described as mapping a query and a setof key-value pairs to an output. The output is computed as a<mark>weighted sum of the values</mark>, where the weight assigned toeach value is computed by a compatibility function of the query with thecorresponding key.”</p><p>The amount of attention is quantified by learned weights and thus theoutput is usually in the form of weighted average over input (Query,Key, Value) pair.</p><h4 id="scaled-dot-product-attention">3.2.1 Scaled Dot-ProductAttention</h4><ul><li>What's Dot-Product?<ul><li>Perform matrix multiplication on queries (Q) and keys (K)embeddings.</li></ul></li><li>Why Dot-Product?<ul><li>Faster &amp; space-efficient in practice</li></ul></li></ul><blockquote><p>Another alternative for attention functions are additiveattention.</p></blockquote><ul><li>What's Scale?<ul><li>After dot-product, divide the result by <spanclass="math inline">\(\sqrt{d_k}\)</span>.</li></ul></li><li>Why scale?<ul><li>For long input sequence, apply <code>softmax</code> on the unscaleddot-product could result in <strong>Vanishing gradient</strong>.</li></ul></li></ul><p><span class="math display">\[Attention(Q,K,V) = \text{softmax}(\frac{QK^T}{\sqrt{d_k}})V\]</span></p><figure><img src="https://s2.loli.net/2022/11/24/4EAL3FWzb69QIpH.png"alt="Scaled Dot-Product Attention" /><figcaption aria-hidden="true">Scaled Dot-Product Attention</figcaption></figure><h4 id="multi-head-attention">3.2.2 Multi-Head Attention</h4><ul><li><p>What is Multi-head attention?</p><ul><li><img src="https://s2.loli.net/2022/11/24/aJTNOvFq7nfwRYP.png"alt="Multi-head attention illustration" /> <span class="math display">\[  \begin{aligned}  \text{MultiHead}(Q,K,V) = \text{Concat}(head_1,...,head_h)W^O \\  where\ head_i=\text{Attention}(QW_i^Q,KW_i^K,VW_i^V)  \end{aligned}  \]</span></li></ul></li><li><p>Why multi-head?</p><ul><li><blockquote><p>Multi-head attention allows the model to jointly attend toinformation from different representation subspaces at differentpositions</p></blockquote></li><li>Just like CNN's different convolution kernel, multi-head attentionenables the model to capture different input patterns, learning morerepresentations.</li></ul></li></ul><h4 id="applications-of-attention-in-our-model">3.2.3 Applications ofAttention in our Model</h4><ol type="1"><li>In "encoder-decoder attention" layers, the queries come from theprevious decoder layer, and the memory keys and values come from theoutput of the encoder.</li><li>The encoder contains self-attention layers</li><li>The decoder contains self-attention layers.</li></ol><h3 id="position-wise-feed-forward-networks">3.3 Position-wiseFeed-Forward Networks</h3><p>Put it in other way - it's a fully-connected feed-forward networkwith one hidden layer (MLP).</p><p>This layer applies a linear transformation (<spanclass="math inline">\(xW_1+b_1\)</span>) on input <code>x</code>, usinga ReLU activation function and then another linear transformation.</p><p>One thing to notice - the first transformation expand the inputdimension to <span class="math inline">\(2048\)</span>, and then projectit back in the second transformation. <span class="math display">\[    FFN(x) = \max(0, xW_1+b_1)W_2+b_2\]</span></p><ul><li>What is position-wise?<ul><li>the above linear transformation is applied to <mark>everyposition</mark> of the output separately and identically.</li><li>To put it in simple ways, it is applied to each word of the inputsequence, and is therefore called <strong>point-wise</strong></li></ul></li></ul><blockquote><p>Comparison between transformer &amp; RNN</p><p>Transformer extracts sequence information when applying attentionfunction, while the RNN directly passes the <spanclass="math inline">\(t-1\)</span> information to the next computingblock.</p></blockquote><h3 id="embeddings-and-softmax">3.4 Embeddings and Softmax</h3><ul><li>What's embedding?<ul><li>Embedding are a vector form of input token, used to representsemantic information.</li></ul></li></ul><p>In Transformer, embeddings are used for inputs of both encoder anddecoder. Same weight matrix are applied for these embeddings andpre-softmax linear transformation.</p><ul><li>Why multiply <span class="math inline">\(\sqrt{d_{model}}\)</span>in embedding layer?<ul><li>When learning embeddings, the L2 Norm value is applied. With theincrease of input dimension, the weight learnt would decrease.</li><li>However, this embedding needs to combine with the positionalencoding (with increasing integer number). To have roughly same scale ofvalue, <span class="math inline">\(\sqrt{d_{model}}\)</span> ismultiplied.</li></ul></li></ul><h3 id="positional-encoding">3.5 Positional Encoding</h3><p>As discussed in previous section, attention mechanism itself areoperations on sets. In other words, changing the order of encoder inputwould not affect its output.</p><p>To add sequence information, we applied "positional encoding". Intransformer, sine and cosine functions of different frequencies areused.</p><p><span class="math display">\[\begin{aligned}PE_{(pos,2i)}=&amp;sin(pos/10000^{2i/d_{model}})\\PE_{(pos,2i+1)}=&amp;cos(pos/10000^{2i/d_{model}})\\&amp;\text{where pos is position and i is dimension}\end{aligned}\]</span></p><h2 id="why-self-attention">4. Why self-attention?</h2><ul><li><p>Comparison between self-attention layers to the recurrent andconvolutional layers on seq2seq tasks.</p></li><li><p>Self attention is evaluated on three criteria (as followingcolumn):</p><ol type="1"><li><p>Computation speed</p></li><li><p>Amount of parallelizable computation (smaller <spanclass="math inline">\(O(x)\)</span> the better)</p></li><li><p>Path length of signals have to traverse in the network betweenlong range dependencies.</p><blockquote><p>“The shorter these paths between any combination of positions in theinput and output sequences, the easier it is to learn long-rangedependencies."</p></blockquote></li></ol></li></ul><table><thead><tr class="header"><th>Layer Type</th><th>Complexity per Layer</th><th>Sequential Operation</th><th>Maximum Path Length</th></tr></thead><tbody><tr class="odd"><td>Self-Attention</td><td><span class="math inline">\(O(n^2\cdot d)\)</span></td><td><span class="math inline">\(O(1)\)</span></td><td><span class="math inline">\(O(1)\)</span></td></tr><tr class="even"><td>Recurrent</td><td><span class="math inline">\(O(n\cdot d^2)\)</span></td><td><span class="math inline">\(O(n)\)</span></td><td><span class="math inline">\(O(n)\)</span></td></tr><tr class="odd"><td>Convolutional</td><td><span class="math inline">\(O(k\cdot n\cdot d^2)\)</span></td><td><span class="math inline">\(O(1)\)</span></td><td><span class="math inline">\(O(log_k(n))\)</span></td></tr><tr class="even"><td>Self-Attention(restricted)</td><td><span class="math inline">\(O(r\cdot n\cdot d)\)</span></td><td><span class="math inline">\(O(1)\)</span></td><td><span class="math inline">\(O(n/r)\)</span></td></tr></tbody></table><blockquote><p><span class="math inline">\(n\)</span> - input sequence length, <spanclass="math inline">\(d\)</span> - the representation dimensionality,<span class="math inline">\(k\)</span> - kernel width, <spanclass="math inline">\(r\)</span> - restricted neighborhood size</p></blockquote><ul><li><span class="math inline">\(n\)</span> is normally smaller than<span class="math inline">\(d\)</span>, giving self-attention advantagesin computing.</li><li><span class="math inline">\(k\)</span> is usually a small number,therefore CNN &amp; RNN has roughly same level of complexity.</li><li>Adding restriction to self-attention is a trade-off betweencapturing long range dependencies and computation speed.</li></ul><h2 id="training">5. Training</h2><p>In this section, training regime is described.</p><ul><li><p>Encode setting - byte-pair encoding</p></li><li><p>Dataset - larger WMT 2014 English-French dataset consisting of36M sentences</p></li><li><p>Batch - a set of sentence pairs with approximately 25000 sourcetokens and 25000 target tokens</p></li><li><p>Hardware - 8 NVIDIA P100 GPUs (still affordable, compared to GPT:P)</p><ul><li>TPU is implemented afterwards to facilitate transformer likecomputation (with large matrix multiplication)</li></ul></li><li><p>Time</p><ul><li>Base model - 0.4s step time,100,000 steps / 12 hours</li><li>big model - 1.0s step time, 300,000 steps / 3.5 days</li></ul></li><li><p>Optimizer</p><ul><li>Adam, <spanclass="math inline">\(\beta_1=0.9,\beta_2=0.98,\epsilon=10^{-9}\)</span></li></ul></li><li><p>Scheduling</p><ul><li><span class="math inline">\(lrate = d^{-0.5}_{model} \cdotmin(step\_num^{-0.5}, step\_ num \cdotwarmup\_steps^{-1.5})\)</span></li><li>"This corresponds to increasing the learning rate linearly for thefirst <code>warmup_steps</code> training steps, and decreasing itthereafter proportionally to the inverse square root of the step number.We used warmup_steps = 4000."</li></ul></li><li><p>Regularization</p><ul><li>Residual dropout<ul><li>output of each sub-layer, sums of the embeddings and the positionalencodings in both the encoder and decoder stacks.</li><li><span class="math inline">\(P_{drop}=0.1\)</span></li></ul></li><li>Label smoothing<ul><li>value <span class="math inline">\(\epsilon_{ls}=0.1\)</span></li><li>hurts perplexity, but improves accuracy &amp; BLUE score.</li></ul></li></ul></li></ul><h2 id="results">6. Results</h2><p>In this section, results on machine translation (English-to-German),different model architecture, English Constituency Parsing tasks aresummarized.</p><h2 id="conclusion">7. Conclusion</h2><ul><li>Transformer - "The first sequence transduction model based entirelyon attention"</li><li>Achieved a new state of the art on machine translation task</li><li>Proposing a new model architecture for handling multi modalities&amp; adapting to different downstream tasks (see more in BERT)</li></ul><div id="footnotes"><hr><div id="footnotelist"><ol><li id="fn:1"><a href="https://lilianweng.github.io/posts/2020-04-07-the-transformer-family/">TheTransformer Family | Lil'Log(lilianweng.github.io)</a><a href="#fnref:1" rev="footnote"> ↩︎</a></li></ol></div></div>]]></content>
    
    
    <categories>
      
      <category>Computer Science</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Artificial Intelligence</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>A brief history of NLP</title>
    <link href="/2022/11/08/A-brief-history-of-NLP/"/>
    <url>/2022/11/08/A-brief-history-of-NLP/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><p>In this piece of note, I will give an overview of NLP's developmenthistory, focusing on how recent neural approaches revolutionise the NLPfield.</p><span id="more"></span><p>Natural language processing could be roughly devided into 3 stagesbased on the domainance methods used.<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup></p><ul><li>Symbolic NLP</li><li>Statitical NLP</li><li>Neural NLP</li></ul><h3 id="symbolic-nlp-1950s---early-1990s">Symbolic NLP (1950s - early1990s)</h3><p>Research related to natural language processing originated roughly inthe 1950s. In the following 40 years, limited by the size of the<strong>corpus</strong> and the <strong>computing power</strong>, earlynatural language processing mainly used <strong>rule-basedmethods</strong> to deal with generic natural language phenomena throughsymbolic logic knowledge summarized by experts. Such rule systems aredifficult to be applied to solve real-world problems due to thecomplexity of natural language.</p><h3 id="statistical-nlp-1990s---2010s">Statistical NLP (1990s -2010s)</h3><p>The rapid <strong>advances in computational power and storagecapacity</strong>, as well as the increasing maturity of statisticallearning approaches, have led to the large-scale application ofcorpus-based statistical learning methods in the field of naturallanguage processing.</p><p>The advantages of this method includes fast training speed, littlerequirement for labelled data and has good performance over simpleproblems.</p><p>Meanwhile, there are obvious limitations to this method. Statisticalapproach requires transformation of the raw natural language input intoa vector form that can be processed by the machine based on empiricalrules. This expertise-dependent, manual process of transformation isknown as feature engineering (feature extraction), which istime-consuming and not compatible for different tasks.</p><h3 id="neural-nlp-present">Neural NLP (present)</h3><p>To cope with the disadvantages of feature engineering, representationlearning and deep neural network-style machine leanring methods becamewidely applied in NLP field, proposing an end-to-end solution.Representation learning allows the machine to automatiacally recognisepatterns from input which can be used for tasks like classifcation.</p><p>In 2013, Tomas Mikolov proposed <strong>word2vec</strong>method<sup id="fnref:2"><a href="#fn:2" rel="footnote">2</a></sup>,using a shallow neural network with large scale corpus, which usescontextual connection of each word to embed the semantics of the tokensinto a dense vector. This output of such method is called <strong>WordEmbedding</strong>.</p><p>This kinds of encoding methods avoid the usage of elaborate featureengineering, and it also breaks down the barriers between differenttasks, as representation learning transformes input into a similar andeasily tranferrable vector space.</p><blockquote><p>This trend of Representation Learning has spread to knowledge graphs(using Graph Embedding techniques) and recommender systems (usinguser/item Embedding techniques).</p></blockquote><p>Shortly after, the drawback of word2vec was discovered - the sameword has different meanings in different contexts, but the word vectorgiven by this encoding is unique and static. Accordingly, the model<strong>ELMo</strong> that introduces contextual Word Embedding wasborn.</p><p>In 2017, the Transformer model wasreleased<sup id="fnref:3"><a href="#fn:3" rel="footnote">3</a></sup>.Compared to ELMo-like models, the biggest breakthrough of Transformer isthat it does not use LSTM, but instead uses an <strong>attentionmechanism</strong>. This mechanism is a function that maps a query and aset of key-value pairs to an output. The values output by the attentionmechanism are weighted sums, where the weight of each value iscalculated by the function of the query and the corresponding key of thevalue.</p><blockquote><p>Some NLP researchers believe that the attention mechanism used bytransformer is a better alternative to LSTM. They believe that theattention mechanism handles long-range dependencies better than LSTM andhas a very promising application. transformer uses an encoder-decoderstructure in its architecture. The encoder and decoder are highlysimilar in structure, but not in function. The encoder consists of Nidentical encoder layers. A decoder consists of N identical decoderlayers. Both encoder and decoder layers use the attention mechanism as acore component.</p></blockquote><p>The great success of Transformer in the field of machine translationhas attracted the interest of many NLP scientists. As deep learningalgorithms evolves, their disadvantages begin to emerge - algorithmrequires massive labelled data. As the subjective natrue of congnitivetask of NLP, and the large number of tasks and domains it deals with, itis time-consuming and labor-intensive for acquiring high qualityannotated corpora. The large scale pre-trained langauge model preciselycompensate for this shortage, helping NLP to achieve a series ofbreakthroughs. On this regard, two famous models were born:Bidirectional Encoder Representations from Transformers(BERT)<sup id="fnref:4"><a href="#fn:4" rel="footnote">4</a></sup> andGenerative Pre-Traing of language model(GPT)<sup id="fnref:5"><a href="#fn:5" rel="footnote">5</a></sup>.</p><p>GPT consists entirely of the decoder layer of the transformer, whileBERT consists entirely of the encoder layer of the transformer. The goalof GPT is to generate human-like text, the goal of BERT, on the otherhand, is to provide better language representations that help achievebetter results for a wide range of downstream tasks. The BERT modelreaches an advanced level on a variety of NLP tasks and have greatlyimproved STOA on many tasks. Now BERT has derived a large family ofmodels, among which the famous ones are XL-Net, RoBERTa,ALBERT<sup id="fnref:6"><a href="#fn:6" rel="footnote">6</a></sup>,ELECTRA, ERNIE, BERT-wwm, DistillBERT, etc.</p><div id="footnotes"><hr><div id="footnotelist"><ol><li id="fn:1"><a href="https://en.wikipedia.org/wiki/Natural_language_processing#History">Naturallanguage processing#History -Wikipedia</a><a href="#fnref:1" rev="footnote"> ↩︎</a></li><li id="fn:2"><a href="https://en.wikipedia.org/wiki/Word2vec">Word2vec -Wikipedia</a><a href="#fnref:2" rev="footnote"> ↩︎</a></li><li id="fn:3"><a href="https://arxiv.org/abs/1706.03762">「1706.03762」 Attention IsAll You Need (arxiv.org)</a><a href="#fnref:3" rev="footnote"> ↩︎</a></li><li id="fn:4"><a href="https://arxiv.org/abs/1810.04805">「1810.04805」 BERT:Pre-training of Deep Bidirectional Transformers for LanguageUnderstanding (arxiv.org)</a><a href="#fnref:4" rev="footnote"> ↩︎</a></li><li id="fn:5"><a href="https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf">ImprovingLanguage Understanding by GenerativePre-Training</a><a href="#fnref:5" rev="footnote"> ↩︎</a></li><li id="fn:6"><a href="https://arxiv.org/abs/1909.11942">「1909.11942」 ALBERT: A LiteBERT for Self-supervised Learning of Language Representations(arxiv.org)</a><a href="#fnref:6" rev="footnote"> ↩︎</a></li></ol></div></div>]]></content>
    
    
    <categories>
      
      <category>Computer Science</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Artificial Intelligence</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Literature Note - BERT</title>
    <link href="/2022/09/15/Literature%20Note%20-%20BERT/"/>
    <url>/2022/09/15/Literature%20Note%20-%20BERT/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><p>In this post, I would summarize key points from classic paper <ahref="http://arxiv.org/abs/1810.04805">&lt;BERT: Pre-training of DeepBidirectional Transformers for Language Understanding&gt;</a> followingits initial structure.</p><span id="more"></span><blockquote><p>Important Links</p><ul><li><a href="http://arxiv.org/abs/1810.04805">Paper</a></li><li><a href="https://github.com/google-research/bert">OfficialCode</a></li></ul></blockquote><h2 id="abstract">0. Abstract</h2><p>Related work: GPT (Radford et al.) &amp; ELMo (Peters et al.)</p><blockquote><p>Fun fact: ELMo &amp; BERT are both character name from SesameStreet</p></blockquote><p>Difference between these two:</p><ul><li><p>GPT - use <strong>left context</strong> for predicting futureinputs &lt;-&gt; BERT - use both context</p></li><li><p>ELMo - RNN architecture, need architecture modification &lt;-&gt;BERT - Transformer Architecture, no task-specific architecturemodifications needed for downstream tasks.</p></li></ul><p>Advantages:</p><ul><li><p>Conceptually simple</p></li><li><p>Empirically powerful (on specific tasks)</p></li></ul><blockquote><p>Writing tips: State both absolute and relative performance for readerunderstanding.</p></blockquote><h2 id="introduction">1. Introduction</h2><ul><li><p>Pre-training language model in NLP area (BERT reused pre-trainingtechnique from CV area, advocating later research to follow)</p></li><li><p>Extension to Abstract para 1. Existing strategies for applyingpre-trained language representations</p><ul><li><p>Feature-based - ELMo</p></li><li><p>Fine-tuning - GPT</p></li></ul></li><li><p>Limitation on related work</p><ul><li><p>Unidirectional language models restrict pre-trainedrepresentations.</p><ul><li>GPT’s left-to-right architecture, “every token can only at- tend toprevious tokens in the self-attention layers of the Transformer”</li></ul></li></ul></li><li><p>BERT’s improvement: using bi-directional context &amp; “maskedlanguage model”</p></li><li><p>Contributions:</p><ul><li><p>Importance of bidirectional pre-training</p></li><li><p>Reducing task-specific architecture modification need</p></li><li><p><a href="https://github.com/%20google-research/bert">Open-sourceRepo</a></p></li></ul></li></ul><h2 id="related-work">2. Related Work</h2><h3 id="unsupervised-feature-based-approach">2.1 UnsupervisedFeature-based approach</h3><p>ELMo &amp; others.</p><h3 id="unsupervised-fine-tuning-approaches">2.2 UnsupervisedFine-tuning Approaches</h3><p>GPT &amp; others.</p><h3 id="transfer-learning-from-supervised-data">2.3 Transfer Learningfrom Supervised Data</h3><h2 id="bert-implementation">3. BERT (Implementation)</h2><ul><li><p>Two steps in BERT’s framework: <em>pre-training</em> and<em>fine-tuning</em>.</p><blockquote><p>Writing tips: Include a brief introduction of supplementarytechniques used. (E.g. pre-training &amp; fine-tuning here)</p></blockquote></li></ul><h4 id="model-architecture">3.0.1 <strong>Modelarchitecture</strong></h4><p>Multi-layer bidirectional Transformer encoder based on Vaswani etal.(2017) ‘s original implementation in <ahref="https://github.com/tensorflow/tensor2tensor">this repo</a>. Guidecould be found in <ahref="http://nlp.seas.harvard.edu/2018/04/03/attention.html">thisarticle</a>.</p><ul><li><p><span class="math inline">\(BERT_{BASE} \RightarrowL=12,H=768,A=12,Total\ parameters=110M\)</span></p><p>This model is designed to have the same model size as GPT oncomparison purposes.</p></li><li><p><span class="math inline">\(BERT_{LARGE} \RightarrowL=24,H=1024,A=16,Total\ parameters=340M\)</span></p><p>where,</p><ul><li><span class="math inline">\(L\)</span> - number of Transformerblocks</li><li><span class="math inline">\(H\)</span> - Hidden size</li><li><span class="math inline">\(A\)</span> - number of self-attentionheads</li></ul></li></ul><blockquote><p>In literature, bidirectional transformer is often referred to as a“Transformer encoder”</p></blockquote><h4 id="inputoutput-representations">3.0.2 Input/OutputRepresentations</h4><ul><li><p>Context</p><p>To cope with different down-stream tasks, input representation needsto unambiguously represent both a single <strong>sentence</strong> and apari of sentences in one token <strong>sequence</strong>.</p></li></ul><blockquote><h5 id="important-definitions">Important definitions</h5><ul><li>Sentence - arbitrary span of contiguous text, rather than an actuallinguistic sentence.</li><li>Sequence - input token to BERT.</li></ul></blockquote><ul><li><p>Implementation</p><p>WordPiece embeddings (Wu et al., 2016.) WordPiece embeddings cut wordinto smaller sub-sequence for low frequency words to reduce the size oftoken vocabulary.</p><p>Rules:</p><ul><li><p>First token of every sequence = <code>[CLS]</code> - Used forclassification tasks</p></li><li><p>Packing sentences</p><ul><li><p>Separate using <code>[SEP]</code> (simple mark)</p></li><li><p>Use a learned embedding - summing the token, segement andposition embeddings.</p><figure><img src="https://miro.medium.com/max/1400/0*m_kXt3uqZH9e7H4w.png"alt="BERT-paper-Figure2-BERT-input-representation" /><figcaptionaria-hidden="true">BERT-paper-Figure2-BERT-input-representation</figcaption></figure></li></ul></li></ul></li></ul><h3 id="pre-training-bert">3.1 Pre-training BERT</h3><p>BERT’s pre-training uses two <strong>unsupervised</strong> tasks</p><ul><li>Masked Language Model (MLM)</li><li>Next Sentence Prediction (NSP)</li></ul><h4 id="task-i-masked-lm">3.1.1 Task I: Masked LM</h4><ul><li><p>Intuition: Bring in contextual information (as ELMosuggests)</p></li><li><p>Task description</p><p>Mask some percentage of the input tokens at random, and then predictthose masked tokens.</p></li><li><p>Task details</p><ul><li>Mask 15% of all WordPiece tokens in each sequence at random.</li><li>To mitigate the mismatch (fine-tuning’s input has no<code>[MASK]</code> token) between pre-training &amp; fine-tuning,masked words are replaced in differently. If the <em>i</em>-th token ischosen, it is replaced with<ol type="1"><li><code>[MASK]</code> token - 80% of the time</li><li>a random token - 10% of the time (to add noise into the trainingdata)</li><li>the unchanged token - 10% of the time</li></ol></li></ul></li></ul><blockquote><p><strong>Online demo for this task</strong></p><p>Check out <ahref="https://huggingface.co/bert-base-uncased?text=The+goal+of+life+is+%5BMASK%5D.">huggingface’sonline impelmentation</a> of BERT base model.</p></blockquote><blockquote><p><strong>Task idea origin</strong></p><p>Cloze task by Taylor.</p></blockquote><h4 id="task-ii-next-sentence-prediction-nsp">3.1.2 Task II: NextSentence Prediction (NSP)</h4><ul><li><p>Intuition: capture sentence relationships for tasks like QuestionAnswering &amp; Natural Language Inference</p></li><li><p>Task description</p><p>Input two sentences A &amp; B, output a binary label indicateswhether B is the next sentence follows A.</p></li><li><p>Details</p><ul><li>Training data construction - 50-50 split of positive &amp; negativesamples.</li></ul></li></ul><h4 id="data-source">3.1.3 Data source</h4><blockquote><p>For the pre-training corpus we use the BooksCorpus (800M words) (Zhuet al., 2015) and English Wikipedia (2,500M words). For Wikipedia weextract only the text passages and ignore lists, tables, andheaders.</p></blockquote><h3 id="fine-tuning-bert">3.2 Fine-tuning BERT</h3><p>Fine-tuning BERT is the process of reorganize the input sentence intosequence to model different downstream tasks. For each task, plug in thetask-specific inputs and outpus is needed and BERT is finetunedend-to-end.</p><blockquote><p>BERT’s fine-tuning is inexpensive. All of the results in the papercan be replicated in at most 1 hour on a single Cloud TPU, or a fewhours on a GPU, starting from the exact same pre-trained model.</p></blockquote><h2 id="experiments">4. Experiments</h2><p>Introduces the way to cope with and the results on differentdown-stream tasks. For the detail of input format modification andexperiment result, please refer to the original paper.</p><ul><li>GLUE</li><li>SQuAD v1.1</li><li>SQuAD v2.0</li><li>SWAG</li></ul><h2 id="ablation-studies">5. Ablation Studies</h2><p>In this section, ablation experiemnt over pre-training tasks, modelsize and feature-based approach are performed.</p><p>In summary, the ablation study shows</p><ul><li>all proposed pre-training tasks are necessary for improving themodel’s performance.</li><li>Increasing the model size coudl lead to continual improvements onlarge-scale tasks.</li><li>Extracting fixed features from pre-trained model experiment resultdemonstrates BERT is effective for both fine-tuning &amp; feature basedapproach</li></ul><blockquote><p>Research tips: It is good practice to perform ablation studies to addexplainability to large scale models with different components.#Area/Research</p></blockquote><h2 id="conclusion">6. Conclusion</h2><ul><li><p>Rich, unsupervised pre-training is crucial for languageunderstanding.</p></li><li><p>Major contribution: “further generalizing these findings to deep<em>bidirectional</em> architectures, allowing the same pre-trainedmodel to successfully tackle a broad set of NLP tasks.”</p></li><li><p>Limitation: Constrain on generation tasks as bidirectional.</p></li></ul><h2 id="reflect">Reflect</h2><ol type="1"><li>Which two former work does BERT mainly refer to? What’s theadvantage(s) of each prior work? What is BERT’s maincontribution/innovation compared to those work?</li><li>Which two kinds of tasks is BERT divided into?</li><li>Which two kinds of tasks is BERT’s pre-training divided into? What’sthe effect of each task?</li><li>What is the advantage and disadvantage of BERT?</li></ol>]]></content>
    
    
    <categories>
      
      <category>Computer Science</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Artificial Intelligence</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Embrace the Information Era</title>
    <link href="/2022/03/13/Embrace%20the%20Information%20Era/"/>
    <url>/2022/03/13/Embrace%20the%20Information%20Era/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><p>Though it may sound strange, I wanted to record some of myrealizations regarding how to deal with the massive incoming informationand how to gain &amp; use information effectively. <span id="more"></span></p><p>When I talk about Information Era, I am <strong>NOT</strong>referring to the time when information technology explodes, but afterthat, when we are overwhelmed by massive information generated byvarious medias or even AI. According to relevant study, modern citizenspercieve one million times more information than citizens back in 1000A.D. The development of all medium and the widespread of personalcomputer contributes to the astonishing increase of informationavailable. Therefore, I would like to focus on this aspect anddemonstrate my understanding and methodology.</p><h2 id="understanding-of-information-era">Understanding of Informationera</h2><h3 id="what-is-information">What is information?</h3><blockquote><p>Information is from which <strong>data</strong> and<strong>knowledge</strong> can be derived, as data represents valuesattributed to parameters, and knowledge represents understanding of realthings or abstract concepts.</p></blockquote><p>In personal management perspective, a lot of topics is in essenceinformation management.</p><ul><li>For task / project management, task is a piece of information withits description, due dates and other meta data; project is a group offiles/materials and tasks.</li><li>For knowledge management, it is concered with keeping your ideas,formal essays and literatures.</li></ul><h3 id="characteristic-of-information">Characteristic ofinformation</h3><ol type="1"><li><p>Information is <strong>infinite</strong>,<strong>quickly-updated</strong></p><p>Compare to the limited time and effort each individual possess, themassive information generated each day and accumulated in the past seemsinfinite.</p></li><li><p>Different information may be <strong>contradicting</strong></p><p>Due to different perspective and former knowledge, ones could havedifferent views on the same thing. For example, in stock market, it iscommon that a lot of reviewers have contradicting views on whether themarket is bearish or bullish.</p></li><li><p>The capture &amp; storage of information <strong>takes time andeffort</strong></p><p>According to its definition, <mark>understanding and extracting theuseful piece of information need human’s time and effort</mark>.Besides, the form of information varies, such as videos, articles,audios, etc. Handling different forms of information also requiresindividual’s time and effort.</p></li></ol><h3 id="challenge-in-this-era">Challenge in this era</h3><p>With the characteristic of information above, this new era proposesnew challenges. In the past ,people suffer from scarcity of information,the challenge is how to obtain information. To cope with this situation,reading books become a widly applied approach for perceivinginformation. On the contray, nowadays we suffer from redundantinformation source, while some may even be contradicting. The challengenow becomes how to quickly find the information needed, how to performcritical thinking against different viewpoints and make a sound decisionin limited time and how to organize digital information.</p><h2 id="methodology-in-this-era">Methodology in this era</h2><p>Regarding to the <ahref="###%20Characteristic%20of%20information">characteristic ofinformation</a> and the new challenge proposed, I have formed the belowmethodology.</p><ol type="1"><li><p>Be <strong>selective</strong> and make decision with sufficientinformation</p><p>As the information is infinite, we need to be astute when capturinginformation. This involves finding relevant information quickly (usingsearch engine) and selecting those important ones that is most suitablefor current situation.</p><p>Another key advice for this is to capture the <strong>first-handinformation</strong>. This means one should try to be closer toinformation source or trusted publisher. When reading news, checkmultiple authorities's statement; when learning a new programmingpackage, check the official documentation first. Being close to theseinformation source is beneficial, for second-hand or third-handinformation may lose details or involve noise.</p><p>The thought of coming with a ‘perfect’ plan should be abandoned.Since the available information is infinite, you could always use othersource to further improve your plan. The best way to do this would bequickly draft a plan, start implementing it and continue with iterativeperfections based on the feedback from your practice.</p></li><li><p>Develop critical thinking and make independent judgments</p><p>Due to the possible conflicting views from different informationsource, you need to develop the ability of critical thinking. You shouldevaluate views from different sides, find their statement, reasoningsand evidence, and then based on your experience and knowledge to make ainformed decision.</p></li><li><p>Form your own workflow for the capture, organization andinduction of information</p><p>This is related the topic called PIM (Personal InformationManagement), which has a range of sub-topics like task management andknowledge management. Based on your purpose, you could find moredetailed information in relevant fields.</p></li></ol><h3 id="capture-info-search-engine-techniques">Capture info: SearchEngine Techniques</h3><p>People seldom exploit the maximum usage of search engine. You couldcustomize your search via simple formatting of your query, whichsignificantly increase the relevance of the information you find.</p><ol type="1"><li><p>Search for key phrases <code>“”</code></p><p>Wrap up your phrase with <code>“”</code> to search the entire phraserather than search word by word.</p><figure><img src="https://s2.loli.net/2022/03/16/SxZatqpoQGDlzmE.png"alt="search-engine-keyprases-eg1.png" /><figcaptionaria-hidden="true">search-engine-keyprases-eg1.png</figcaption></figure><figure><img src="https://s2.loli.net/2022/03/16/wG9clIuJDi1SdLj.png"alt="search-engine-keypharse-eg2" /><figcaption aria-hidden="true">search-engine-keypharse-eg2</figcaption></figure></li><li><p>Exclude key phrases <code>-</code></p><p>Use a <code>-</code> before the keyword you would like toexclude.</p><figure><img src="https://s2.loli.net/2022/03/16/dkmxwOJf98LBrA6.png"alt="search-engine-exclude-eg1" /><figcaption aria-hidden="true">search-engine-exclude-eg1</figcaption></figure><figure><img src="https://s2.loli.net/2022/03/16/4zAqsKpiBSGJEme.png"alt="image-20220315224450069" /><figcaption aria-hidden="true">image-20220315224450069</figcaption></figure></li><li><p>Searching for synonyms <code>~</code></p><p>Place the <code>~</code> in front of the search term.</p></li><li><p>Using <strong>AND</strong> <strong>OR</strong> logic</p><p>Place keyword <code>AND</code> <code>OR</code> between search termsto indicate whether you want all of them or part of them to appear inthe search result.</p></li><li><p>Using <strong>grammar</strong> to filter result</p></li></ol><ul><li><p>Suppose you want to find something in <strong>a particularwebsite</strong>, use the keyword <code>site:</code>. E.g.<code>Awesome Computer Science Courses site:github.com</code></p></li><li><p>Suppose you want to find something in <strong>specific filetype</strong>, use the keyword <code>filetype:</code>. E.g.<code>How to take smart notes filetype:pdf</code></p></li><li><p>Suppose you want to find <strong>related websites</strong> (havesimilar content), use the keyword <code>related:</code>. E.g.</p><figure><img src="https://s2.loli.net/2022/03/16/YeXLzC4xRskhfPD.png"alt="image-20220315220125781" /><figcaption aria-hidden="true">image-20220315220125781</figcaption></figure></li><li><p>Suppose you want your search term to appear in the title of thesearch result, use the keyword <code>intitle:</code>.</p></li></ul><h3 id="organizing-info-categorization-and-using-tools">Organizing info:Categorization and Using tools</h3><h4 id="categorization">Categorization</h4><p>Inspiration of this idea comes from David Allen’s book introducingGTD method. One of the principle in GTD is to collect all the things(to-dos, reference materials, action reminder, etc.) in one place andcategorize them later to maintain organized. It is the same fororganizing the information you captured.</p><p>To make use of them later, you should categorize them into differentcategories based on its type (video or article) or its topic. There aremultiple ways of doing that, putting them in different folders ortagging them with different tags. The principle for the organizationprocess is simple: the sorting process should be quick to execute,without much confusion and not tedious.</p><p>Below is an example of how I organize a specific type of information- research materials.</p><h5 id="literature-management-tools">Literature management tools</h5><p>As for me, I like to keep a record of the original copy of theinformation source, such as a journal article or a video, for laterreview. Therefore the literature management tools (in my case, Zotero)help me a lot.</p><p>With Zotero (or other similar tools like Citavi, endnote), youcould</p><ul><li>Capture journal articles using DOIs or ISBN, and websites or blogthrough browser extension with a single click.</li><li>Cite your reference easily with uniform cite keys (plugin<code>Better-BibTeX</code> needed) in Microsoft Word, OpenOffice,LibreOffice, etc.</li><li>Sync your references cross-platform.</li><li>Manage your notes for different entries.</li></ul><p>Using a well-designed tool could make the process of managinginformation pleasing and rewarding.</p><h3 id="extracting-info-knowledge-management">Extracting info: Knowledgemanagement</h3><p>Only digested information is valuable and reusable. Another name forthis kind of information is knowledge. Sometimes you need to express theinformation in your own language to see if you understand them fully(Feynman method of learning).</p><p>In AI field, knowledge management is implemented using Triples(<code>(Subject,predicate,object)</code> such as<code>(wheel, part of, cars)</code>) and reasoning rules, and thesebasic units together forms a larger semantic web or knowledge graph.This is some how instructive on how you manage your personal knowledge-&gt; make each note atomic and then forms a larger repository.</p><p>As for individuals, managing reusable knowledge requires note takingstrategies. A field called PKM (Personal Knowledge management) focuseson solve this issue. I would discuss my understanding of PKM and mymethodology (the ZettleKasten) in a later article.</p>]]></content>
    
    
    <categories>
      
      <category>Informal Essays</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Methodology</tag>
      
      <tag>PIM</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Introduction to Cryptography</title>
    <link href="/2022/02/17/Introduction-to-Crypotography/"/>
    <url>/2022/02/17/Introduction-to-Crypotography/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><p>In this piece of note, I will give an overview of Crypotography,introduce basic principles and algorithms for symmetric cryptography,assymetric cryptography and Protocols.</p><span id="more"></span><h1 id="structure-of-cryptography">Structure of Cryptography</h1><figure><img src="https://s2.loli.net/2022/02/18/SMT17RiAEoOHYmv.png"alt="Structure of Cryptography" /><figcaption aria-hidden="true">Structure of Cryptography</figcaption></figure><h2 id="symmetric-cryptography">Symmetric Cryptography</h2><blockquote><p><strong>Same key</strong> for encryption and decryption</p></blockquote><ul><li>Ensures <strong>confidentiality</strong></li><li>Implemented via <strong>block ciphers</strong> or <strong>streamciphers</strong><ul><li>Lightweight and fast</li><li>Used for general communication</li></ul></li></ul><h3 id="stream-ciphers">Stream Ciphers</h3><h4 id="implementation">Implementation</h4><ul><li><p>Initial <strong>seed</strong> key to generate an <strong>infinitekeystream</strong> of random bits</p></li><li><p>Using same keystream to encrypt two messages -&gt; easy tobreak</p><ul><li>A random <em>“number used once”</em> ( <strong>nonce</strong> )added as additional seed -&gt; ensure keystream is new</li></ul></li><li><p>Message &amp; keystream combined using <strong>XOR</strong> toget the cipher text</p><ul><li><mark>XOR is <strong>reversible</strong> is applied twice</mark>,which brings much convenience when decrypt cipher text.</li></ul></li></ul><h4 id="advantages">Advantages</h4><ul><li>Encrypting <strong>long continuous streams</strong>, possibly ofunknown length</li><li>Extremely <strong>fast</strong> with a <strong>low memory</strong>footprint, ideal for low-power devices</li><li>If designed well, can <strong>seek</strong> to any location in thestream</li></ul><h4 id="disadvantages">Disadvantages</h4><ul><li>The keystream must <strong>appear statistically random</strong></li><li>You must *<strong>never* reuse a key + nonce</strong></li><li>Stream ciphers <strong>do not protect the ciphertext</strong><ul><li>Therefore, message could be manipulated during transition withoutbreaking confidentiality</li><li>E.g., suppose you are transmitting a message to bank saying A owesyou $50. Attacker could either manipulate the amount or the creditorusing the same stream ciper or resent the same message to server.</li></ul></li></ul><h3 id="block-cipers">Block Cipers</h3><h4 id="implementation-1">Implementation</h4><ul><li>Use a key to encrypt a <strong>fixed-size block</strong> ofplaintext into a <strong>fixed-size block</strong> of ciphertext<ul><li>Changing and permuting the bits of the block depending on thekey</li></ul></li><li>Different lengths of messages can be handled by splitting themessage up and padding</li></ul><h4 id="example---sp-networks">Example - SP-Networks</h4><p><ahref="https://en.wikipedia.org/wiki/Substitution–permutation_network">Wiki</a></p><ul><li><p>Repeated substitution and permutation</p><figure><img src="https://s2.loli.net/2022/02/18/DdKNjiPcCJvgkhW.png"alt="SP-Network Example" /><figcaption aria-hidden="true">SP-Network Example</figcaption></figure></li><li><p>Key mixing for enhancing security -&gt; Different key fordifferent round</p></li><li><p>Decipher = Reverse operation</p></li></ul><h3 id="symmetric-algorithms">Symmetric Algorithms</h3><table><thead><tr class="header"><th>Algorithm</th><th>Cipher Type</th><th>Design</th><th>Block Size (bits)</th><th>Speed</th><th>Memory Footprint</th><th>Safe Implementation Difficulty</th><th>Key Sizes (bits)</th></tr></thead><tbody><tr class="odd"><td>DES</td><td>Block</td><td>Feistel</td><td>64</td><td>Fast</td><td>Low</td><td>Easy</td><td>56</td></tr><tr class="even"><td>3DES</td><td>Block</td><td>Feistel</td><td>64</td><td>Slow</td><td>Low</td><td>Easy</td><td>112</td></tr><tr class="odd"><td>AES</td><td>Block</td><td>SP-Network</td><td>128</td><td>Very fast</td><td>Low-Medium</td><td>Hard</td><td>128/192/256</td></tr><tr class="even"><td>ChaCha20</td><td>Stream</td><td>add-xor-rot</td><td>N/A</td><td>Very fast</td><td>Very low</td><td>Easy</td><td>256</td></tr></tbody></table><h2 id="asymmetric-cryptography">Asymmetric Cryptography</h2><blockquote><p>Use a <strong>pair</strong> of keys, one public and one private</p></blockquote><h3 id="public-key-cryptography">Public-key cryptography</h3><h4 id="general-idea">General Idea</h4><ul><li>Hinges upon the premise that: <em>It is computationally infeasibleto calculate a private from a public key</em></li><li>In practice, it is achieved through <strong>intractable mathematicalproblem</strong></li></ul><h4 id="key-exchange">Key exchange</h4><ul><li><p>Diffie-Hellman Key exchange allows two parties to mathematicallyagree a shared secret over an insecure channel</p></li><li><p>Alice and Bob each uses a public non-reversible Generator withtheir private keys to generate public key and send it to each other.Using other’s public key and self’s private key, shared secret could beestablished.</p><figure><img src="https://s2.loli.net/2022/02/18/S5Ud1z7g3yN2aPl.jpg"alt="Asymmetric-Cryptography-key-exchange" /><figcaptionaria-hidden="true">Asymmetric-Cryptography-key-exchange</figcaption></figure></li></ul><h4 id="public-key-encryption">Public Key Encryption</h4><ul><li>Encryption performed by the <strong>public key</strong> can only bereversed using the <strong>private key</strong></li></ul><h4 id="digital-signatures">Digital Signatures</h4><ul><li>The authenticity of signatures generated by the private key can byverified by the public key</li><li>Steps<ol type="1"><li>Server send the original message</li><li>Server use private key to encrypt</li><li>Server send the encrypted message</li><li>User verify using public key</li></ol></li></ul><h3 id="public-key-algorithms">Public Key Algorithms</h3><table><thead><tr class="header"><th>Algorithm</th><th>Key Exchange</th><th>Encryption</th><th>Digital Signatures</th><th>Mathematical Problem</th><th>Elliptic Curves?</th><th>Typical key Size (bits)</th><th></th></tr></thead><tbody><tr class="odd"><td>Diffie-Hellman</td><td>✓</td><td></td><td></td><td>Discrete Logs</td><td>✓</td><td>256</td><td></td></tr><tr class="even"><td>RSA</td><td></td><td>✓</td><td>✓</td><td>Integer Factorisation</td><td></td><td>2048/4096</td><td></td></tr><tr class="odd"><td>Elgamal</td><td></td><td>✓</td><td>✓</td><td>Discrete Logs</td><td>✓</td><td>2048</td><td></td></tr><tr class="even"><td>DSA</td><td></td><td></td><td>✓</td><td>Discrete Logs</td><td>✓</td><td>256</td><td></td></tr></tbody></table><h2 id="protocols">Protocols</h2><blockquote><p>Application of cryptographic algorithms in secure systems</p></blockquote><h3 id="hash-functions">Hash Functions</h3><ul><li><p>Cryptographic primitive</p></li><li><p>Takes a message of any length, and returns a pseudorandom hash offixed length</p></li><li><p>Strong hash functions</p><ul><li><p>must appear <strong>random</strong></p></li><li><p>be hard to find collisions – two messages that hash to the samething</p><figure><img src="https://s2.loli.net/2022/02/18/tmOYN6ISBkEfVL5.jpg"alt="strong hash funciton example" /><figcaption aria-hidden="true">strong hash funciton example</figcaption></figure></li></ul><p>### Hash Function usage</p></li></ul><h4 id="message-authentication-codes">Message Authentication Codes</h4><ul><li><p>Provide <strong>integrity</strong> and<strong>authenticity</strong>, not confidentiality</p><ul><li>Protecting system files</li><li>Ensuring messages haven’t been altered</li></ul></li><li><p>Calculate a keyed hash of the message, then append to the end ofthe message</p><figure><img src="https://s2.loli.net/2022/02/18/osuM17TI5D4x2pX.png"alt="hash funciton in message authentication" /><figcaption aria-hidden="true">hash funciton in messageauthentication</figcaption></figure></li></ul><h4 id="digital-signatures-1">Digital Signatures</h4><ul><li>The use of a hash during the signing process shortens thesignature</li><li>More efficient for long messages</li></ul><h4 id="password-storage">Password storage</h4><ul><li>Passwords stored hashed to prevent disclosure</li></ul>]]></content>
    
    
    <categories>
      
      <category>Computer Science</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Cryptography</tag>
      
      <tag>Note</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Thinking about Time management</title>
    <link href="/2022/02/16/Thinking-about-time-management/"/>
    <url>/2022/02/16/Thinking-about-time-management/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><p>In this article, I will talk about my understanding andimplementation of time management measures. Moreover, I would introducesome popular concepts of this topic, like GTD, Pomodoros,The EisenhowerMethod. <span id="more"></span></p><h2 id="understanding-of-time-management">Understanding of Timemanagement</h2><blockquote><p>What it is? What’s its importance?</p></blockquote><p>Time management is the process of carefully planning time individualsspent on various activities. The aim of the time management is toincrease efficiency and productivity. For a simple example, suppose youneed to prepare dinner for your family, you need to complete a set oftasks like shopping for groceries, preparing ingridients, cooking, etc.Time management skills tend to help you reduce the overall time spent onall this tasks by arranging them consciously.</p><p>In computer science, the design of operating system provides anabstraction on this topic via CPU scheduling.</p><ul><li>The priorities of tasks resembles the real life situation where sometasks is more urgent than others.</li><li>The overhead of context switch (switching between tasks) is a vividabstraction of human changing focus.</li><li>For a difficult task (takes more time), it was split into more timeslices to complete.</li></ul><h2 id="popular-concepts">Popular Concepts</h2><h3 id="the-eisenhower-method">The Eisenhower Method</h3><p>It is a method that utilizes the criteria of importance and urgencyto organize priorities and workload. Based on the two criteria, taskscould be categorized into four categories (as in following graph)</p><figure><img src="https://s2.loli.net/2022/02/17/SJzlLvZ1HBuCd3y.png"alt="The Eisenhower Matrix" /><figcaption aria-hidden="true">The Eisenhower Matrix</figcaption></figure><ol type="1"><li>Important &amp; Urgent tasks - should be done immediately and inperson.</li><li>Important &amp; Not Urgent tasks - should be done at certain datesand in person.</li><li>Unimportant &amp; Urgent tasks - could be delegated.</li><li>Unimportant &amp; Not Urgent tasks - should be dropped.</li></ol><p>In practice, it is not frequently listed but used as a mental modelto decide the task’s properties.</p><h3 id="pomodoros">Pomodoros</h3><p>This method was originally from Francesco Cirillo's <ahref="https://en.wikipedia.org/wiki/Pomodoro_Technique">PomodoroTechnique</a>. It took the name from a Pomodoro - tomato shaped kitchentimer. The “Pomodoro” is defined as the fundamental unit of time tomeasure tasks’ expected completion time, which is traditionally definedas being 30 minutes long, consisting of 25 minutes of work and 5 minutesof break time.</p><p>Though it may seems stiff to use strict pomodoros, it could actuallydevelop your sense of time and help you record your performance. Withcontinuous using of this technique, you could be more confident inpredicting tasks’ completion time. Recoding how many Pomodoros youfinished could also be a straight forward metric of evaluating yourperformance.</p><h3 id="gtd">GTD</h3><p>This strategy was created by <ahref="https://en.wikipedia.org/wiki/David_Allen_(author)">DavidAllen</a> in his book <ahref="https://en.wikipedia.org/wiki/Getting_Things_Done">Getting ThingsDone</a>. The basic idea of this strategy is to <strong>capture</strong>all unfinished things (projects or tasks), <strong>clarify</strong> theminto small actionable tasks with clear goals, organize<strong>them</strong> in appropriate forms (and come up to you at propertime), <strong>review</strong> tasks frequently to update the status and<strong>engage</strong> in these tasks.</p><p>In general, it provides a complete workflow for you to manage allyour tasks and projects in a personalized system. Though this system maybe hard to build and maintain, from my own experience, it is worthwhileto keep you confident in action decisions.</p><h2 id="my-implementation-of-time-management">My implementation of timemanagement</h2><p>To start with your time mangement, you frist need to be aware ofwhere you spent your time. I used <code>aTimeLogger</code> to track myeveryday activities. This is the start of my time management practiceand could provide a clear view of whether you are hard working orplaying too much. You could also pick your own time tracking app, justpay attention to the philosophy of the software to make sure they areNOT interruptive of your current activities and time-consuming whenrecording.</p><p><img src="https://s2.loli.net/2022/02/22/TtAapD1cR4I7v6g.jpg" alt="aTimeLogger Time Tracker· by BGCI" style="zoom:67%;" /></p><p>To plan your time carefully and wisely, I used GTD techniques totrack all the tasks I need to finish and all the events I need toparticipate. Following GTD’s principles, I would tag the tasks with itsexpected context (when would be proper, what tools needed, etc.) andgroup them with the assoicated project. I have tried plenty of taskmanagement apps like Omnifocus (which I am now using), Things 3,TickTick (Used for a long time), Wunderlist, etc. It is hard to give ageneral suggestion for the choice as different people may have differentrequirements, just make sure the app you choose helps record your taskseasily, intergrate nicely with your workflow and remind you inappropriate format.</p><p>One more thing to care about, is <strong>DO NOTovermanaging</strong>. I had once fallen into the pitfall ofovermanaging myself. I enjoyed listing and categorizing different tasksand projects, trying different apps, perfecting the tag system but justNOT complete many of those tasks. Remember what the name suggest,getting things done, so focus on completing the tasks rather thanputting most of your efforts changing their organization.</p><p>In the new information era, another thing has become more valuablethan our time, that is, our attention (or effective time). The power ofattention has long been discovered by physicist through <ahref="https://en.wikipedia.org/wiki/Double-slit_experiment">Double-slitexperiment</a>, in which whether observer exists could impact theresults of the inference pattern.</p><figure><img src="https://s2.loli.net/2022/02/18/xQ3H4IUFnDdfRoB.png"alt="Double-slit experiment" /><figcaption aria-hidden="true">Double-slit experiment</figcaption></figure><p>Modern business are even using our attention to gain money (throughonline advertisement). <strong>We need to pay attention to what we paidour attention to.</strong> What you should do, is paying attention tothe four things below:</p><ol type="1"><li>focusing on valuable things</li><li>relationships, especially intimacy</li><li>finding new trends</li><li>Self development</li></ol><p><strong>Pomodoros</strong> is therefore been introduced to my systemto record my attention (though it has way more potentials as introducedabove). You could easily track your progress and performance viapomodoro recoding. I am now using <code>Session</code> as the app torecord for its elegant visualizations and ease of use.</p>]]></content>
    
    
    <categories>
      
      <category>Informal Essays</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Methodology</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Thinking about writing</title>
    <link href="/2022/02/09/Thinking-about-writing/"/>
    <url>/2022/02/09/Thinking-about-writing/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><p>In this article, I will rethink the importance of writing, anddiscuss how the tools I used evolved.</p><span id="more"></span><h2 id="motivation">Motivation</h2><ul><li>In information era, the way we express ourselves matters.</li><li>Different thinking pattern could be reflected from the writing.</li><li>Among applications, we could use the most efficient way to expressand organize our ideas.</li></ul><h2 id="the-importance-of-writing">The importance of writing</h2><p>Writing, in its board aspect, is an everyday activity for all of us.However, according to my friends, little of us have ever thoughtcarefully about this activity. Different format we use could help ustrain different thinking patterns. Different applications we chose couldeffect the efficiency of expressing ourselves and organizing ideas. Itis also an important way for us to exchange serious opinions in a decentmanner (like publications).</p><p>Different format could be applied to writing. Within my knowledge,they are plain text (.txt, .word files), hypertext (.html, .md files)and outline (.opml files). Each format has an implication of differentthinking pattern. For example, if you use outlining more often thanother format, you are tend to be a person with a good sense of theoverall picture.If you use hypertext (e.g. markdown) very often, youtend to care about the content more than the format it is presented.</p><p>In Sönke Ahrens’s book <how to take smart notes>, he emphasis theimportance of writing:</p><blockquote><p>An idea kept private is as good as one you never had. And a fact noone can reproduce is no fact at all. <strong>Making something publicalways means to write it down</strong> so it can be read. There is nosuch thing as a history of unwritten ideas.</p></blockquote><h2 id="my-experience-in-writing">My experience in writing</h2><p>During my early life, I used Microsoft Word as my main editing toolas this is the only one I am familiar with. The software works fine,however, as I grow older, I tend to realize that I spend a lot of time<strong>editing the format</strong> for different headings andemphasis.</p><p>With my exploartion in computer science, I started to use markdown asthe main form of many writings. Markdown is a kind of mark up language,which uses a small set of symbols to realize the formatting. This freedme from doing manual adjustment for different parts of the text andcould now focus more on the content. Markdown is also a portable format.The formatting is realized by limited symbols which allows the raw textto be readable.In my university, I have been using markdown to takenotes, write reports and draft my dissertation.</p><p>Though markdown itself is a powerful concept, the editor could be ofgreat add on to this kind of writing. I have tried a lot of differentmarkdown editors and now kept mainly two of them (Typora and Obsidian),I will write more about the reasoning of choices I made in a laterpost.</p><p>As my writing in markdown format increases, I started to realize onedrawback for this format. It is more of a connstraint in its methodologyrather than software design. Markdown kinds of suggest a<strong>fragmented thinking</strong>, where each piece of markdown notestands for a concept or event solely. Though markdown provides linkfeature, it is not good for getting the whole picture (say you aretaking notes for a course and want to have an overview before exam).This let me to another kind of writing - outlining.</p><p>Compared to putting emphasis on the details, outline writing put anemphasis on the key points or the main topic. It encourages conciselanguage choices which is helpful for letting you know the biggerpicture and the key points. Using the outlining tools together with mymarkdown notes, I could both get an general understanding and havedetailed information when refering to my notes.</p><p>Later when I came accross the PKM concept, I began to use Obsidian tomanage my markdown notes, which could provide two-way linking betweendifferent files. How I implemented my own PKM system using Obsidiancould be found in another post.</p>]]></content>
    
    
    <categories>
      
      <category>Informal Essays</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Methodology</tag>
      
      <tag>Writing</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>How to set up a hexo blog</title>
    <link href="/2021/11/28/How-to-set-up-a-hexo-blog/"/>
    <url>/2021/11/28/How-to-set-up-a-hexo-blog/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><p>In this article, you will find how to set up a hexo blog and deployit.</p><span id="more"></span><blockquote><p>Special thanks to <ahref="https://www.bilibili.com/video/BV1Yb411a7ty">Codesheep'svideo</a></p></blockquote><h1 id="pre-requisite">0. Pre-requisite</h1><p>The most important of all, don't be afraid of making mistakes!</p><p>To initiate your blog, you will need the libraries below.</p><h2 id="node.js">0.1 Node.js</h2><p><ahref="https://nodejs.org/en/download/"><code>Download here</code></a> -suggest LTS version</p><p>To check whether <code>Node.js</code> was downloaded successfully,type <code>node -v</code> in the terminal window. If something like<code>v12.18.2</code> is presented with no error message, you are freeto go for the next step.</p><blockquote><p>For Windows users, terminal could be invoked by pressing<code>win</code> + <code>R</code>, and then type <code>cmd</code> in theprompt window.</p></blockquote><h2 id="npm">0.2 npm</h2><p><code>npm</code> is the default package management tool for<code>Node.js</code>.</p><blockquote><p>For Chinese users, you could switch to the mirror in<code>cnpm</code> for faster downloads. Run the command to install<code>cnpm</code>: <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs linux">$ npm install -g cnpm --registry=https://registry.npm.taobao.org<br></code></pre></td></tr></table></figure></p></blockquote><p>Similar to <code>Node.js</code>, type <code>npm -v</code> to check ifit's installed successfully.</p><h2 id="git">0.3 Git</h2><p><code>git</code> is a version control tool used widely amongprogramming projects. Generally speaking, it could help you keepdifferent versions of your project.</p><p><a href="https://git-scm.com/downloads">Download here</a></p><p>To configure the git globally, you could run the command afterinstallation. In the command, <code>--global</code> would set thefollowing parameters for all git repositories on your computer.<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs linux">$ git config --global user.name &quot;Your Namee&quot;<br>$ git config --global user.email &quot;email@example.com&quot;<br></code></pre></td></tr></table></figure></p><h2 id="hexo">0.4 hexo</h2><p>With the package management tool installed, fetch the<code>hexo</code> package using command:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs linux">$ npm install -g hexo<br></code></pre></td></tr></table></figure><p>or: <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs linux">$ cnpm install -g hexo<br></code></pre></td></tr></table></figure></p><p>Similar to <code>Node.js</code>, type <code>hexo -v</code> to checkif it's installed successfully.</p><h1 id="initiate-blog">1. Initiate blog</h1><ol type="1"><li><p>Create a folder</p><p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs linux">$ mkdir blog<br></code></pre></td></tr></table></figure></p><p>By default, this <code>blog/</code> folder will be created in<code>/Users/YourUserName/</code> for both Mac and Windowsusers.</p></li><li><p>Navigate into the folder</p><p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs linux">$ cd blog<br></code></pre></td></tr></table></figure></p><p>To check if you are in the right folder, type <code>pwd</code> tocheck.</p></li><li><p>Initiate your blog</p></li></ol><p><mark>Make sure you are in the right folder before running commandbelow!</mark></p><p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs linux">$ sudo hexo init<br></code></pre></td></tr></table></figure></p><p>The <code>sudo</code> parameter refers to admin access.</p><ol start="4" type="1"><li>Run your blog!</li></ol><p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs linux">$ hexo s<br></code></pre></td></tr></table></figure></p><p>By default, you will see the blog running athttp://localhost:4000</p><h1 id="create-a-new-article">2. Create a new article</h1><p>As indicated in the default blog file <code>helloworld.md</code>, youcould use the command below to create a new blog.</p><figure class="highlight elixir"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs elixir"><span class="hljs-variable">$ </span>hexo n <span class="hljs-string">&quot;Your artical title&quot;</span><br></code></pre></td></tr></table></figure><p>By default, it will be created in <code>source/_posts</code> folder.For markdown reference, please check <ahref="https://commonmark.org/help/">here</a>.</p><p>After writing, use the following command to clean the database andgenerate static files for local blog.</p><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs verilog">$ hexo clean<br>$ hexo <span class="hljs-keyword">generate</span><br>$ hexo server<br></code></pre></td></tr></table></figure><p>Vist the default link again, you could see the article you justwrote.</p><h1 id="deploy-your-blog">3. Deploy your blog</h1><blockquote><p>You will need a Github account or Gitee accound for deployment.</p></blockquote><h2 id="github">Github</h2><ol type="1"><li><p>Create a new repository with the name<code>YourFullUserName.github.io</code> and it has to be set topublic.</p></li><li><p>Install a plugin for deployment.</p><p><figure class="highlight ada"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs ada">$ npm install <span class="hljs-comment">--save hexo-deployer-git</span><br></code></pre></td></tr></table></figure></p></li><li><p>Find the <code>_config.yml</code> file in your blog folder, atthe end of this file, modify the following content:</p><p><figure class="highlight nestedtext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs nestedtext"><span class="hljs-comment"># Deployment</span><br><span class="hljs-comment">## Docs: https://hexo.io/docs/deployment.html</span><br><span class="hljs-attribute">deploy</span><span class="hljs-punctuation">:</span><br>  <span class="hljs-attribute">type</span><span class="hljs-punctuation">:</span> <span class="hljs-string">git</span><br>  <span class="hljs-attribute">repo</span><span class="hljs-punctuation">:</span> <span class="hljs-string">Your Github repo&#x27;s link</span><br>  <span class="hljs-attribute">branch</span><span class="hljs-punctuation">:</span> <span class="hljs-string">master</span><br></code></pre></td></tr></table></figure></p><p>Your repo link should end with <code>.github.io.git</code> which youcould obtain here.</p><figure><img src="https://i.loli.net/2021/11/28/mQEldKOZv9wsjqc.jpg"alt="Where to find your link" /><figcaption aria-hidden="true">Where to find your link</figcaption></figure></li><li><p>After saving your config file, run command below to deploy yourblog.</p><p><figure class="highlight crystal"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs crystal"><span class="hljs-variable">$ </span>hexo d<br></code></pre></td></tr></table></figure></p><p>You may need to type your user name and password.</p></li><li><p>See you blog online!</p><p>Visit <code>yourUserName.github.io</code></p></li></ol><h2 id="gitee">Gitee</h2><p>#TODO</p><h1 id="references">References</h1><ul><li><a href="https://www.bilibili.com/video/BV1Yb411a7ty">Codesheep'svideo in Chinese</a></li></ul>]]></content>
    
    
    
    <tags>
      
      <tag>blog</tag>
      
      <tag>translation</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Index System Introduction</title>
    <link href="/2021/09/27/Index%20System%20Introduction/"/>
    <url>/2021/09/27/Index%20System%20Introduction/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><p>In this article, you will find an brief definition of Index system,how is it useful and how to build one on your own.</p><span id="more"></span><p>Further to my internship experience and my reading on the web, I haveconcluded some information about index system.</p><h2 id="what-is-index-system">1. What is Index System?</h2><p>For example, when deciding whether a company is worth investing, youwould see comments like "This company has too much loans", "It is notmaking any profits". However in data-driven industries (like finance),you need to support your decisions with intuitive evidence. Instead ofraw business data, an index should be used for demonstration purposes(e.g. Asset-liability ratio).In the above example, the index ofasset-liability ration addresses the company's debt.</p><p>In real world problem, complicate problem could not be resolved byusing one single index (e.g. Evaluating a company's futureprofitability), therefore a set of indexes is needed to describe thedata subject from different perspectives and lead to a informeddecision, that is where index system plays a role.</p><h2 id="how-is-index-system-useful">2. How is index system useful?</h2><p>When evaluating one's health condition, we tend to use the indicatorslike body fat percentage, body temperature, blood pressure, etc.Considering these indicators together, one's health status could then bedetermined.</p><p>It's the same when using index system to evaluate a company. Whensomething goes wrong, the index system should be able to reflect thisabnormality. Tracing down the problematic index that goes wrong, thecurrent problem in business should be clear. And then the relevantdepartment could have the right direction to improve on.</p><p>In summary, the index system should achieve the following: 1. Monitorbusiness situation 2. Find problems based on problematic index 3.Evaluate business and guide the future work.</p><h2 id="how-to-build-an-index-system">3. How to build an indexsystem?</h2><p>The general approach is as following: 1. Understand company's /department's Key Performance Indicator (KPI), define Level-1 Index 2.Understand the business, dismantle Level-1 Index and define Level-2Index 3. Sort out business processes, dismantle Level-2 Index and defineLevel-3 Index 4. Using reports to monitor index system, update itaccordingly</p><h2 id="common-mistakes-when-building-index-system">4. Common mistakeswhen building index system</h2><ul><li>Not understand the KPI</li><li>No logic relationship between indexes</li><li>Dissembled indexes has no business meaning</li><li>Little or No communication between data department and businessdepartment</li></ul><h2 id="reference">Reference</h2><ul><li><a href="https://zhuanlan.zhihu.com/p/285551902">Zhihu's passage -How to build an index system by Houzi</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>Data Science</category>
      
    </categories>
    
    
    <tags>
      
      <tag>translation</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Binary search algorithm</title>
    <link href="/2021/09/11/Binary%20search%20algorithm%20Summary/"/>
    <url>/2021/09/11/Binary%20search%20algorithm%20Summary/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><p>In this post, I will give a brief summary of binary search algorithm,together with some programming problems on this topic.</p><span id="more"></span><h2 id="algorithm-introduction">Algorithm Introduction</h2><ul><li>It is a simple <strong>recursive</strong> searching algorithm.</li><li>Scope of application: in <strong>ordered</strong> arrays</li></ul><p>The pseudocode<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup> is asfollows:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python">Procedure binary_search<br>   A ← <span class="hljs-built_in">sorted</span> array<br>   n ← size of array<br>   x ← value to be searched<br>   <span class="hljs-type">Set</span> lowerBound = <span class="hljs-number">1</span> <br>   <span class="hljs-type">Set</span> upperBound = n <br>   <span class="hljs-keyword">while</span> x <span class="hljs-keyword">not</span> found <br>    <span class="hljs-keyword">if</span> upperBound &lt; lowerBound <br>EXIT: x does <span class="hljs-keyword">not</span> exists. <br><span class="hljs-built_in">set</span> midPoint = lowerBound + ( upperBound - lowerBound ) / <span class="hljs-number">2</span> <br> <br> <span class="hljs-keyword">if</span> A[midPoint] &lt; x <br> <span class="hljs-built_in">set</span> lowerBound = midPoint + <span class="hljs-number">1</span> <br> <span class="hljs-keyword">if</span> A[midPoint] &gt; x <br> <span class="hljs-built_in">set</span> upperBound = midPoint - <span class="hljs-number">1</span> <br> <span class="hljs-keyword">if</span> A[midPoint] = x <br>         EXIT: x found at location midPoint <br>   end <span class="hljs-keyword">while</span><br></code></pre></td></tr></table></figure><p>In plain words, it recursively check whether the mid point value isthe target, if the target is bigger, check the left half; if the targetis smaller, check the right half.</p><h3 id="complexity">Complexity</h3><ul><li>Space complexity Only constant number of variables are used,therefore the space complexity is <spanclass="math inline">\(O(1)\)</span>.</li><li>Time complexity Because each time after search, half of the arraywould be 'discarded', therefore the overall complexity is <spanclass="math inline">\(O(\log n)\)</span>, where <spanclass="math inline">\(n\)</span> is the length of the array.</li></ul><h2 id="java-implementation-example">Java Implementation example</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-comment">// Java - Non-recursive version</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>&#123;<br><span class="hljs-keyword">public</span> <span class="hljs-type">int</span> <span class="hljs-title function_">binarySearch</span><span class="hljs-params">(<span class="hljs-type">int</span>[] nums, <span class="hljs-type">int</span> target)</span> &#123;<br><span class="hljs-type">int</span> <span class="hljs-variable">n</span> <span class="hljs-operator">=</span> nums.length;<br><span class="hljs-type">int</span> <span class="hljs-variable">left</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>, right = n - <span class="hljs-number">1</span>;<br><span class="hljs-keyword">while</span> (left &lt;= right) &#123;<br><span class="hljs-type">int</span> <span class="hljs-variable">mid</span> <span class="hljs-operator">=</span> left + (right - left) / <span class="hljs-number">2</span>; <span class="hljs-comment">// Prevent add overflow</span><br><span class="hljs-keyword">if</span> (nums[mid] == target) <span class="hljs-keyword">return</span> mid;<br><span class="hljs-keyword">if</span> (nums[mid] &lt; target) &#123;<br>left = mid + <span class="hljs-number">1</span>;<br>&#125; <span class="hljs-keyword">else</span> &#123;<br>right = mid - <span class="hljs-number">1</span>;<br>&#125;<br>&#125;<br><span class="hljs-keyword">return</span> -<span class="hljs-number">1</span>;<br>&#125;<br>&#125;<br><br></code></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-comment">// Java - Revursive version</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>&#123;<br><span class="hljs-keyword">public</span> <span class="hljs-type">int</span> <span class="hljs-title function_">binarySearch</span><span class="hljs-params">(<span class="hljs-type">int</span>[] nums, <span class="hljs-type">int</span> start, <span class="hljs-type">int</span> end, <span class="hljs-type">int</span> target)</span> &#123;<br><span class="hljs-keyword">if</span> (start &gt; end)<br><span class="hljs-keyword">return</span> -<span class="hljs-number">1</span>;<br>    <span class="hljs-type">int</span> <span class="hljs-variable">mid</span> <span class="hljs-operator">=</span> start + (end - start)/<span class="hljs-number">2</span>; <span class="hljs-comment">// Prevent add overflow</span><br>    <span class="hljs-keyword">if</span> (arr[mid] &gt; target)<br>        <span class="hljs-keyword">return</span> binarySearch(arr, start, mid - <span class="hljs-number">1</span>, target);<br>    <span class="hljs-keyword">if</span> (arr[mid] &lt; target)<br>        <span class="hljs-keyword">return</span> binarySearch(arr, mid + <span class="hljs-number">1</span>, end, target);<br>    <span class="hljs-keyword">return</span> mid;<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="questions">Questions</h2><ol type="1"><li><a href="https://leetcode.com/problems/binary-search/">Leetcode 704- Binary search</a> - Basic implementation for this algorithm.</li><li><a href="https://leetcode.com/problems/first-bad-version/">Leetcode278 - First bad Version</a> - Variation on look-up standards.</li><li><ahref="https://leetcode.com/problems/find-first-and-last-position-of-element-in-sorted-array/">Leetcode34 - Find First and Last Position of element in Sorted array</a> -Variation on look-up standards and re-use of code.</li><li><ahref="https://leetcode.com/problems/search-in-rotated-sorted-array/">Leetcode33 - Search in rotated sorted array</a>- Variation on the structure ofarray.</li><li><a href="https://leetcode.com/problems/search-a-2d-matrix/">Leetcode74 - Search a 2D matrix</a> - Variation on the structure of input array,need to reduce the dimension of input.</li><li><a href="https://leetcode.com/problems/find-peak-element/">Leetcode162 - Find peak element</a> - Another realization of binary searchalgorithm.</li></ol><div id="footnotes"><hr><div id="footnotelist"><ol><li id="fn:1">The pseudo code is derived from<a href="https://www.tutorialspoint.com/data_structures_algorithms/binary_search_algorithm.htm">tutorialspoint</a><a href="#fnref:1" rev="footnote"> ↩︎</a></li></ol></div></div>]]></content>
    
    
    <categories>
      
      <category>Computer Science</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Algorithm</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Intention of this blog</title>
    <link href="/2021/08/18/Intention-of-this-blog/"/>
    <url>/2021/08/18/Intention-of-this-blog/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><span id="more"></span><h2 id="aims">Aims</h2><ul><li>Record feelings and findings during CS study.</li><li>Share my project experience with reproduceble steps.</li><li>Publish notes about courses and libraies.</li></ul><h2 id="why-this-blog-is-named-connecting-dots">Why this blog is namedconnecting dots?</h2><p>In childhood, I was fond of the game <ahref="https://en.wikipedia.org/wiki/Connect_the_dots">Connect thedots</a>. It seems magic to me that drawing lines between numbered dotsgradually reveals the actual shape hidden behind. Sometimes it's toughto predict what you will arrive at simply by looking at the outline ofthe unconnected dots and therefore finishing the game always brings mesurprise and excitement.</p><p>As I grew older, I thought about the ultimate philosophicalquestions: Who am I? Where am I heading? Reading lots of biographies didnot offer me a satisfactory answer, as I found that most of the time,people aren't quite sure where they will be taken to by theiractions.</p><p>It struck me one day that life is just like the game I enjoyed in mychildhood. Finishing school, completing projects, and entering arelationship are all actions that create a 'dot' on the canvas of ourlife. It is not until some point in life when we look back, that we seea clear picture of our past by connecting the 'dots' we created.</p><p>Therefore, I named my blog after my favourite childhood game torecord the dots I made in my life and remind me to constantly reviewwhere these dots may take me.</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>Basic Blog Operations</title>
    <link href="/2021/08/17/hello-world/"/>
    <url>/2021/08/17/hello-world/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your veryfirst post. Check <a href="https://hexo.io/docs/">documentation</a> formore info. If you get any problems when using Hexo, you can find theanswer in <ahref="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> oryou can ask me on <ahref="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><span id="more"></span><h2 id="quick-start">Quick Start</h2><h3 id="create-a-new-post">Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo new <span class="hljs-string">&quot;My New Post&quot;</span><br></code></pre></td></tr></table></figure><p>More info: <ahref="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="run-server">Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo server<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="generate-static-files">Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo generate<br></code></pre></td></tr></table></figure><p>More info: <ahref="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="deploy-to-remote-sites">Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo deploy<br></code></pre></td></tr></table></figure><p>More info: <ahref="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
    
    
    
    <tags>
      
      <tag>blog</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Operating System Lecture Notes - Introduction</title>
    <link href="/2020/10/04/OSC%20Lecture%20Notes%20-%20Introduction/"/>
    <url>/2020/10/04/OSC%20Lecture%20Notes%20-%20Introduction/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><p>In this note, you could find the basic definition of OperatingSystems and the general architecture of computer.</p><span id="more"></span><h2 id="defining-operating-systems">Defining Operating Systems</h2><h3 id="what-can-an-os-do-for-me">What can an OS do for me?</h3><ul><li><p><strong>File systems</strong>: where is the file physicallywritten on the disk and how is it retrieved?</p></li><li><p><strong>Abstraction</strong>: why looks the instruction the sameindependent of the device?</p></li><li><p><strong>Concurrency</strong>: what if multiple programs accessthe same file simultaneously? What if an other process startsrunning?</p></li><li><p><strong>Security</strong>: why is the access denied? Where inmemory will the array be stored and how is it protected fromunauthorised access?</p></li><li><p>What if the array requires more memory than physicallyavailable?</p></li><li><p>What if only part of the array is currently in use ?</p></li></ul><h4 id="what-is-part-of-the-operating-system">What is part of theoperating system?</h4><p>Memory management, CPU scheduling, file system, communication, memorymanagement, interrupt handling, GUI, . . .</p><h4 id="a-resource-manager">A resource manager</h4><ul><li>Many modern operating systems use <strong>multi-programming</strong>to <strong>improve user experience</strong> and <strong>maximizeresource utilization</strong><ul><li>Disks are slow: without multi-programming, CPU time is wasted whilewaiting for I/O requests<ul><li>Imagine a CPU running at 3.2 GHz (approx. 3:2 <spanclass="math inline">\(\times\)</span> 109 instructions per second)</li><li>Imagine a disk rotating at 7200 RPM, taking 4.2 ms to rotate half atrack</li><li>I/O is slow, we are missing out on 3.2 <spanclass="math inline">\(\times\)</span> 4.2 <spanclass="math inline">\(\times\)</span> <spanclass="math inline">\(10^6\)</span> instructions (13.44m)!</li></ul></li></ul></li><li>The implementation of multi-programming has important consequencesfor operating system design</li><li>The operating system must <strong>allocate/share resources</strong>(including CPU, memory, I/O devices) fairly and safely between competingprocesses:<ul><li>In time, e.g. CPUs and printers</li><li>In space, e.g., memory and disks</li></ul></li><li>The execution of multiple programs (processes) needs to beinterleaved with one another:<ul><li>This requires context switches and process scheduling ) <spanclass="math inline">\(\Rightarrow\)</span> mutual exclusion, deadlockavoidance, protection, . .</li></ul></li></ul><h3 id="origin">Origin</h3><p>In the early days, programmers had to deal directly with thehardware</p><ul><li>Real computer hardware is ugly</li><li>Hardware is extremely difficult to manipulate/program</li></ul><p><mark>An operating system is a layer of indirection on top of thehardware</mark>:</p><ul><li>It provide <strong>abstractions</strong> for application programs(e.g., file systems)</li><li>It provides a <strong>cleaner and easier interface to thehardware</strong> and hides the complexity of “bare metal”</li><li>It allows the programmer to be lazy by using common routines:-)</li></ul><p><img src="https://s2.loli.net/2022/01/09/Fi8pODhsMjUYQWe.png" alt="image-20201004095954244" style="zoom:67%;" /></p><h3 id="why-study-operating-system">Why study operating system?</h3><ul><li>The programs that we write <strong>use operating systemfunctionality</strong></li><li>How are the operating system’s services/abstractionsimplemented</li></ul><h2 id="computer-architecture">Computer Architecture</h2><p><img src="https://s2.loli.net/2022/01/09/6zOLWYRhwxfPS48.png" alt="image-20201004100314213" style="zoom:50%;" /></p><center>Simplified computer model (Tanenbaum, 2014)</center><h3 id="cpu-design">CPU design</h3><ul><li>CPU’s basic cycle consist of <strong>fetch, decode, andexecute</strong> (pipelines, or superscalar)</li><li>Every CPU has his own instruction set</li><li>A CPU has a set of registers (extremely fast memory close to the CPU“core”)<ul><li>Registers are used to <strong>store data and for specialfunctions</strong> (e.g. program counter, program status word – modebit)</li><li>The <strong>compiler/programmer</strong> decides what to keep in theregisters</li><li><strong>Context switching</strong> must save and restore the CPU’sinternal state, including its registers</li></ul></li></ul><figure><img src="https://s2.loli.net/2022/01/09/BXFD78eJvCzyScn.png"alt="image-20201004100845955" /><figcaption aria-hidden="true">image-20201004100845955</figcaption></figure><h4 id="memory-management-unit">Memory management Unit</h4><ul><li><p>There are two different address spaces:</p><ul><li>the <strong>logical address space</strong> seen by the process andused by the compiler</li><li>the <strong>physical address space</strong> seen by thehardware/OS</li></ul></li><li><p>When compiling code, memory addresses must be assigned tovariables and instructions, the compiler does not know what memoryaddresses will be available in physical memory</p></li><li><p>It will just assume that the code will start running at address 0when generating the machine code</p><p><img src="https://s2.loli.net/2022/01/09/Ug1EDLKpfQdIZqV.png" alt="image-20201004102110699" style="zoom:67%;" /></p></li><li><p>On some rare occasions, the process may run at physical address0</p><ul><li>physical address = logical address + 0</li></ul></li><li><p>On other occasions, it will be running at a completely differentlocation in physical memory and an offset is added</p><ul><li>physical address = logical address + offset</li></ul></li><li><p>The <code>memory management unit</code>(MMU) is<strong>responsible for address translation</strong> (“adding theoffset”)</p><ul><li>Different processes require different address translation(offsets)</li><li>Context switching requires the MMU to be updated (and registers,cache, ...)</li></ul></li></ul><h5 id="example">Example</h5><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;stdio.h&gt;</span></span><br><span class="hljs-type">int</span> iVar = <span class="hljs-number">0</span>;<br><span class="hljs-type">void</span> <span class="hljs-title function_">main</span><span class="hljs-params">()</span> &#123;<br>    <span class="hljs-type">int</span> i = <span class="hljs-number">0</span>;<br>    <span class="hljs-keyword">while</span>(i &lt; <span class="hljs-number">10</span>) &#123;<br>        iVar++;<br>        sleep(<span class="hljs-number">2</span>);<br>        <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;Address:%u; Value:%d\n&quot;</span>,&amp;iVar, iVar);<br>         i++;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><ul><li>The same addresses will be displayed for <code>iVar</code>. Theaddress printed on the screen is the logical address</li><li>The value for <code>iVar</code> in the first run doesn’t influencethe second run’s value</li></ul><h3 id="moores-law">Moore’s Law</h3><blockquote><p>“The number of transistors on an integrated circuit (chip) doublesroughly every two years”</p></blockquote><ul><li>Closely linked, but not necessarily related to performance</li><li>Moore’s still continuing, but the “power wall” slows performanceimprovements of <strong>single core/single processor systems</strong><ul><li>A few cores for multiple “programs” is easy to justify</li><li>How to use <strong>massively parallel</strong> computers/CPUs/manycore machines</li><li>Can we extract parallelism automatically, can we implementparallelism at the lowest level (similar to multiprogramming)</li></ul></li></ul><blockquote><p>Lead to multi-core / parallel development</p></blockquote><h3 id="multi-core-hyperthreaded-processors">Multi-core, hyperthreadedprocessors</h3><ul><li><p>Modern CPUs contain multiple cores and are oftenhyper-threaded</p></li><li><p><strong>Evolution in hardware</strong> has implications on<strong>operating system design</strong></p><ul><li><p>XP did not support <strong>multi processorarchitectures</strong></p></li><li><p><strong>Process scheduling</strong> needs to account for loadbalancing and CPU affinity</p></li><li><p>Cache <strong>coherency</strong> becomes important (managerun-time data)</p><p><img src="https://s2.loli.net/2022/01/09/nlVhBsdvXeZO7uJ.png" alt="image-20201004111125457" style="zoom:50%;" /></p></li></ul></li></ul><blockquote><p>Previous exam: Describe how, in your opinion, recent developments incomputer architecture and computer design have influenced operatingsystem design</p></blockquote><h3 id="timer-interrupts">Timer Interrupts</h3><ul><li>Interrupts temporarily pause a process’s normal operation</li><li>Different types of interrupts exist, including:<ul><li>Timer interrupts by <strong>CPU clock</strong></li><li><strong>I/O interrupts</strong> for <strong>I/O completion</strong>or error codes</li><li><strong>Software generated</strong>, e.g. errors and exceptions</li></ul></li><li><strong>Context switches</strong> (i.e. switching between processes)can be initiated by timer interrupts after a “set time”</li></ul><p><img src="https://s2.loli.net/2022/01/09/lHoSLPmFs6bNGny.png" alt="image-20201004111301287" style="zoom:50%;" /></p><ol type="1"><li>Timer generates an interrupt</li><li>CPU finishes current instruction and tests for interrupt</li><li>Transfer to interrupt service routine<ul><li>Hardware saves current process state (PSW, program counter)</li><li>Set program counter to interrupt service routine</li><li>Save registers and other state information</li></ul></li><li>Carry out interrupt service routine (scheduler)</li><li>Restore next process to run</li></ol>]]></content>
    
    
    <categories>
      
      <category>Computer Science</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Note</tag>
      
      <tag>Operating System</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
