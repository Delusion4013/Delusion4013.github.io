[{"title":"RL00 - A glimpse of Reinforcement Learning","date":"2025-06-24","path":"2025/06/24/RL00-A-glimpse-of-Reinforcement-Learning/","excerpt":"This post summarizes reinforcement learning from classic tabular\nmethods to ML-based approximations and recent LLM applications like\nRLHF.","content":"This post summarizes reinforcement learning from classic tabular methods to ML-based approximations and recent LLM applications like RLHF. General definition and applications Intuition &amp; Definition If you were asked, ‚ÄúHow did you learn to ride a bike or solve a math problem?‚Äù, your answer would likely involve interaction. When learning to ride a bike, for instance, you probably didn‚Äôt follow a step-by-step guide detailing exact body movements. Instead, you engaged directly with the environment‚Äîthe bike, the road, your own balance‚Äîlearning through trial and error: falling, adjusting, and gradually figuring out what works. This kind of learning‚Äîdriven by feedback from experience‚Äîis at the heart of reinforcement learning. In more formal terms, reinforcement learning (RL) is learning what to do - how to map situations to actions - so as to maximize a numerical reward signal. The learner is not told which actions to take, but instead must discover which actions yield the most reward by trying them. This separates RL from supervised learning and unsupervised learning. a third paradigm Reinforcement Learning (RL) differs from supervised learning (SL) in learning method: SL learns from a fixed dataset of labeled examples, where each input has a known correct output provided by an external supervisor. In contrast, RL learns through interaction with the environment, receiving feedback in the form of rewards rather than explicit labels, and improving behavior via trial and error. RL also differs from unsupervised learning (USL) in learning objective: USL seeks to discover hidden patterns or structures in unlabeled data (e.g., clustering or dimensionality reduction), whereas RL aims to optimize a policy that maximizes cumulative rewards. Components Reinforcement learning (RL) is structured around two central entities: the agent and the environment, connected through a feedback loop illustrated in the diagram At each timestep \\(t\\), the agent receives an observation \\(o_t\\) from the environment, takes an action \\(a_t\\), and subsequently receives a reward \\(r_{t+1}\\). The environment, in turn, processes the action, updates its state, and emits the next observation \\(o_{t+1}\\) along with the reward signal \\(r_{t+1}\\). Beyond this basic interaction loop, an RL learning system comprises several core components: a policy \\(\\pi\\), which maps states to actions and defines the agent's behavior; a reward signal, which evaluates the immediate desirability of actions taken; a value function, which estimates the expected cumulative reward and thus guides long-term decision-making; optionally, a model of the environment, which allows the agent to simulate and plan by predicting future states and rewards. Together, these elements enable the agent to learn from experience and improve its performance over time. Applications Reinforcement learning shines in domains that require continuous decision-making and adaptation. In robotics, RL trains agents to control complex systems‚Äîsuch as robotic arms grasping objects or mobile robots navigating unpredictable terrains‚Äîthrough trial and error. On factory floors, it optimizes processes like automated control and supply-chain logistics, improving efficiency and resilience . In finance, RL algorithms drive algorithmic trading and portfolio management by learning strategies to buy, sell, or hold assets, maximizing risk-adjusted returns . And in gaming, RL systems such as Deep Q-Networks and AlphaZero have mastered Go, StarCraft II, and Dota 2, demonstrating extraordinary planning and strategic reasoning. From Tabular methods to Approximated methods Tabular solution Methods At first glance, \"tabular methods\" might conjure dull images of exhaustive spreadsheets and tedious searches. So why are we still intrigued by them? Simple: they distill reinforcement learning down to its purest form, clearly revealing the fundamental mechanics behind RL algorithms. What are the scope of tabular methods then? We start with a basic model - Multi-armed bandits model as a representation of single state situation where value functions are introduced, along with the classical exploration vs. exploitation challenge. Then we move on to more general problem formulation - (finite) Markov Decision Process (MDP), introducing multiple states into the problem formation. Now, our learning becomes sequential and goal-oriented, reflecting real-world decision-making as we interact repeatedly with our environment. To solve MDP problem we introduced 3 new methods: Dynamic Programming Monte Carlo(MC) Method Temporal Difference(TD) learning DP-vs-MC-vs-TD As the pros and cons of each method was discovered, variation of the above 3 methods are proposed, like MC+TD via multi-step bootstrapping, TD+model learning &amp; planning, which will be discussed in later post. Approximate solution method The number of distinct states grows exponentially in most realistic tasks, so storing a separate value for each state‚Äìaction pair is impos","categories":["Notes"],"tags":["Data Science","Reinforcement Learning"]},{"title":"Complete walk through of general hypothesis testing","date":"2024-07-19","path":"2024/07/19/Complete-walk-through-of-hypothesis-testing/","excerpt":"In this blog, I will provide a complete walk through of another\npopular concept in data science interviews - hypothesis testing, from\nits general setup, key concepts related (test statistics, Type I error,\netc.) to actual applications.","content":"In this blog, I will provide a complete walk through of another popular concept in data science interviews - hypothesis testing, from its general setup, key concepts related (test statistics, Type I error, etc.) to actual applications. General setup The process of testing whether or not a sample of data supports a particular hypothesis is called ==Hypothesis Testing==. State a null hypothesis (baseline) and an alternative hypothesis (the statement you want to prove). Either the null hypothesis will be rejected (in favor of the alternative hypothesis), or it will fail to be rejected (although failing to reject the null hypothesis does not necessarily mean it is true, but rather that there is not sufficient evidence to reject it) Design your test Decide the Test Statistic to work with Decide the Significance level Compute the observed statistic (based on your sample) Reach a conclusion Compare the p-value to a certain significance level \\(\\alpha\\). (to decide whether to reject or fail to reject your null hypothesis) Types of hypothesis test Hypothesis tests are either one- or two- tailed tests. Here \\(H_0\\) is the null hypothesis and \\(H_1\\) is the alternative hypothesis, and \\(\\mu\\) is the parameter of interest. One tailed tests \\[ \\begin{align} H_0:\\mu=\\mu_0\\text{ versus } &amp;H_1:\\mu&lt;\\mu_0\\text{(also called left tailed) }\\\\ &amp;H_1: \\mu&gt;\\mu_0 \\text{(right tailed)} \\end{align} \\] Two tailed tests \\(H_0:\\mu=\\mu_0\\text{ versus } H_1: \\mu \\ne \\mu_0\\) Test statistic Now lets suppose you have already set up your hypothesis and are marching into step 2 of the setup. Then you may be wondering, what is test statistic? A ==test statistic== is a numerical summary designed for the purpose of determining whether the null hypothesis or the alternative hypothesis should be accepted as correct. More specifically, it assumes that the parameter of interest follows a particular sampling distribution under the null hypothesis. Based on the test statistic we select and the assumptions we made with our samples, hypothesis testing varies into different categories. For example, we have: Z-test, where we use z-score as the test statistic, and assumes this statistic follows a normal distribution under the null hypothesis. where \\(\\sigma\\) is the population variance and \\(\\mu_0\\) is the population mean. \\[z=\\frac{\\bar{x}-\\mu_0}{\\sigma/\\sqrt{n}}\\sim N(0,1)\\] t-test, where we use a student's t-distribution rather than a normal distribution to cope with unknown population variance. \\[t=\\frac{\\bar{x}-\\mu_0}{s/\\sqrt{n}}\\sim t_{n-1}\\] Chi-squared test, where we check whether two categorical variables are independent by this test statistic: \\[\\chi^2=\\sum_i\\frac{(O_i-E_i)^2}{E_i}\\] There are a lot of other tests not covered like ANOVA, Independent t-test Paired t-test. These tests typically focus on verifying hypothesis with different setup of the samples and population. Significance level &amp; Type I/Type II Errors With test statistic selected, you are now ready to decide the significance level \\(\\alpha\\). What is that? To give a intuitive definition under hypothesis testing context, we need to look at the errors we could made during this process. Suppose our research question is whether a new campaign design is effective and profitable by measuring the average conversion rate on different users. Then the null hypothesis we set for this one is The new campaign design has no effect on promoting sales. Or more statistically, The new compaign's conversion rate \\(\\mu\\) is equal to old campaign design \\(\\mu_0\\), i.e. \\(H_0:\\mu=\\mu_0\\). And the alternative hypothesis could be The new campaign has positive effect on promoting sales, \\(H_1:\\mu &gt; \\mu_0\\) in case we take a right-tailed test. Your hypothesis test would result in a decision which either accept the null hypothesis or the alternative hypothesis. Under both cases, there are two possibilities regarding the reality, that is to say, whether the null hypothesis is actually the fact happening regardless of what our test result shows. This leads to the following table where we list these four scenarios: type-one-two-error-table So, to formally define the two mismatch between decision and reality, we name Type I error when the null hypothesis \\(H_0\\) is true, but we reject it. This is also called False positive or False Alarm in other literature. Combined with the former example, that is to say when the campaign is actually not promoting sales, but due to some reason (probably insufficient sample collected / biased user group selection), we reject the null hypothesis and claim the campaign is actually effective. The Type II error is just the opposite case, where we failed to reject the null hypothesis. With that, we can now define significance level as the greatest probability of making Type I error you are willing to tolerate. \\[ \\begin{align} \\alpha &amp;= \\max P(\\text{Type I Error})\\\\ &amp;= \\max P(\\text{Reject } H_0 | H_0) \\end{align} \\] To take a more extreme example, say you a","categories":["Data Science"],"tags":[]},{"title":"Complete walk through of confidence intervals","date":"2024-07-05","path":"2024/07/05/Complete-walk-through-of-confidence-intervals/","excerpt":"In this article, I will provide a complete walk through of a popular\nconcept in data science interviews - the confidence interval, from its\nintuition, definition to actual computation.","content":"In this article, I will provide a complete walk through of a popular concept in data science interviews - the confidence interval, from its intuition, definition to actual computation. Intuition When encountering a new concept, my natural impulse would be to ask the question: how does this concept help in solving real world problem? This concept is introduced to answer the question below: &gt; How to use sample mean to deduce population mean and quantify our certainty? &gt; &gt; Or rather, how can we use sample means with some degree of certainty? What is a confidence interval? Let's set up a fake scenario to see how this means in practical context. Suppose you want to investigate the population's average height \\(\\mu\\) on a island (10,000 people in total). You already obtained a sample with 100 people's height recorded, how to give a quantify the certainty of a population mean deduction? That is to say, we want to obtain a bound for the population mean: \\[ \\text{lower limit} &lt; \\mu &lt; \\text{upper limit} \\] This interval is the confidence interval I want to introduce in this article. To make things simple, let's assume that heights on this island follow a normal distribution with a mean \\(\\mu\\), which is unknown, and a population variance, \\(\\sigma^2\\), which for now will assume is known (\\(X \\sim \\mathcal{N}(\\mu, \\sigma^2)\\)). This may seem weird to know \\(\\sigma\\) without knowing \\(\\mu\\), but it simplifies the problems for now and we will see how to deal with unknown variance later. To generate such a confidence interval, a random sample needs to be taken from the population. To further simplify the setting, we start with a sample of size one. Since the sample has only one person in it, their height will also be the sample mean, which will be called \\(\\bar x\\). Let's create a random variable, \\(\\bar X\\), to describe the probability of selecting different sample means. It's actually going to be identical to the population (\\(X\\)), a normal distribution centered of \\(\\mu\\) with a variance \\(\\sigma^2\\). (\\(\\bar X \\sim \\mathcal{N}(\\mu, \\sigma^2)\\)). This doesn't mean you suddenly know the true value of \\(\\mu\\), but you do know \\(X\\) and \\(\\bar X\\) have the same mean. With this setting, as we can't know for sure whether \\(\\bar X\\) is smaller or larger than the \\(\\mu\\), we do know \"How far are most sample means from \\(\\mu\\)?\" based on the distribution property. To do this, you need two related concepts. The first one is margin of error, which is a distance on either side of mu, and a confidence level, which is the probability that your sample mean is within that margin of error. To set these two values, you actually normally start with a third one called the significance level, which is denoted with a Greek letter \\(\\alpha\\). In practice, \\(\\alpha\\) is usually set to be \\(0.05\\), and the confidence level \\(1-\\alpha\\) yield 0.95, also denoted as \\(95\\%\\). This is the probability that a randomly generated sample mean falls within the margin of error. Since the normal distribution is symmetric around its mean, you can say that 2.5% (\\(\\alpha\\)) of the time your sample mean will lie outside the margin of error because it's too big and 2.5% of the time because it's too small. What does the confidence level stands for? Given \\(n=1\\), Known \\(\\sigma\\) and defined margin of error \\(95\\%\\), when we sample multiple times, there will be approximately 95% of the chance that our confidence interval contains the population mean \\(\\mu\\). Here is a graph illustration of what confidence level stands for. Where we sample multiple times and the green interval suggest the population mean \\(\\mu\\) is in the interval while red interval suggest it does not. In other words, with a confidence level, we could say that the confidence interval contains the true population parameter approximately 95% of the time. What is the effect of changing sample size? We made an simplification to use an sample of size 1 in the previous chapters, you may be wondering how things will change if we change the size of that? First, we need to know, \\(\\mu_{\\bar{x}}\\), or the expected value of the sample mean, always equals \\(\\mu\\), the population mean. This is true no matter how many observations are in your sample. Now consider the standard deviation of the sample mean, \\(\\sigma_{\\bar{x}}\\). We know that it will be equal to the population standard deviation divided by the square root of the number of samples, n, which is (\\(\\sigma / \\sqrt{n}\\)). In this case, it does vary with sample size. Then whats the effect of changing sample size? You may find as the \\(n\\) increase, the fraction \\(\\frac{\\sigma}{\\sqrt{n}}\\) becomes smaller. For a normal distribution, shrinking the standard deviation means the values are more likely to appear near \\(\\mu\\), the central part of the graph. More generally, as n, the sample size increases, the confidence interval shrinks. In other words, as we collect more data, you can make more precise estimates of \\(\\mu\\) without droppi","categories":["Notes"],"tags":["Data Science"]},{"title":"Dealing with structured data - SQL cheatsheet","date":"2024-01-26","path":"2024/01/26/SQL-cheatsheet/","excerpt":"SQL (Structured Query Language) is the backbone of relational\ndatabases. This guide breaks SQL into its five command types‚ÄîDQL, DML,\nDDL, DCL, TCL.","content":"SQL (Structured Query Language) is the backbone of relational databases. This guide breaks SQL into its five command types‚ÄîDQL, DML, DDL, DCL, TCL. What is SQLÔºü Structured Query Language (SQL) is a standard computer language created for accessing and manipulating relational databases like MySQL, Oracle, SQL Server, PostgreSQL, etc. SQL could perform the below commands on relational databases: Retrieve and filter data Insert, update, and delete records Create and modify database structures Manage permissions and transactions Commands Category Name Purpose Examples DDL Data Definition Language Create or modify database structures CREATE, ALTER, DROP, TRUNCATE DQL Data Query Language Query data SELECT DML Data Manipulation Language Manage data INSERT, UPDATE, DELETE DCL Data Control Language Manage access and permissions GRANT, REVOKE TCL Transaction Control Manage transactions COMMIT, ROLLBACK, SAVEPOINT Note: DCL and TCL is not covered in this post. Syntax SQL is case-insensitive: SELECT and select are identical. Some database systems require a semicolon (;) at the end of each SQL statement. A semicolon is the standard way to separate SQL statements in database systems, enabling multiple statements to be executed in a single request to the server. SQL uses single quotes (' ') to enclose text values. Comments: Single-line: -- Multi-line: /* */ Data Query Language - DQL SELECT To retrieve data you use the command SELECT. At its core, you select the columns you want to see from the table they're contained in. 1234567cities| city_id | City | Country || ------- | -------- | ------------- || 1 | Tokyo | Japan || 2 | Atlanta | United States || 3 | Auckland | New Zealand | 1234567SELECT cityFROM cities;-- Output:-- Tokyo-- Atlanta-- Auckland Use sub-clause to narrow down the rows WHERE WHERE are used for filtering result table. Basic Syntax: SELECT column1, column2,... FROM table_name WHERE condition; To write a condition, we can use the below operator to form an expression. Operator Description e.g. = equal column=value &lt;&gt; not equal. In some version could be != column&lt;&gt;value &gt; larger than column &gt; value &lt; smaller than column &lt; value &gt;= larger or equal to column &gt;= value &lt;= smaller or equal to column &lt;= value BETWEEN... AND filter values within the range column between a and b LIKE search for a pattern (most common for strings) column LIKE '%k' (ending with k) IN multiple possible values for a column column IN (value1, value2, ...) ORDER BY ORDER BY are used to sort the result table. The table is sorted in ascending order by default. When sorting by multiple columns, the order of columns affects the result. The sorting is performed on column1 first, and then column2 is sorted based on the order preserved by column1. Basic Syntax: 123SELECT column1, column2, ...FROM table_nameORDER BY column1, column2, ... ASC|DESC; GROUP BY GROUP BY are used together with aggregation function: - AVG() - return the average - COUNT() - return the number of occurrence - FIRST() - return the first record - LAST() - return the last record - MAX() - return the maximum value - MIN() - return the minimum value - SUM() - return the sum Basic Syntax: 1234SELECT column_name, aggregate_function(column_name) FROM table_name WHERE column_name operator value GROUP BY column_name; HAVING HAVING 's usage is just like WHERE, the main difference is WHERE filters rows in the table, while HAVING filters groups. Therefore, we can have a below query, we want to list suppliers who supply two or more products, each priced at 10 or more. 12345SELECT supplier_idFROM productsWHERE price &gt;= 10GROUP BY supplier_idHAVING COUNT(*) &gt;= 2; JOIN To retrieve data from multiple tables, we use command JOIN to combine records from different tables and use ON to indicate columns for the seam. 1234567891011121314rainfall| rainfall_id | city_id | Year | Amount || ----------- | ------- | ---- | ------ || 1 | 1 | 2018 | 1445 || 2 | 1 | 2019 | 1874 || 3 | 1 | 2020 | 1690 || 4 | 2 | 2018 | 1779 || 5 | 2 | 2019 | 1111 || 6 | 2 | 2020 | 1683 || 7 | 3 | 2018 | 1386 || 8 | 3 | 2019 | 942 || 9 | 3 | 2020 | 1176 | 12345678910111213SELECT cities.city rainfall.amountFROM cities INNER JOIN rainfall ON cities.city_id = rainfall.city_idWHERE rainfall.year = 2019-- Output-- city | amount-- -------- | -------- Tokyo | 1874-- Atlanta | 1111-- Auckland | 942 SQL-joins-example Type Description INNER JOIN Returns records that match in both tables (intersection). LEFT JOIN Returns all records from the left table, with matched records from the right table (preserves left table). RIGHT JOIN Returns all records from the right table, with matched records from the left table (preserves right table). FULL OUTER JOIN Returns all records from both tables, including unmatched ones (union). CROSS JOIN Returns the Cartesian product: each row from the left table paired with each from the right. SELF JOIN Joins a table with itself. NATURAL JOIN Automatically joins tab","categories":["Notes"],"tags":["Data Science","SQL"]},{"title":"Recommender Series 1 - Overview","date":"2023-11-21","path":"2023/11/21/Recommender-overview/","excerpt":"In this article, I will give an overall introduction about\nrecommenders, including how the recommendation problem arises, the\nabstract models and the key problems when building a new\nrecommender.","content":"In this article, I will give an overall introduction about recommenders, including how the recommendation problem arises, the abstract models and the key problems when building a new recommender. Background As we step into the information era, there are a increasing number of products, movies, music, short videos, etc. that is either virtual content itself or was provided online shopping option instead of onsite. This paradigm shift from scarcity to abundance took place as virtual content provider and online stores gained more advantages in the cost of inventory storage and distribution compared to traditional retailers (onsite shops). We have developed two ways to interact with these abundant virtual catalogues, which are: Search (When the user know what they want to find) Recommendation (when the user does not know what they want to find) Since there seems to be more profit by selling small volumes of hard-to-find items to many customers (the long tail part) instead of only selling large volumes of a reduced number of popular items (the head part), companies are refining their business strategy based on the Long Tail model (as described in the image below). That is to say, by customizing the content (in the long tail) presented to the user, increase the chance of product sell or consumption. This requirements necessitates better filters, that is to say, the Recommender or recommendation system. Long Tail model.png Types of recommenders There are several general types of recommenders arose under different context: Editorial and hand curated Some example of this type of recommendation includes \"List of favorites\", \"List of essentials\". This type of recommender has a significant drawback: there is no input from the user sides. The recommendation relies entirely on the selection of the website editor, and there is no usage of the user interaction data. So this approach is not used in modern application with a lot of user generated content and data. Simple aggregates Examples of these aggregates includes \"Top 10 XXX\", \"Most popular\", \"Recent uploads\", etc. This type of recommender simply perform some grouping actions on the consumption data, but it is still not customized to specific users. However, this approach is useful to deal with the Cold Start problem when a new user joined with no previous interaction data, so you could still see these sections in applications today. Tailored to individual users This is the type of recommender that most applications used today by taking individual user's interaction as input and output content tailored to their taste, which I will to discuss further in future posts. General models When defining later recommenders, we usually have a structure with the following data: \\(C\\) = set of Customers \\(S\\) = set of Items Utility function \\(u: C\\times S \\rightarrow R\\) \\(R\\) = set of ratings ( is a totally ordered set) E.g. 0-5 stars, real number in [0,1] Utility matrix - \\(U\\) = the matrix form of the above utility function. Usually we have items listed on columns, user listed on rows, where the entry \\((i,j)\\) corresponds to the user \\(i\\)'s rating on \\(j\\)-th item. Key problems By defining the general models above, we could derive some of the key problems that we need to handle when building recommenders. 1. Gathering \"known\" ratings to form the utility matrix The problem is then - How to collect the data in the utility matrix? We need to take the cold start problem into consideration. That is to say, for new items with no ratings or for new users with no history, we need to derive different strategies. For example, some applications may let you choose the area you are interested in during the registration process. More and more new item are now tagged with genre / producer / director / actor all kinds of metadata to help it fit into the current database. To solve the collection problem mentioned above, the industry has two types of solutions: Explicit That's ask people to rate items after purchase or consumption. This is a very direct way to get ratings, however it has the drawback of it doesn't scale as not many users would like to provide ratings or detailed feedback. Implicit To handle the scaling aspect of the data, industry (based on their products) have designed various algorithms to interpret ratings from user interactions. For example, companies like TikTok will track the type of videos that you like to view more and perform corresponding recommendation. Nevertheless, it is still hard to learn low ratings (as users tend not to interact with items they dislike). 2. How to extrapolate \"unknown\" ratings from the known ones? This is the key part of \"recommendation\" where the system based on past user interaction data to infer user's most likely interested items and present it. It is also the main focus of different recommender architecture and algorithms. For example, there are recommendation methods like and will be discussed in later posts: - Content-based filtering - C","categories":["Notes"],"tags":["Computer Science","Data Science"]},{"title":"SD - 3. How to use diffusion web ui? - Scripts, Extras, Extensions","date":"2023-05-21","path":"2023/05/21/How-to-use-diffusion-web-ui-Scripts-Extras-Extensions/","excerpt":"In this post, I will briefly walk through some of the auxiliary\nfunctions provided in stable diffusion web ui for earlier idea testing\nand experience enhancement.","content":"In this post, I will briefly walk through some of the auxiliary functions provided in stable diffusion web ui for earlier idea testing and experience enhancement. Script At the beginning of generation, it is often the case that you need to test different prompts and parameter settings. Besides manually trying all combinations, webui has built-in scripts that automates this process. This feature could be enabled by selecting the corresponding scripts. The script could be selected at the bottom-left corner of the webui. diffusion webui script location Prompt form file or textbox Used for testing different prompts using files or handwritten prompts. It's pretty easy and straightforward to use so I would leave it for you to play with. prompt matrix Overview Used for testing different tags' (in prompt) influence on the generation result. This feature could be further enhanced by the extension dynamic-prompts Below is a screen shot of the available settings. diffusion-webui-prompt-matrix-script For those interested in reading the source code, check here Usage To properly invoke this plugin, you need to append the tags you want to experiment with | symbol, follow the format below: ```txt basic_prompt, | tag1 | tag2 | ... 12345678- Put a `|` symbol before each tag you want to try solely, and separate other tags using `|`.- I used `tag` here for simplicity, but you could also try prompt snippets.- In this way, prompt matrix would try the below combinations - ``` basic_prompt, basic_prompt, tag1 basic_prompt, tag2 basic_prompt, tag1, tag2 Example You could find the tags used is displayed in bold, while the tags not used are underscored One common thing you want to experiment with is probably the style of the output. Here is an example, I tried different medium of generating a girl's portrait with the following prompt 1girl, masterpiece, | pencil sketch | oil painting | photo | watercolor diffusion-webui-prompt-matrix-result-1 Another thing you may want to try is that whether certain tags are taking effects. Here is another example, I tried different quality tags 1girl, | masterpiece | best quality | extremely detailed diffusion-webui-prompt-matrix-result-2 Or you want to try different lighting options 1girl, RAW photo, masterpiece, best quality, extremely detailed, | spotlight | rim lighting | sunlight | natural lighting diffusion-webui-prompt-matrix-result-3 I would strongly recommend this website - promptmania if you are struggling with finding suitable tags for a specific aspect of the generation (e.g. medium, lighting, camera setting, etc.). This website providers wonderful visual cue for different tags. promptmania-example-screenshot XYZ plot Overview Used for testing different parameter settings Below is a screen shot of the available settings. diffusion-webui-xyzplot-script For those interested in reading the source code, check here Usage The interaction logic is straightforward, select the parameter you would like to play with, fill in the values by hand or use the üìí icon to automatically import all available options (for checkpoints, sampler, etc.) In my previous blog, I used this script for doing experiments with testing different checkpoints' performance and parameter setting's impact. Example usage Test different models performance on a given prompt diffusion-webui-xyzplotscript-different-model Test different parameter settings' impact (like sampling steps, CFG scale) X type = CFG scale, X values = 3,5,7,9 diffusion-webui-xyzplotscript-different-CFG-scale X type = Steps, X values = 10,20,30,40 diffusion-webui-xyzplotscript-different-sampling-steps Test different parameter combinations. By the way, it is often best practice to use recommended sampling method. X type = Checkpoint name, X values = filled Y type = sampler, Y values = filled diffusion-webui-xyzplotscript-different-model-sample-combination Auxiliary tabs Skip the training related part for a later post (like checkpoinst merger, training, etc.) Extras This step is dedicated for upscaling images. It plays a similar role as txt2img tab's hires fix, or img2img tab's SD upscale script diffusion-webui-extra-tab-screenshot Upload a image and choose a upscaler for the task. RealESRGAN_x4plus_anime_6B is good for animation characters realesr-general-wdn-x4v3 is good for realistic characters or scenery. When an upscaler is used for the first time, it may take some time to download. If failed to download for some reason, check this website to download upscaler manually (and place them in stable-diffusion-webui/models/ESRGAN/ - not sure about all other upscaler, but worked for the above two) PNG info A useful tab for extracting generation data stored in images. diffusion-webui-example-pnginfo-tab Enable setting to store the generation data In the Settings tab, check the following path saving images/grids &gt; Save text information about generation parameters as chunks to png files You would then be able to retrieve generation data. Extensions Used to insta","categories":["Tutorial"],"tags":["Artificial Intelligence","Diffusion"]},{"title":"SD - 2.How to use diffusion web ui? - img2img","date":"2023-04-25","path":"2023/04/25/How-to-use-diffusion-web-ui/","excerpt":"In this article, I will provide a walkthrough of common features on\nimg2img tab.","content":"In this article, I will provide a walkthrough of common features on img2img tab. I will first go through some unique parameters for this tab, then provide my workflow on use cases like outpaint and inpaint. stable-diffusion-webui-img2img-tab In img2img tab, images could be used as additional input as the guide for generation. This enables a bunch of useful cases. For exmaple, you could use realistic photo to generate your animation figure, or use hand-drawn sketch to create good looking pictures. Unique parameter For most of the part, img2img tab shares an identical parameter list as txt2img tab, please check my previous post for more detail. Additional parameters are used to customize the process of input images. Resize mode This defines the behavior when the input image size is not same as the one you indicated. Just resize resize the image to target resolution. This may lead to incorrect aspect ratio Crop and resize Resize the image so that entirety of target resolution is filled with the image. Crop parts that stick out. Resize and fill Resize the image so that entirety of image is inside target resolution. Fill empty space with image's colors Just resize (latent upscale) same as the first one, but uses latent upscaling method (without a scaler, just latent decoder) - Ref Denoising strength Range in [0,1]. This defines the similarity between the generated image and the original one. The larger / the closer to 1, the image would likely to take less features fro the original input. Usages Style Transfer Use your image as input, adding prompt, choose the right style model, and AI will do the magic. Below is a showcase of using a same prompt and image input with different models gives different style output. img2img-example-sketch Image Source image.png img2img-sketch-example-people Sketch image source image-20230418221414301 I have to admit that I used ==ControlNet== for the basic image structure control. With only image and text guidance, you will get pretty randomized output, like the one below. image-20230418221837294 Inpaint - Fix / Modify selected parts of the image Mask the part you want to re-generate, modify the prompt a bit, you could fix those faulty parts or let the AI inspires you. Inpaint processing logic Select Mask Area Pre-process masked area Add mask blur Image generation Parameter settings Prompt Prompt for the masked area (or the not masked part) Could reuse the prompt when generating original images Mask Blur To what extent should the masked area should be blurred, influence the third steps above The higher the value, the lower the degree of ambiguity stable-diffusion-inpaint-different-mask-blur-sample Mask mode Tell the model which area to inpaint Masked content Defines how to preprocess masked area (refer to logic step 2) fill Based on the image color, use blurred color block to replace the original image. original No pre-process, directly use original images latent noise Use latent noise (the AI's interpretation of input prompt) to fill latent nothing Use a zero-valued latent variable to fill selected area Normally, fill &amp; original are used for minor improvements. latent noise and latent nothing are used to generate something new with significant difference. Inpaint area Whole picture After inpainting, refer to the width and height, resize mode to adjust the image. Only masked Only repaint the masked area Better for high resolution images, no need to set width and height Only masked padding, pixels When inpaint area = only masked, defines the masked area's pixels count. The smaller the value, the higher the density of filled pixels. The higher the density, the more content it will be generated - may lead to the generation of a new image based on your prompt in the inpaint area. Other inpaint mode inpaint sketch add color guide to the mask, could adjust the guidance strength by mask transparency inpaint upload problems of normal inpaint Mouse does not easily apply problem areas with precision One-time masking does not stay Inpaint upload tab allows you to upload an image and a prepared mask image Note The mask is black and white, ==white== represents the mask selection area Leave some inner space for inpaint area Outpaint - Expand existing image Under certain circumstances, you may want to expand an existing image. This is when outpaint script come into play. In the bottom left corner, you could find a drop down list for Outpaint script, which by default has two versions, normally we use Outpainting mk2 version for more stable result. Parameter settings stable-diffusion-webui-outpainting-script-ui For both scripts, there are two common settings - Pixels to expand, and Outpainting direction. This is pretty straightforward to understand. For Outpainting mk2, mask blur is applied to the outpainted part during preprocess to create a soft boundary between original image and the expanded part. Fall-off exponent controls the ‚Äúsmoothness‚Äù of the masked picture (one to be expanded). A high","categories":["Tutorial"],"tags":["Artificial Intelligence","Diffusion"]},{"title":"Thinking about LLMs and Multi-modality","date":"2023-03-21","path":"2023/03/21/Thinking-about-LLMs-and-Multi-modality/","excerpt":"In this post, I would discuss some of my thoughts on Multi-modality\nand future LLMs directions. Welcome to post your thoughts in the\ncomments and discuss with me.","content":"In this post, I would discuss some of my thoughts on Multi-modality and future LLMs directions. Welcome to post your thoughts in the comments and discuss with me. Thoughts on Multi-modality Since OpenAI (GPT-4) and Baidu (Wen Xin Yi Yan) released LLMs with different design for multi-modality. GPT-4 unifies the embedding representation between text and images, while WXYY seems to unify the ability to generate different medium content (text, image, voice and video). In my point of view, multi-modality should support machine's comprehension by encoding different medium into a unified latent space, bridging the information between different modality. It is a progressive simulation of human's learning approach, from reading only to read and see. In Xiaotong Fei's perspective (Chinese anthropologist and sociologist) from nearly 80 years ago, written language has intrinsic deficiency which could convey only incomplete and ambiguous meanings compare to real life situation. For example, we could tell from voice who is visiting us, or from body language to understand other's emotion. It is therefore natural to gradually integrate the ability to take in and understand different medium as AI develops. By quoting Xiaotong Fei's ideas years ago, I want to emphasize that we could to draw inspirations from studies which tries to explain how human learns and perceives. Artificial Intelligence, should always be rooted in the study of human intelligence. Current LLMs Situation Not hitting human-level intelligence yet. Though it perform well in exams and chatting, it is still not good tasks like few-shot learning, long text comprehension and factual generation. GPT-4 performed well in many exams. Though it's not human-level intelligence yet, it is time when we start to think about the essence of human intelligence, or more specific, what makes us human unique compared with LLMs. Human‚Äôs unique competence in AI‚Äôs perspective Here is the answer GPT-4 gave me (which I used my holistic understanding to summarize them into the below key points). OpenAI also published a relevant study about LLMs' impact at the labor market. #### Empathy and Emotion intelligence Ability to understand, respond emotions. Collaboration Collaborate and work as a team with others, combining individual strengths. Creativity and imagination Think divergently, create original ideas and innovative plans, imagine novel concepts. In AI generated art for instance, we could see the potentials of human imagination empowered by a drawing tool that understands human prompts. Adaptability and learning Adaptability is kind of few-shot learning capability. Humans could adjust fast to new situations and environments. Intuition and decision-making Making decisions with incomplete information. Similar to the concept tacit knowledge. Morality and ethics AI lack a true understanding of moral and ethical values. Holistic understanding Ability to integrate information from various sources and modality to form a holistic understanding. Critical thinking Ability to evaluate information based on logic and intuition. Context and common sense Understanding of the problem situation and make reasonable judgements. Future LLMs directions Guesses based on current LLM's deficiency. Multimodal comprehension to enable different interaction methods. Multi-modal comprehension could enable more training data for models. Imagine AI learns how to do carpenter work by watching a 3D video of a master carpenter. Explainability Understanding different part of LLMs, why and how they draw certain conclusions, could help eliminating hallucination. Safety Fact-based, combined with thought chain for inference Generate more accurate content could prepare AI for more responsible positions. Detecting AI generated content. Being able to judge AI generated content is essential when the generated content contains hallucination. Related Research - Guo et al., 2023 Ensure data privacy during training / fine-tuning Debates about what data could be used during training. Consensus needs to be drawn. Online GPT models may be attacked Indirect prompt injection by human invisible content on web. Accessibility Model distill technology could be used to lower the cost of use. We could also see a lot of contributions from the academia and tech companies aiming for democratic training and inferencing for LLMs. Meta proposed a series of LLMs trained based on publicly accessible data only - LLaMA Official Repo, which uses a lot fewer parameters to achieve similar results compared with large ones. More detail in the paper Stanford research group follows the previous research and fine-tuned a better performing model Alpaca. A new optimisation of LLaMA was proposed in this repo which allows Mac to run the large model. Bionic Structure? For now, LLMs seems to be stacking transformers (or say GPUs) to achieve better performance. I suppose we could improve the performance by using different networks combinations (change of arch","categories":["Informal Essays"],"tags":["Artificial Intelligence","Generative AI"]},{"title":"SD - 1. How to use diffusion web ui? - txt2img","date":"2023-03-07","path":"2023/03/07/How-to-use-diffusion-web-ui-txt2img/","excerpt":"In this article, I will provide a walkthrough of common features on\nstable diffusion webui's txt2img tab and how to use them to produce\nbetter quality pictures as you wish.","content":"In this article, I will provide a walkthrough of common features on stable diffusion webui's txt2img tab and how to use them to produce better quality pictures as you wish. Common Parameters Below is a screenshot of stable diffusion web ui. I will walk through this interface left-to-right, top-to-bottom. stable-diffusion-webui-txt2img-tab-screenshot P.S. If you want to set your web ui to dark theme, you could either change your website url to your_url_goes_here/?__theme=dark or pass a parameter when launching webui by python launch.py --theme dark Checkpoints Checkpoints (or more commonly referred as models) provide customizations for different styles. Why there are different checkpoints? Checkpoints are further trained on the base diffusion model provided by stability AI to obtain better results with high quality images or enhance the performance on certain styles. For example, I used a model called Realistic Vision, which is optimized for real photo generation and provides better results compared to the base model. Pick your model up on civitai and put it under stable-diffusion-webui/models/stable-diffusion folder to load. A list of recommended models Realistic Vision - for photography like, realistic images deliberate - A great model for general purpose, with sufficient tags, you could get great results ranging from 2.5D images to 2D animation style images or even flat illustration images. VAE P.S. I modified the settings to bring up these two selections, if you are interested, check Settings &gt; VAE stands for variational autoencoder, which transform the images from latent place (the computer/model representation of images) to human-readable format. A wonderful tutorial could be found here. I would share a comparison of using or not using VAE in a later advanced usage post. LoRA LoRA stands for Low-Rank Adaptation, which is actually a technique used to fine-tune large language models (LoRA paper). In this context, you could treat LoRA as a smaller version of checkpoints which provide style guide or particular character guide. You could also find LoRA on civitai. Prompt The cue passed to model for image generation, this is the most important part during generations. Separated into 2 parts in webui: positive prompt (what you want) negative prompt (what should be avoid) How to write good prompts? Prompt could be roughly divided into two parts based on word count: textual descriptions and tags. Different models have different support for the two categories‚Äô prompt input. Different models may even have different weights on a same tag. It‚Äôs better to check the models‚Äô description and example prompts from community to better your generations. Format () - multiply the weights of enclosed tag(s) by 1.1, could be nested ((tag)). [] - divide the weights of enclosed tags by 1.1. : - used directly after the tag to define the weightsÔºåe.g. pink:1.4 For more formatting guides, check the webui wiki page. Templates for textual descriptions Descriptions are normally a sentence, describing the subject, the on-going event, the type of pictures, etc. ‚ÄúA [type of picture] of a [main subject], *[style cues]**‚Äù Ref - E.g. A portrait of a 25 y.o. young man, uhd Tags Tags are short, symbolic words that represents a specific type of image or element. It could be roughly divided into 3 categories: Quality tags: like masterpiece, highres (high resolution), best quality. Usually Content tags: restrict the content of the image, 1girl, RAW photo in positive prompts or mutated hands, missing fingers in negative prompts Subject tags: clearly defines what the subject should be like. For example, when generating a anime character, tags like black hair, yellow eyes, lab coat, standing,looking at viewer could be used for precise generation in terms of appearance, clothing and pose. P.S. Despite using tags, ControlNet could be another way to control the pose for character generation. Please wait for my advanced tutorial post, or check this wonderful video tutorial first. Commonly used tags Positive tags: masterpiece, 1girl, highres, ultra detail, etc. Discover the tags that fits your need on Diffusion Model site's example prompts. Or found interesting prompts use the search engine Style tags/templates - Realistic Image - RAW photo, 8k uhd - Postive Prompts 1RAW photo, *subject*, (high detailed skin:1.2), 8k uhd, dslr, soft lighting, high quality, film grain, Fujifilm XT3 - Negative Prompts 1(deformed iris, deformed pupils, semi-realistic, cgi, 3d, render, sketch, cartoon, drawing, anime:1.4), text, close up, cropped, out of frame, worst quality, low quality, jpeg artifacts, ugly, duplicate, morbid, mutilated, extra fingers, mutated hands, poorly drawn hands, poorly drawn face, mutation, deformed, blurry, dehydrated, bad anatomy, bad proportions, extra limbs, cloned face, disfigured, gross proportions, malformed limbs, missing arms, missing legs, extra arms, extra legs, fused fingers, too many fingers, long neck Commonly used negative tags: 1","categories":["Tutorial"],"tags":["Artificial Intelligence","Diffusion"]},{"title":"SD - 0. How to set up your diffusion webui?","date":"2023-02-28","path":"2023/02/28/How-to-set-up-your-diffusion-webui/","excerpt":"In this article, I will present a step-to-step guide to help you set\nup stable-diffusion-webui uploaded by automatic1111.","content":"In this article, I will present a step-to-step guide to help you set up stable-diffusion-webui uploaded by automatic1111. Pre-requisite Large AI models perform better on GPUs, check your GPU's version by running nvidia-smi command. This would allow you to check your CUDA version (kind of GPU driver), which will be used in later package selection. Check you have installed Python and git. By command python --version &amp;&amp; git --version you could check whether they are installed. If you haven't installed Python, you could check the official website to download the package(^^3.9+ version with installer recommended!^^). If you haven't installed Git, check the Official website to download the package. Choose your model Models often require some time to be downloaded, so it's prudent to start downloading the models and then continuing to setup your environment. Here is some resources for diffusion models The official version of stable diffusion 2 on HuggingFace A website with fine-tuned checkpoints Fine-tune is a technique for further fitting the base AI models to the given style or performing better on a specific task. Set up your environment One popular repository for diffusion is the stable-diffusion-webui by AUTOMATIC1111 Run the command below under the directory where you want the application to be placed. 1$ git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui.git Automatic Download Following the instructions in the README, you could either run webui-user.bat (Windows Users) or webui.sh (linux user by bash webui.sh) to automatically download the required packages Manual Download Create a virtual environment for the required packages using conda. create a new conda environment with command 1234// You could change the word after -n // to customize the environment name$ conda create -n diffusion$ conda activate diffusion Download the corresponding pytorch package (the CUDA version) using the command from official website For example, if your CUDA version is 11.4, run the below command 1$ conda install pytorch==1.12.1 torchvision==0.13.1 torchaudio==0.12.1 cudatoolkit=11.3 -c pytorch Run python launch.py and let the script install the other packages for you. Or you could run pip install -r requirements.txt. If failed to launch, you could Manually download the repository git clone https://github.com/Stability-AI/stablediffusion.git Install the required package according to Requirements - skip the pytorch installation run pip install -e . in the directory Place your models After you could run python launch.py with no error, put the downloaded model under stable-diffusion-webui/models/Stable-diffusion/ directory, then you should be able to adjust the model on the top left corner. You are ready to go! Make sure your conda environment is correctly activated, then copy and paste the command python path/to/your/webui/folder/launch.py For prompt reference, you could dive into different communities and use this wonderful search engine. In a later article, I will present more detailed introductions to the different components of diffusion models (like inference steps, sampling methods and so on). You could also reference to the wonderful tutorials on Stable diffusion webui wiki for advanced features.","categories":["Tutorial"],"tags":["Artificial Intelligence","Diffusion"]},{"title":"Thinking about Generative AI","date":"2023-02-14","path":"2023/02/14/Thinking-about-Generative-AI/","excerpt":"In this post, I would give a brief introduction of recent popular\ngenerative AIs, and then dicsuss some of its pros and cons.","content":"In this post, I would give a brief introduction of recent popular generative AIs, and then dicsuss some of its pros and cons. Introduction of recent popular models In the past year, Generative AI (or AIGC) captured massive attention from all over the world. From Stable-Diffusion to various versions of Text-to-image models in the first half, and ChatGPT to Bing-GPT in the second half, there seems a new level of intelligence has been achieved. Out of the spotlight, AlphaCode and CodeX has been used to boost programmer's productivity. AlphaTensor successfully discovered a new matrix multiply algorithm. After several years of development in deep learning field, Artificial Intelligence has made a remarkable step forward in multiple areas. For more generative AI, please refer to Gozalo-Brizuela and Garrido-Merchan's Work, in which they give an comprehensive overview of different generative AIs and a brief introduction of various models. The categorization based on input and output of models split the recent research into 9 categories as follows: - text-to-image - text-to-3D model - image-to-text (image summary) - text-to-video - text-to-audio (also called TTS) - text-to-text (summary, comprehension, translation, etc..) - text-to-code - text-science - Others I am not going to give a detailed introduction to the technology behind each model, but discusses the pros and cons of some of the representative models and what to do with this irreversible trend. Diffusion models - Artists Some example images diffusion model generated - obtained from Lexica.art, a wonderful image search engine for generated images .column { float: left; width: 33.33%; padding: 5px; } .row::after { content: \"\"; clear: both; display: table; } In case you haven't try these awesome models, below are some resources of ready-to-use models MidJourney Discord Channel HuggingFace model Pros Quick to draw. Compared to human artists, AI could generate an image in less than 10s. Adjustability. It may be hard to change the pose, the cloth or other details about the figure, but for AI, changing a few tags could have this effect. One could use impaint to erase some part of the picture and re-generate. Modifying a few tags could also change the style of the painting significantly. Image-Image imitate capability. Take an image as input, generate a new image based on the given one and the prompt. This feature allows people to create personalized portrait for themselves. Cons Prompt engineering needed. As the model name (text-to-image) suggests, one need to provide a description for the desired image. Though many products has encapsulated some prompt engineering work, it is still user's responsibility to understand the basic prompt structure and (know and )choose the tags they need for certain styles. Here are some guides for you to write efficient prompts: Stable-diffusion demonstration blog How to write smart prompt? How to write diffusion prompt - Google docs Prompt Generator Serious copyright issues This topic is much debated, and most AI companies are vague about rights of the generated images (correct me if I got this wrong). Laws or industry rules are still unclear about to which extent of resemblance should we consider an image is plagiarized. Some may debate that it is plagiarism for using copyright protected images as the training input! Unsure quality If you are using raw models, it is common to get poorly drawn hands, fused fingers or more than 2 feet figures. The impact of different sampling method, CFG scale (how strictly model adhere to prompt) and sampling steps is significant. These things all add up to unsure quality for unskilled user of diffusion models. A possible negative prompts I collected on the internet: 123# Negative prompts (poorly drawn hands), (poorly drawn face), weird, (((fat))), ((cropped)), ((fused fingers)), ((too many fingers)), (malformed limbs), (((bad anatomy))), ((ugly)), out of frame, blurry, gross propotions, distorted face, distorted body, ((distorted fingers)), missing leg, more than 2 leg, more than 2 feet, more than 2 arms, text, ui, signature, icon, watermark, misplaced limbs, leg too big, leg too small, fused hands, fused arms, distorted backgroud, fused buildings, ((finger too short)), more than 1 right hand, more than 1 left hand, wrong direction of limbs, wrong direction of legs, wrong direction of feet, misplaced facial features, unbalanced facial features, ((body too long)), ((arm too short)), (poorly drawn joint), misplaced joint, wrong joint angle, disappearing legs, disappearing arms, disappearing limbs, ((fused limbs)), thumb too long, fingers too long, missing hands, missing arms, ((misplaced animal tail)),less than 2 ears, ((more than 2 ears)),(watermark) What to do against Visual Generations? With the rapid development of text to image models, what's the unique advantages of humans that could hardly be replaced in the short time (as for now)? How to cope with such situation? Embrace the change, use as","categories":["Informal Essays"],"tags":["Artificial Intelligence","Diffusion","Generative AI","ChatGPT"]},{"title":"An introduction to KMP algorithm","date":"2023-02-10","path":"2023/02/10/An-introduction-to-KMP-algorithm/","excerpt":"In this post, I will introduce the string matching problem, and a\nclever solution - KMP algorithm. I start from the brute force method and\nshowed how to deduce KMP.","content":"In this post, I will introduce the string matching problem, and a clever solution - KMP algorithm. I start from the brute force method and showed how to deduce KMP. Introduction String Matching Problem Given strings S(length m) and T (length n), find T in S. The string T called pattern. Wide Applications, essential role in various real-world problems. Text processing: spell checking, text classification, information retrieval (especially in NLP field). Pattern recognition: bioinformatics, speech recognition Database management: used to searching and retrieving efficiently. KMP algorithm This is an algorithm designed for the above problem, which is time efficient. Summary of key ideas in KMP (for those are familiar with string matching problem): reduce the total comparison round --&gt; utilize the information gained after each failed comparison exploit the information of the pattern string --&gt; maintain an array for storing useful information. Brute Force method Before dig into KMP algorithm, let's look at the method which defines the lower limit of the performance. 12345# Brute force algorithm for string matchingdef bruteForce(S, P): for i in range(len(S) - len(P) + 1): if S[i : i + len(P)] == P: print(f&#x27;Find a matching point at position &#123;i&#125;&#x27;) # f-string 12345678910111213141516void bruteForce(char *s, char *p) &#123; int lenS = strlen(s), lenP = strlen(p); for(int i = 0; i &lt;= lenS - lenP; i++) &#123; boolean flag = true; for int(j = 0; p[j] != &#x27;\\0&#x27;; j++) &#123; if(s[i+j] != p[j]) &#123; flag = false; break; &#125; &#125; if(flag) printf(&quot;Find a matching point at position %d\\n&quot;, i); &#125;&#125; The intuition is pretty straight forward, we match the string character by character, if no failed matching till the end of the pattern string, then a successful matching was found. Then for the entire string, we place the pattern string at the start of each character in S string, then perform the above the step. Analysis The step 1 takes |P| (length of pattern string, usually marked as n) time, and the step 2 takes |S| (length of original string) time, we could easily conclude the time complexity is \\(O(|P| \\cdot |S| )\\). Why is it so slow? Or where could we improve? Apparently we could not optimize the comparison process at step 1 , to check a match we need to perform a full comparison. Naturally we turned to think if we could reduce the round for matching in step 2. Look at the example below: image.png After the above failed comparison, the brute force would start a new round of comparison at S[1],S[2]. These attempts is obvious to fail. The KMP algorithm therefore proposes a mechanism to skip these impossible matching. The resulting process should be like this: (white colored means comparison skipped): image.png Deducing the KMP algorithm Partial Matching Table Following the intuition of skipping impossible matching, we need to find a mechanism to decide which ones should be skipped. The KMP algorithm proposed a structure called partial matching table, which stores the information we need. The partial matching table has the same length as the pattern string, denoted as next[]. Given the length of P is n, next[i] represents If substring p[0..i] has a pair of identical prefix and suffix (p[0..k-1] == p[i-(k-1),..i]), then next[i] = k For example for the pattern string abcabcd,we have next[i] = [0,0,0,1,2,3,0]. When i = 5, the string is abcabc, therefore we could get identical pair abc, where the length is 3 You may have noticed, with next[] array calculated, we could skip impossible matchings by referencing the next[] array. As shown in below example image.png When we failed the first match at P[3], we replace the P[1] on the mismatched index and restart the matching. When failed the second match at P[6], we replace P[3] on the mismatched index. From above we could conclude, we utilize the identical prefix and suffix for skipping some comparisons. Say the mismatch occurs at P[i], then between P[0]~P[i-1], the former next[i-1] character(s) should be the same as the latter next[i-1] character(s), so we could replace the suffix with the prefix. In conclusion, we could realign P[next[i-1]] with P[i]. In other word, the next[] array provides reference for how to skip comparison and how many comparison to skip. 123456789101112131415161718# Suppose we have calculated the next[] arraydef search(): s_pointer = 0 p_pointer = 0 while s_pointer &lt; len(s): if s[s_pointer] == p[p_pointer]: # If matched, increment both pointers s_pointer += 1 p_pointer += 1 elif p_pointer: # mismatched at p[p_pointer], move p_pointer p_pointer = next[p_pointer-1] else: # mismatcher at p[0] s_pointer += 1 if p_pointer == len(p): print(f&#x27;The matching start point is &#123;s_pointer - p_pointer&#125;&#x27;) p_pointer = next[p_pointer - 1] How to analysis the complexity of this step? We could use amortized analysis, the s_pointer could increment at most len(s) times, therefore the time complexity is ","categories":["Notes"],"tags":["Algorithm","Computer Science"]},{"title":"Knowledge Graph, An Introduction","date":"2023-02-02","path":"2023/02/02/Knowledge-Graph-An-Introduction/","excerpt":"In this post, I would provide an introduction to Knowledge graph,\nprovide information about its definition, construction, storage and\napplication.","content":"In this post, I would provide an introduction to Knowledge graph, provide information about its definition, construction, storage and application. Definition What is Knowledge Graph (KG)? Knowledge graph is a symbolic, structured semantic network used to store entities and their relations. Basic Components Entity The node in knowledge graph. Used to represent people, events or things. Relation The edge in knowledge graph. Used to represent relations between defined entities. Property Additional information attached to node or relation. Examples Based on different context, entity and relations could be varied. Below are three examples for possible designs. Medical KG Entity - Disease, Drug, Food, Cure method, Department Relation Disease --[recommend_use]--&gt; drug Disease --[recommend_eat]--&gt; food Disease --[accompany_with]--&gt; Disease Property Disease - cause, cure_last_time, susceptible_groups,... Financial KG Entity - Company, Person (Management), Fund, Industry Relation Company --[has_manager]--&gt; Person Company --[in_industry]--&gt; Industry User Profile KG Entity - User, Event (could be further divided to different categories based on user's interaction / data gathered), Company Relation User --[is_friend | is_lover]--&gt; User Event --[]--&gt; User User --[work_for]--&gt; Company Property User - name, gender, occupation, preferences Event - name, type, start/end_time, type_specific_information Construction Data Access Use open-source data or web-crawlers. Information Retrieval Used for processing unstructured / semi-structured data by extracting useful information via NLP methods, which includes: Sentence segmentation Tokenization Part Of Speech (POS) tagging Named Entity Recognition Relation Retrieval Knowledge Fusion Used for intergrate incoming data and existing knowldge graph. Knowledge retrieved may contain inaccurate or redundant information, Coreference Resolution (to solve ambiguity brought by pronouns) and Entity Disambiguation (combine aliases for one thing) could be used to improve the quality of knowledge map. Knowledge Process Used for discovering new relations. E.g. User Profile KG, users with identical properties may share similar preferences. The technology involed is called Knowledge Inference, which could be implemented using logic / graph algorithm / deep learning. Storage RDF (Resource Description Framework) Text format, easy modification, poor readability A glimpse of RDF file (from this repo): 123456789101112131415161718192021222324252627282930313233343536373839404142434445&lt;?xml version=&quot;1.0&quot;?&gt;&lt;rdf:RDF xmlns:rdf=&quot;http://www.w3.org/1999/02/22-rdf-syntax-ns#&quot; xmlns:owl=&quot;http://www.w3.org/2002/07/owl#&quot; xmlns:asset=&quot;http://www.daedafusion.com/Asset#&quot; xmlns:xsd=&quot;http://www.w3.org/2001/XMLSchema#&quot; xmlns:edt=&quot;http://www.daedafusion.com/editor_annotation#&quot; xmlns:rdfs=&quot;http://www.w3.org/2000/01/rdf-schema#&quot; xml:base=&quot;http://www.daedafusion.com/Asset&quot;&gt; &lt;owl:Ontology rdf:about=&quot;&quot;&gt; &lt;owl:imports rdf:resource=&quot;http://www.daedafusion.com/editor_annotation&quot;/&gt; &lt;rdfs:label xml:lang=&quot;en-US&quot;&gt;ARGOS Asset Ontology&lt;/rdfs:label&gt; &lt;rdfs:comment xml:lang=&quot;en-US&quot;&gt;Editor Annotation ontology defines a set of annotations that provide a graphical editor information about how to create corresponding IRI&#x27;s for new instances created along with information that is used to control how properties appear in the editor. Copyright (c) 2014, DaedaFusion, LLC. All rights reserved.&lt;/rdfs:comment&gt; &lt;owl:versionInfo rdf:datatype=&quot;http://www.w3.org/2001/XMLSchema#string&quot; &gt;1.0.0.0&lt;/owl:versionInfo&gt; &lt;/owl:Ontology&gt; &lt;owl:Class rdf:ID=&quot;Asset&quot;&gt; &lt;rdfs:subClassOf&gt; &lt;owl:Restriction&gt; &lt;owl:cardinality rdf:datatype=&quot;http://www.w3.org/2001/XMLSchema#nonNegativeInteger&quot; &gt;1&lt;/owl:cardinality&gt; &lt;owl:onProperty&gt; &lt;owl:DatatypeProperty rdf:ID=&quot;mimeType&quot;/&gt; &lt;/owl:onProperty&gt; &lt;/owl:Restriction&gt; &lt;/rdfs:subClassOf&gt; &lt;rdfs:comment xml:lang=&quot;en-US&quot;&gt;Characterizes a digital asset&lt;/rdfs:comment&gt; &lt;rdfs:label xml:lang=&quot;en-US&quot;&gt;Asset&lt;/rdfs:label&gt; &lt;rdfs:subClassOf rdf:resource=&quot;http://www.w3.org/2002/07/owl#Thing&quot;/&gt; &lt;edt:namespacePrefix rdf:datatype=&quot;http://www.w3.org/2001/XMLSchema#string&quot; &gt;argos&lt;/edt:namespacePrefix&gt; &lt;rdfs:isDefinedBy rdf:resource=&quot;&quot;/&gt; &lt;/owl:Class&gt; &lt;owl:ObjectProperty rdf:about=&quot;#locatorURI&quot;&gt; &lt;rdfs:comment xml:lang=&quot;en-US&quot;&gt;Specifies the location from where the asset was ingested&lt;/rdfs:comment&gt; &lt;edt:namespacePrefix rdf:datatype=&quot;http://www.w3.org/2001/XMLSchema#string&quot; &gt;argos&lt;/edt:namespacePrefix&gt; &lt;rdfs:label xml:lang=&quot;en-US&quot;&gt;Location URI&lt;/rdfs:label&gt; &lt;rdfs:domain r","categories":["Notes"],"tags":["Artificial Intelligence","Knowledge Graph"]},{"title":"Introduction to ZettleKasten - Your Personal Knowledge Management System","date":"2022-12-07","path":"2022/12/07/Introduction-to-ZettleKasten-Managing-your-note-and-knowledge/","excerpt":"In this post, I would provide a detailed introduction to ZettleKasten\nmethod, which I have been applying since I read the book How to take\nsmart notes.","content":"In this post, I would provide a detailed introduction to ZettleKasten method, which I have been applying since I read the book How to take smart notes. A quick overview - What is ZettleKasten? ZettleKasten is a note taking and personal knowledge management system, consists of basic component called 'Zettle'. Zettel is the German word for a small piece of paper or a note. It can also refer to a brief written summary or an outline of a topic. It is often used in the context of taking notes, making lists, or organizing ideas. Suggestions about how to write structure and content for a Zettle is included in the third section. This system, first adopted by the German sociologist and philosopher Luhmann, is centered on the idea of constructing a web of notes (also named Zettles) as a way to promote more flexible interdisciplinary thinking. This note-taking method is widely applied in different scenarios: academic research, writing, personal productivity improvement and creative work. Advantages of ZettleKasten Organizing notes in files + folders can lead to a rigid note structure that makes it difficult to keep track of the interrelationships between knowledge points. Organizing notes in tabbed form (tags) is less practical with limited content to see at one time. A better way to organize notes and thoughts -- use a mesh structure to organize (as emphasized in ZettleKasten), relying not only on tags, but also on links to different Zettles. More advantages are listed below: Better preservation and recall of information and knowledge with a unified structure. Access to information and links between different topics, enough to quickly find and use the knowledge and ideas contained in Zettle. Increase productivity and creativity by easily organizing and accessing their knowledge and ideas, enabling flexible, dynamic thinking. Can be integrated with other productivity tools, such as task management or time tracking software (Detail would be discussed in another post coming soon) Accumulating Zettles with similar structures could realize the Compound Interest effect for your personal knowledge. Features of ZettleKasten Zettle (card) is smallest unit of the system. These Zettle include small ideas, notes that can be easily created, organized, and linked. Each Zettle uses a unique identifier that can help with the organization and access of notes. Unique identifiers can use ID-like numbers + characters or be the keywords/summary of the note's topic based on your choice. Emphasis is placed on creating links between notes and creating a web-like structure. Review and update Zettle regularly to prevent ZettleKasten from progressing to linear structures guide the study/research to fill the gap/missing concept in your system spot links between different topics How to implement - principles and discussions Choice of Software There are a bunch of note taking apps which supports wiki-links or bi-directional links. Discussing the pros and cons of each of the listed software is beyond the scope of this post. If you are interested in a detailed comparison of these apps, please leave a comment. Typical Tools that are made for ZettleKasten: Roam Research Obsidian LogSeq Notion Zettlr Siyuan ... I personally recommend Obsidian, with its highly customizable plugins, rich forum and active community. If you prefer to work in a outline mode (like WorkFlowy), then LogSeq / Roam Research may serve you well. How to write Zettle? As the basic component of ZettleKasten system, it is crucial to follow a uniform format and some principles when keeping Zettles for later note connection. Principles Generally, A Zettle is a concept with a name that is as short and recognizable as possible.Take bricks as example, good zettle should play the same role as bricks when building your knowledge palace. The Zettles should be: Spliceable - single block, one thing/concept at a time To achieve this, a good way is to check if you could find a concise title to summarise your zettle. According to How to take smart notes, context is important when understanding a concept. It is therefore a good practice to include (either by text or links to relevant zettles) sufficient background information to explain this zettle‚Äôs concept. Reusable - complete block, contain sufficient information to understand the concept itself This is complementary to the former principle, where self-explainable Zettles allows you to create more complex system. In practice, achieving this is often linked with formatting your notes‚Äô meta data, containing the tags, creation, alias of your zettle. naming your notes with recallable and distinguishable keywords could also be helpful. Tractable - record the source of notes This means that you don't need to copy and paste the original content; if you forget anything, you can go back to the source of knowledge and review it. Different Types of Zettles To help organizing and accessing notes, together with later understanding and exploration of differe","categories":["Informal Essays"],"tags":["Methodology","Knowledge Management"]},{"title":"Literature Note - Transformer","date":"2022-11-10","path":"2022/11/10/Literature-Note-Transformer/","excerpt":"In this post, I would summarize key points from classic paper \nfollowing its initial structure.","content":"In this post, I would summarize key points from classic paper following its initial structure. Important Links Paper link Code link Acknowledgements Special thanks to Mu LI, who provides a wonderful review video on this article. Also thanks to Lilian, for this wonderful blog connecting transformer's principle &amp; applications. 0. Abstract Paper proposes a new simple network architecture, the Transformer, based solely on attention mechanisms State-of-the-art result on machine translation tasks Advantages of transformer architecture More parallelizable &amp; require significantly less training time Generalize well to other tasks - see BERT, GPT Writing tips When stating equal contribution using *, it's good practice to list briefly about each member's work done. 1. Introduction Basically an extension to abstract Recurrent neural networks /models' Principle Generate a sequence of hidden states \\(h_t\\), as a function of the previous hidden state \\(h_{t‚àí1}\\) and the input for position \\(t\\). RNN-calculation-example.png Drawbacks Parallelization preclusion by calculation method High memory requirements for preserving historical information. / Possibility in forgetting early information after step by step passing. Attention Mechanism An integral part of sequence &amp; transduction models. Allow the model to capture dependencies between in/out sequence regardless of their distance. Most of them used in conjunction with a recurrent network Transformer's innovation ‚Äúeschewing recurrence and instead relying entirely on an attention mechanism‚Äù 2. Background Introduces previous attempts to reduce sequential computation - using CNN (convolutional neural networks) ‚Äúdifficult to learn dependencies between distant positions‚Äù, between long sequences Why Multi-Head Attention (instead of single head)? Attention mechanism eschewed convolution mechanism, losing the opportunity to model different patterns. Using Multi-Head Attention mechanism is to simulate the multi-channel output of CNN. Previous success on self-attention End-to-end memory networks‚Äô scope and performance Innovation point about Transformer. 3. Model Architecture Follows most competitive sequence transduction models, Transformer uses an encoder-decoder structure, where Encoder maps input sequence to a vector-like representation for model usage. Decoder generates output sequence one element at a time. The model is auto-regressive, using output from previous moment as additional input. 3.1 Encoder &amp; Decoder Stacks Transformer-Architecture-from-Paper.png Encoder - Decoder, shown in the left and right halves respectively. Each layer of encoder consists of two sub-layers - a multi-head attention mechanism &amp; a MLP. The residual connection (inspired by ResNet) is used within sub-layers. The LayerNorm technique is also implemented. LayerNorm is a different normalization method from Batch Normalization and is more suitable with models taking variable-length inputs (temporal sequences), reducing the impact of different batch cuts (sequence length variations) on normalization. Generally speaking, the difference lies in the data slicing mechanism. BN slices the data according to the batch and regularizes the feature dimensions, while LN slices the data according to the input samples and regularizes different features of the same sample. In addition to encoder, decoder adds another layer, calculate the multi-head attention over the output of the encoder. A masking mechanism is used to prevent decoder uses output after position \\(i\\) to predict the position \\(i\\). 3.2 Attention Attention is a mechanism that model learns to make predictions by selectively attending to a given set of data.1 Self-attention is a type of attention mechanism where the model makes prediction for one part of a data sample using other parts of the observation about the same sample,... it is permutation-invariant; in other words, it is an operation on sets.1 In transformer's Encoder, Query, Key, Value are identical vectors generated by the embedding layer, therefore no trainable variables involved. ‚ÄúAn attention function can be described as mapping a query and a set of key-value pairs to an output. The output is computed as a weighted sum of the values, where the weight assigned to each value is computed by a compatibility function of the query with the corresponding key.‚Äù The amount of attention is quantified by learned weights and thus the output is usually in the form of weighted average over input (Query, Key, Value) pair. 3.2.1 Scaled Dot-Product Attention What's Dot-Product? Perform matrix multiplication on queries (Q) and keys (K) embeddings. Why Dot-Product? Faster &amp; space-efficient in practice Another alternative for attention functions are additive attention. What's Scale? After dot-product, divide the result by \\(\\sqrt{d_k}\\). Why scale? For long input sequence, apply softmax on the unscaled dot-product could result in Vanishing gradient. \\[ Attention(Q,K,V) = \\text{softmax}(\\fr","categories":["Notes"],"tags":["Artificial Intelligence","NLP","Classic Papers"]},{"title":"A brief history of NLP","date":"2022-11-08","path":"2022/11/08/A-brief-history-of-NLP/","excerpt":"In this piece of note, I will give an overview of NLP's development\nhistory, focusing on how recent neural approaches revolutionise the NLP\nfield.","content":"In this piece of note, I will give an overview of NLP's development history, focusing on how recent neural approaches revolutionise the NLP field. Natural language processing could be roughly devided into 3 stages based on the domainance methods used. 1 Symbolic NLP Statitical NLP Neural NLP Symbolic NLP (1950s - early 1990s) Research related to natural language processing originated roughly in the 1950s. In the following 40 years, limited by the size of the corpus and the computing power, early natural language processing mainly used rule-based methods to deal with generic natural language phenomena through symbolic logic knowledge summarized by experts. Such rule systems are difficult to be applied to solve real-world problems due to the complexity of natural language. Statistical NLP (1990s - 2010s) The rapid advances in computational power and storage capacity, as well as the increasing maturity of statistical learning approaches, have led to the large-scale application of corpus-based statistical learning methods in the field of natural language processing. The advantages of this method includes fast training speed, little requirement for labelled data and has good performance over simple problems. Meanwhile, there are obvious limitations to this method. Statistical approach requires transformation of the raw natural language input into a vector form that can be processed by the machine based on empirical rules. This expertise-dependent, manual process of transformation is known as feature engineering (feature extraction), which is time-consuming and not compatible for different tasks. Neural NLP (present) To cope with the disadvantages of feature engineering, representation learning and deep neural network-style machine leanring methods became widely applied in NLP field, proposing an end-to-end solution. Representation learning allows the machine to automatiacally recognise patterns from input which can be used for tasks like classifcation. In 2013, Tomas Mikolov proposed word2vec method2, using a shallow neural network with large scale corpus, which uses contextual connection of each word to embed the semantics of the tokens into a dense vector. This output of such method is called Word Embedding. This kinds of encoding methods avoid the usage of elaborate feature engineering, and it also breaks down the barriers between different tasks, as representation learning transformes input into a similar and easily tranferrable vector space. This trend of Representation Learning has spread to knowledge graphs (using Graph Embedding techniques) and recommender systems (using user/item Embedding techniques). Shortly after, the drawback of word2vec was discovered - the same word has different meanings in different contexts, but the word vector given by this encoding is unique and static. Accordingly, the model ELMo that introduces contextual Word Embedding was born. In 2017, the Transformer model was released3. Compared to ELMo-like models, the biggest breakthrough of Transformer is that it does not use LSTM, but instead uses an attention mechanism. This mechanism is a function that maps a query and a set of key-value pairs to an output. The values output by the attention mechanism are weighted sums, where the weight of each value is calculated by the function of the query and the corresponding key of the value. Some NLP researchers believe that the attention mechanism used by transformer is a better alternative to LSTM. They believe that the attention mechanism handles long-range dependencies better than LSTM and has a very promising application. transformer uses an encoder-decoder structure in its architecture. The encoder and decoder are highly similar in structure, but not in function. The encoder consists of N identical encoder layers. A decoder consists of N identical decoder layers. Both encoder and decoder layers use the attention mechanism as a core component. The great success of Transformer in the field of machine translation has attracted the interest of many NLP scientists. As deep learning algorithms evolves, their disadvantages begin to emerge - algorithm requires massive labelled data. As the subjective natrue of congnitive task of NLP, and the large number of tasks and domains it deals with, it is time-consuming and labor-intensive for acquiring high quality annotated corpora. The large scale pre-trained langauge model precisely compensate for this shortage, helping NLP to achieve a series of breakthroughs. On this regard, two famous models were born: Bidirectional Encoder Representations from Transformers (BERT)4 and Generative Pre-Traing of language model (GPT)5. GPT consists entirely of the decoder layer of the transformer, while BERT consists entirely of the encoder layer of the transformer. The goal of GPT is to generate human-like text, the goal of BERT, on the other hand, is to provide better language representations that help achieve better results for a wide range of downstream tasks.","categories":["Notes"],"tags":["Artificial Intelligence","NLP"]},{"title":"Literature Note - BERT","date":"2022-09-15","path":"2022/09/15/Literature Note - BERT/","excerpt":"In this post, I would summarize key points from classic paper &lt;BERT: Pre-training of Deep\nBidirectional Transformers for Language Understanding&gt; following\nits initial structure.","content":"In this post, I would summarize key points from classic paper &lt;BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding&gt; following its initial structure. Important Links Paper Official Code 0. Abstract Related work: GPT (Radford et al.) &amp; ELMo (Peters et al.) Fun fact: ELMo &amp; BERT are both character name from Sesame Street Difference between these two: GPT - use left context for predicting future inputs &lt;-&gt; BERT - use both context ELMo - RNN architecture, need architecture modification &lt;-&gt; BERT - Transformer Architecture, no task-specific architecture modifications needed for downstream tasks. Advantages: Conceptually simple Empirically powerful (on specific tasks) Writing tips: State both absolute and relative performance for reader understanding. 1. Introduction Pre-training language model in NLP area (BERT reused pre-training technique from CV area, advocating later research to follow) Extension to Abstract para 1. Existing strategies for applying pre-trained language representations Feature-based - ELMo Fine-tuning - GPT Limitation on related work Unidirectional language models restrict pre-trained representations. GPT‚Äôs left-to-right architecture, ‚Äúevery token can only at- tend to previous tokens in the self-attention layers of the Transformer‚Äù BERT‚Äôs improvement: using bi-directional context &amp; ‚Äúmasked language model‚Äù Contributions: Importance of bidirectional pre-training Reducing task-specific architecture modification need Open-source Repo 2. Related Work 2.1 Unsupervised Feature-based approach ELMo &amp; others. 2.2 Unsupervised Fine-tuning Approaches GPT &amp; others. 2.3 Transfer Learning from Supervised Data 3. BERT (Implementation) Two steps in BERT‚Äôs framework: pre-training and fine-tuning. Writing tips: Include a brief introduction of supplementary techniques used. (E.g. pre-training &amp; fine-tuning here) 3.0.1 Model architecture Multi-layer bidirectional Transformer encoder based on Vaswani et al.(2017) ‚Äòs original implementation in this repo. Guide could be found in this article. \\(BERT_{BASE} \\Rightarrow L=12,H=768,A=12,Total\\ parameters=110M\\) This model is designed to have the same model size as GPT on comparison purposes. \\(BERT_{LARGE} \\Rightarrow L=24,H=1024,A=16,Total\\ parameters=340M\\) where, \\(L\\) - number of Transformer blocks \\(H\\) - Hidden size \\(A\\) - number of self-attention heads In literature, bidirectional transformer is often referred to as a ‚ÄúTransformer encoder‚Äù 3.0.2 Input/Output Representations Context To cope with different down-stream tasks, input representation needs to unambiguously represent both a single sentence and a pari of sentences in one token sequence. Important definitions Sentence - arbitrary span of contiguous text, rather than an actual linguistic sentence. Sequence - input token to BERT. Implementation WordPiece embeddings (Wu et al., 2016.) WordPiece embeddings cut word into smaller sub-sequence for low frequency words to reduce the size of token vocabulary. Rules: First token of every sequence = [CLS] - Used for classification tasks Packing sentences Separate using [SEP] (simple mark) Use a learned embedding - summing the token, segement and position embeddings. BERT-paper-Figure2-BERT-input-representation 3.1 Pre-training BERT BERT‚Äôs pre-training uses two unsupervised tasks Masked Language Model (MLM) Next Sentence Prediction (NSP) 3.1.1 Task I: Masked LM Intuition: Bring in contextual information (as ELMo suggests) Task description Mask some percentage of the input tokens at random, and then predict those masked tokens. Task details Mask 15% of all WordPiece tokens in each sequence at random. To mitigate the mismatch (fine-tuning‚Äôs input has no [MASK] token) between pre-training &amp; fine-tuning, masked words are replaced in differently. If the i-th token is chosen, it is replaced with [MASK] token - 80% of the time a random token - 10% of the time (to add noise into the training data) the unchanged token - 10% of the time Online demo for this task Check out huggingface‚Äôs online impelmentation of BERT base model. Task idea origin Cloze task by Taylor. 3.1.2 Task II: Next Sentence Prediction (NSP) Intuition: capture sentence relationships for tasks like Question Answering &amp; Natural Language Inference Task description Input two sentences A &amp; B, output a binary label indicates whether B is the next sentence follows A. Details Training data construction - 50-50 split of positive &amp; negative samples. 3.1.3 Data source For the pre-training corpus we use the BooksCorpus (800M words) (Zhu et al., 2015) and English Wikipedia (2,500M words). For Wikipedia we extract only the text passages and ignore lists, tables, and headers. 3.2 Fine-tuning BERT Fine-tuning BERT is the process of reorganize the input sentence into sequence to model different downstream tasks. For each task, plug in the task-specific inputs and outpus is needed and BERT is finetuned end-to-end. BERT‚Äôs fine-tuning is inexpe","categories":["Notes"],"tags":["Artificial Intelligence","NLP","Classic Papers"]},{"title":"Embrace the Information Era","date":"2022-03-13","path":"2022/03/13/Embrace the Information Era/","excerpt":"Though it may sound strange, I wanted to record some of my\nrealizations regarding how to deal with the massive incoming information\nand how to gain &amp; use information effectively.","content":"Though it may sound strange, I wanted to record some of my realizations regarding how to deal with the massive incoming information and how to gain &amp; use information effectively. When I talk about Information Era, I am NOT referring to the time when information technology explodes, but after that, when we are overwhelmed by massive information generated by various medias or even AI. According to relevant study, modern citizens percieve one million times more information than citizens back in 1000 A.D. The development of all medium and the widespread of personal computer contributes to the astonishing increase of information available. Therefore, I would like to focus on this aspect and demonstrate my understanding and methodology. Understanding of Information era What is information? Information is from which data and knowledge can be derived, as data represents values attributed to parameters, and knowledge represents understanding of real things or abstract concepts. In personal management perspective, a lot of topics is in essence information management. For task / project management, task is a piece of information with its description, due dates and other meta data; project is a group of files/materials and tasks. For knowledge management, it is concered with keeping your ideas, formal essays and literatures. Characteristic of information Information is infinite, quickly-updated Compare to the limited time and effort each individual possess, the massive information generated each day and accumulated in the past seems infinite. Different information may be contradicting Due to different perspective and former knowledge, ones could have different views on the same thing. For example, in stock market, it is common that a lot of reviewers have contradicting views on whether the market is bearish or bullish. The capture &amp; storage of information takes time and effort According to its definition, understanding and extracting the useful piece of information need human‚Äôs time and effort. Besides, the form of information varies, such as videos, articles, audios, etc. Handling different forms of information also requires individual‚Äôs time and effort. Challenge in this era With the characteristic of information above, this new era proposes new challenges. In the past ,people suffer from scarcity of information, the challenge is how to obtain information. To cope with this situation, reading books become a widly applied approach for perceiving information. On the contray, nowadays we suffer from redundant information source, while some may even be contradicting. The challenge now becomes how to quickly find the information needed, how to perform critical thinking against different viewpoints and make a sound decision in limited time and how to organize digital information. Methodology in this era Regarding to the characteristic of information and the new challenge proposed, I have formed the below methodology. Be selective and make decision with sufficient information As the information is infinite, we need to be astute when capturing information. This involves finding relevant information quickly (using search engine) and selecting those important ones that is most suitable for current situation. Another key advice for this is to capture the first-hand information. This means one should try to be closer to information source or trusted publisher. When reading news, check multiple authorities's statement; when learning a new programming package, check the official documentation first. Being close to these information source is beneficial, for second-hand or third-hand information may lose details or involve noise. The thought of coming with a ‚Äòperfect‚Äô plan should be abandoned. Since the available information is infinite, you could always use other source to further improve your plan. The best way to do this would be quickly draft a plan, start implementing it and continue with iterative perfections based on the feedback from your practice. Develop critical thinking and make independent judgments Due to the possible conflicting views from different information source, you need to develop the ability of critical thinking. You should evaluate views from different sides, find their statement, reasonings and evidence, and then based on your experience and knowledge to make a informed decision. Form your own workflow for the capture, organization and induction of information This is related the topic called PIM (Personal Information Management), which has a range of sub-topics like task management and knowledge management. Based on your purpose, you could find more detailed information in relevant fields. Capture info: Search Engine Techniques People seldom exploit the maximum usage of search engine. You could customize your search via simple formatting of your query, which significantly increase the relevance of the information you find. Search for key phrases ‚Äú‚Äù Wrap up your phrase with ‚Äú‚Äù to search the entire ","categories":["Informal Essays"],"tags":["Methodology","PIM"]},{"title":"Introduction to Cryptography","date":"2022-02-17","path":"2022/02/17/Introduction-to-Crypotography/","excerpt":"In this piece of note, I will give an overview of Crypotography,\nintroduce basic principles and algorithms for symmetric cryptography,\nassymetric cryptography and Protocols.","content":"In this piece of note, I will give an overview of Crypotography, introduce basic principles and algorithms for symmetric cryptography, assymetric cryptography and Protocols. Structure of Cryptography Structure of Cryptography Symmetric Cryptography Same key for encryption and decryption Ensures confidentiality Implemented via block ciphers or stream ciphers Lightweight and fast Used for general communication Stream Ciphers Implementation Initial seed key to generate an infinite keystream of random bits Using same keystream to encrypt two messages -&gt; easy to break A random ‚Äúnumber used once‚Äù ( nonce ) added as additional seed -&gt; ensure keystream is new Message &amp; keystream combined using XOR to get the cipher text XOR is reversible is applied twice, which brings much convenience when decrypt cipher text. Advantages Encrypting long continuous streams, possibly of unknown length Extremely fast with a low memory footprint, ideal for low-power devices If designed well, can seek to any location in the stream Disadvantages The keystream must appear statistically random You must *never* reuse a key + nonce Stream ciphers do not protect the ciphertext Therefore, message could be manipulated during transition without breaking confidentiality E.g., suppose you are transmitting a message to bank saying A owes you $50. Attacker could either manipulate the amount or the creditor using the same stream ciper or resent the same message to server. Block Cipers Implementation Use a key to encrypt a fixed-size block of plaintext into a fixed-size block of ciphertext Changing and permuting the bits of the block depending on the key Different lengths of messages can be handled by splitting the message up and padding Example - SP-Networks Wiki Repeated substitution and permutation SP-Network Example Key mixing for enhancing security -&gt; Different key for different round Decipher = Reverse operation Symmetric Algorithms Algorithm Cipher Type Design Block Size (bits) Speed Memory Footprint Safe Implementation Difficulty Key Sizes (bits) DES Block Feistel 64 Fast Low Easy 56 3DES Block Feistel 64 Slow Low Easy 112 AES Block SP-Network 128 Very fast Low-Medium Hard 128/192/256 ChaCha20 Stream add-xor-rot N/A Very fast Very low Easy 256 Asymmetric Cryptography Use a pair of keys, one public and one private Public-key cryptography General Idea Hinges upon the premise that: It is computationally infeasible to calculate a private from a public key In practice, it is achieved through intractable mathematical problem Key exchange Diffie-Hellman Key exchange allows two parties to mathematically agree a shared secret over an insecure channel Alice and Bob each uses a public non-reversible Generator with their private keys to generate public key and send it to each other. Using other‚Äôs public key and self‚Äôs private key, shared secret could be established. Asymmetric-Cryptography-key-exchange Public Key Encryption Encryption performed by the public key can only be reversed using the private key Digital Signatures The authenticity of signatures generated by the private key can by verified by the public key Steps Server send the original message Server use private key to encrypt Server send the encrypted message User verify using public key Public Key Algorithms Algorithm Key Exchange Encryption Digital Signatures Mathematical Problem Elliptic Curves? Typical key Size (bits) Diffie-Hellman ‚úì Discrete Logs ‚úì 256 RSA ‚úì ‚úì Integer Factorisation 2048/4096 Elgamal ‚úì ‚úì Discrete Logs ‚úì 2048 DSA ‚úì Discrete Logs ‚úì 256 Protocols Application of cryptographic algorithms in secure systems Hash Functions Cryptographic primitive Takes a message of any length, and returns a pseudorandom hash of fixed length Strong hash functions must appear random be hard to find collisions ‚Äì two messages that hash to the same thing strong hash funciton example ### Hash Function usage Message Authentication Codes Provide integrity and authenticity, not confidentiality Protecting system files Ensuring messages haven‚Äôt been altered Calculate a keyed hash of the message, then append to the end of the message hash funciton in message authentication Digital Signatures The use of a hash during the signing process shortens the signature More efficient for long messages Password storage Passwords stored hashed to prevent disclosure","categories":["Notes"],"tags":["Cryptography"]},{"title":"Thinking about Time management","date":"2022-02-16","path":"2022/02/16/Thinking-about-time-management/","excerpt":"In this article, I will talk about my understanding and\nimplementation of time management measures. Moreover, I would introduce\nsome popular concepts of this topic, like GTD, Pomodoros,The Eisenhower\nMethod.","content":"In this article, I will talk about my understanding and implementation of time management measures. Moreover, I would introduce some popular concepts of this topic, like GTD, Pomodoros,The Eisenhower Method. Understanding of Time management What it is? What‚Äôs its importance? Time management is the process of carefully planning time individuals spent on various activities. The aim of the time management is to increase efficiency and productivity. For a simple example, suppose you need to prepare dinner for your family, you need to complete a set of tasks like shopping for groceries, preparing ingridients, cooking, etc. Time management skills tend to help you reduce the overall time spent on all this tasks by arranging them consciously. In computer science, the design of operating system provides an abstraction on this topic via CPU scheduling. The priorities of tasks resembles the real life situation where some tasks is more urgent than others. The overhead of context switch (switching between tasks) is a vivid abstraction of human changing focus. For a difficult task (takes more time), it was split into more time slices to complete. Popular Concepts The Eisenhower Method It is a method that utilizes the criteria of importance and urgency to organize priorities and workload. Based on the two criteria, tasks could be categorized into four categories (as in following graph) The Eisenhower Matrix Important &amp; Urgent tasks - should be done immediately and in person. Important &amp; Not Urgent tasks - should be done at certain dates and in person. Unimportant &amp; Urgent tasks - could be delegated. Unimportant &amp; Not Urgent tasks - should be dropped. In practice, it is not frequently listed but used as a mental model to decide the task‚Äôs properties. Pomodoros This method was originally from Francesco Cirillo's Pomodoro Technique. It took the name from a Pomodoro - tomato shaped kitchen timer. The ‚ÄúPomodoro‚Äù is defined as the fundamental unit of time to measure tasks‚Äô expected completion time, which is traditionally defined as being 30 minutes long, consisting of 25 minutes of work and 5 minutes of break time. Though it may seems stiff to use strict pomodoros, it could actually develop your sense of time and help you record your performance. With continuous using of this technique, you could be more confident in predicting tasks‚Äô completion time. Recoding how many Pomodoros you finished could also be a straight forward metric of evaluating your performance. GTD This strategy was created by David Allen in his book Getting Things Done. The basic idea of this strategy is to capture all unfinished things (projects or tasks), clarify them into small actionable tasks with clear goals, organize them in appropriate forms (and come up to you at proper time), review tasks frequently to update the status and engage in these tasks. In general, it provides a complete workflow for you to manage all your tasks and projects in a personalized system. Though this system may be hard to build and maintain, from my own experience, it is worthwhile to keep you confident in action decisions. My implementation of time management To start with your time mangement, you frist need to be aware of where you spent your time. I used aTimeLogger to track my everyday activities. This is the start of my time management practice and could provide a clear view of whether you are hard working or playing too much. You could also pick your own time tracking app, just pay attention to the philosophy of the software to make sure they are NOT interruptive of your current activities and time-consuming when recording. To plan your time carefully and wisely, I used GTD techniques to track all the tasks I need to finish and all the events I need to participate. Following GTD‚Äôs principles, I would tag the tasks with its expected context (when would be proper, what tools needed, etc.) and group them with the assoicated project. I have tried plenty of task management apps like Omnifocus (which I am now using), Things 3, TickTick (Used for a long time), Wunderlist, etc. It is hard to give a general suggestion for the choice as different people may have different requirements, just make sure the app you choose helps record your tasks easily, intergrate nicely with your workflow and remind you in appropriate format. One more thing to care about, is DO NOT overmanaging. I had once fallen into the pitfall of overmanaging myself. I enjoyed listing and categorizing different tasks and projects, trying different apps, perfecting the tag system but just NOT complete many of those tasks. Remember what the name suggest, getting things done, so focus on completing the tasks rather than putting most of your efforts changing their organization. In the new information era, another thing has become more valuable than our time, that is, our attention (or effective time). The power of attention has long been discovered by physicist through Double-slit experiment, in which ","categories":["Informal Essays"],"tags":["Methodology","Time Management"]},{"title":"Thinking about writing","date":"2022-02-09","path":"2022/02/09/Thinking-about-writing/","excerpt":"In this article, I will rethink the importance of writing, and\ndiscuss how the tools I used evolved.","content":"In this article, I will rethink the importance of writing, and discuss how the tools I used evolved. Motivation In information era, the way we express ourselves matters. Different thinking pattern could be reflected from the writing. Among applications, we could use the most efficient way to express and organize our ideas. The importance of writing Writing, in its board aspect, is an everyday activity for all of us. However, according to my friends, little of us have ever thought carefully about this activity. Different format we use could help us train different thinking patterns. Different applications we chose could effect the efficiency of expressing ourselves and organizing ideas. It is also an important way for us to exchange serious opinions in a decent manner (like publications). Different format could be applied to writing. Within my knowledge, they are plain text (.txt, .word files), hypertext (.html, .md files) and outline (.opml files). Each format has an implication of different thinking pattern. For example, if you use outlining more often than other format, you are tend to be a person with a good sense of the overall picture.If you use hypertext (e.g. markdown) very often, you tend to care about the content more than the format it is presented. In S√∂nke Ahrens‚Äôs book , he emphasis the importance of writing: An idea kept private is as good as one you never had. And a fact no one can reproduce is no fact at all. Making something public always means to write it down so it can be read. There is no such thing as a history of unwritten ideas. My experience in writing During my early life, I used Microsoft Word as my main editing tool as this is the only one I am familiar with. The software works fine, however, as I grow older, I tend to realize that I spend a lot of time editing the format for different headings and emphasis. With my exploartion in computer science, I started to use markdown as the main form of many writings. Markdown is a kind of mark up language, which uses a small set of symbols to realize the formatting. This freed me from doing manual adjustment for different parts of the text and could now focus more on the content. Markdown is also a portable format. The formatting is realized by limited symbols which allows the raw text to be readable.In my university, I have been using markdown to take notes, write reports and draft my dissertation. Though markdown itself is a powerful concept, the editor could be of great add on to this kind of writing. I have tried a lot of different markdown editors and now kept mainly two of them (Typora and Obsidian), I will write more about the reasoning of choices I made in a later post. As my writing in markdown format increases, I started to realize one drawback for this format. It is more of a connstraint in its methodology rather than software design. Markdown kinds of suggest a fragmented thinking, where each piece of markdown note stands for a concept or event solely. Though markdown provides link feature, it is not good for getting the whole picture (say you are taking notes for a course and want to have an overview before exam). This let me to another kind of writing - outlining. Compared to putting emphasis on the details, outline writing put an emphasis on the key points or the main topic. It encourages concise language choices which is helpful for letting you know the bigger picture and the key points. Using the outlining tools together with my markdown notes, I could both get an general understanding and have detailed information when refering to my notes. Later when I came accross the PKM concept, I began to use Obsidian to manage my markdown notes, which could provide two-way linking between different files. How I implemented my own PKM system using Obsidian could be found in another post.","categories":["Informal Essays"],"tags":["Methodology","Writing"]},{"title":"How to set up a hexo blog?","date":"2021-11-28","path":"2021/11/28/How-to-set-up-a-hexo-blog/","excerpt":"In this article, you will find how to set up a hexo blog and deploy\nit.","content":"In this article, you will find how to set up a hexo blog and deploy it. Special thanks to Codesheep's video 0. Pre-requisite The most important of all, don't be afraid of making mistakes! To initiate your blog, you will need the libraries below. 0.1 Node.js Download here - suggest LTS version To check whether Node.js was downloaded successfully, type node -v in the terminal window. If something like v12.18.2 is presented with no error message, you are free to go for the next step. For Windows users, terminal could be invoked by pressing win + R, and then type cmd in the prompt window. 0.2 npm npm is the default package management tool for Node.js. For Chinese users, you could switch to the mirror in cnpm for faster downloads. Run the command to install cnpm: 1$ npm install -g cnpm --registry=https://registry.npm.taobao.org Similar to Node.js, type npm -v to check if it's installed successfully. 0.3 Git git is a version control tool used widely among programming projects. Generally speaking, it could help you keep different versions of your project. Download here To configure the git globally, you could run the command after installation. In the command, --global would set the following parameters for all git repositories on your computer. 12$ git config --global user.name &quot;Your Name&quot;$ git config --global user.email &quot;email@example.com&quot; 0.4 hexo With the package management tool installed, fetch the hexo package using command: 1$ npm install -g hexo or: 1$ cnpm install -g hexo Similar to Node.js, type hexo -v to check if it's installed successfully. 1. Initiate blog Create a folder 1$ mkdir blog By default, this blog/ folder will be created in /Users/YourUserName/ for both Mac and Windows users. Navigate into the folder 1$ cd blog To check if you are in the right folder, type pwd to check. Initiate your blog Make sure you are in the right folder before running command below! 1$ sudo hexo init The sudo parameter refers to admin access. Run your blog! 1$ hexo s By default, you will see the blog running at http://localhost:4000 2. Create a new article As indicated in the default blog file helloworld.md, you could use the command below to create a new blog. 1$ hexo n &quot;Your artical title&quot; By default, it will be created in source/_posts folder. For markdown reference, please check here. After writing, use the following command to clean the database and generate static files for local blog. 123$ hexo clean$ hexo generate$ hexo server Vist the default link again, you could see the article you just wrote. 3. Deploy your blog You will need a Github account or Gitee accound for deployment. Github Create a new repository with the name YourFullUserName.github.io and it has to be set to public. Install a plugin for deployment. 1$ npm install --save hexo-deployer-git Find the _config.yml file in your blog folder, at the end of this file, modify the following content: 123456# Deployment## Docs: https://hexo.io/docs/deployment.htmldeploy: type: git repo: Your Github repo&#x27;s link branch: master Your repo link should end with .github.io.git which you could obtain here. Where to find your link After saving your config file, run command below to deploy your blog. 1$ hexo d You may need to type your user name and password. See you blog online! Visit yourUserName.github.io References Codesheep's video in Chinese","categories":["Tutorial"],"tags":["blog","translation"]},{"title":"Index System Introduction","date":"2021-09-27","path":"2021/09/27/Index System Introduction/","excerpt":"In this article, you will find an brief definition of Index system,\nhow is it useful and how to build one on your own.","content":"In this article, you will find an brief definition of Index system, how is it useful and how to build one on your own. Further to my internship experience and my reading on the web, I have concluded some information about index system. 1. What is Index System? For example, when deciding whether a company is worth investing, you would see comments like \"This company has too much loans\", \"It is not making any profits\". However in data-driven industries (like finance), you need to support your decisions with intuitive evidence. Instead of raw business data, an index should be used for demonstration purposes (e.g. Asset-liability ratio).In the above example, the index of asset-liability ration addresses the company's debt. In real world problem, complicate problem could not be resolved by using one single index (e.g. Evaluating a company's future profitability), therefore a set of indexes is needed to describe the data subject from different perspectives and lead to a informed decision, that is where index system plays a role. 2. How is index system useful? When evaluating one's health condition, we tend to use the indicators like body fat percentage, body temperature, blood pressure, etc. Considering these indicators together, one's health status could then be determined. It's the same when using index system to evaluate a company. When something goes wrong, the index system should be able to reflect this abnormality. Tracing down the problematic index that goes wrong, the current problem in business should be clear. And then the relevant department could have the right direction to improve on. In summary, the index system should achieve the following: 1. Monitor business situation 2. Find problems based on problematic index 3. Evaluate business and guide the future work. 3. How to build an index system? The general approach is as following: 1. Understand company's / department's Key Performance Indicator (KPI), define Level-1 Index 2. Understand the business, dismantle Level-1 Index and define Level-2 Index 3. Sort out business processes, dismantle Level-2 Index and define Level-3 Index 4. Using reports to monitor index system, update it accordingly 4. Common mistakes when building index system Not understand the KPI No logic relationship between indexes Dissembled indexes has no business meaning Little or No communication between data department and business department Reference Zhihu's passage - How to build an index system by Houzi","categories":["Notes"],"tags":["Data Science","translation","Finance"]},{"title":"Binary search algorithm","date":"2021-09-11","path":"2021/09/11/Binary search algorithm Summary/","excerpt":"In this post, I will give a brief summary of binary search algorithm,\ntogether with some programming problems on this topic.","content":"In this post, I will give a brief summary of binary search algorithm, together with some programming problems on this topic. Algorithm Introduction It is a simple recursive searching algorithm. Scope of application: in ordered arrays The pseudo code1 is as follows: 123456789101112131415161718Procedure binary_search A ‚Üê sorted array n ‚Üê size of array x ‚Üê value to be searched Set lowerBound = 1 Set upperBound = n while x not found if upperBound &lt; lowerBound EXIT: x does not exists. set midPoint = lowerBound + ( upperBound - lowerBound ) / 2 if A[midPoint] &lt; x set lowerBound = midPoint + 1 if A[midPoint] &gt; x set upperBound = midPoint - 1 if A[midPoint] = x EXIT: x found at location midPoint end while In plain words, it recursively check whether the mid point value is the target, if the target is bigger, check the left half; if the target is smaller, check the right half. Complexity Space complexity Only constant number of variables are used, therefore the space complexity is \\(O(1)\\). Time complexity Because each time after search, half of the array would be 'discarded', therefore the overall complexity is \\(O(\\log n)\\), where \\(n\\) is the length of the array. Java Implementation example 123456789101112131415161718// Java - Non-recursive versionclass Solution&#123; public int binarySearch(int[] nums, int target) &#123; int n = nums.length; int left = 0, right = n - 1; while (left &lt;= right) &#123; int mid = left + (right - left) / 2; // Prevent add overflow if (nums[mid] == target) return mid; if (nums[mid] &lt; target) &#123; left = mid + 1; &#125; else &#123; right = mid - 1; &#125; &#125; return -1; &#125;&#125; 12345678910111213// Java - Revursive versionclass Solution&#123; public int binarySearch(int[] nums, int start, int end, int target) &#123; if (start &gt; end) return -1; int mid = start + (end - start)/2; // Prevent add overflow if (arr[mid] &gt; target) return binarySearch(arr, start, mid - 1, target); if (arr[mid] &lt; target) return binarySearch(arr, mid + 1, end, target); return mid; &#125;&#125; Questions Leetcode 704 - Binary search - Basic implementation for this algorithm. Leetcode 278 - First bad Version - Variation on look-up standards. Leetcode 34 - Find First and Last Position of element in Sorted array - Variation on look-up standards and re-use of code. Leetcode 33 - Search in rotated sorted array- Variation on the structure of array. Leetcode 74 - Search a 2D matrix - Variation on the structure of input array, need to reduce the dimension of input. Leetcode 162 - Find peak element - Another realization of binary search algorithm. The pseudo code is derived from tutorials point ‚Ü©Ô∏é","categories":["Notes"],"tags":["Algorithm","Computer Science"]},{"title":"Intention of this blog","date":"2021-08-18","path":"2021/08/18/Intention-of-this-blog/","excerpt":"Aims Record feelings and findings during CS study. Share my project experience with reproduceble steps. Publish notes about courses and libraies. Why this blog is named connecting dots? In childhood, ","content":"Aims Record feelings and findings during CS study. Share my project experience with reproduceble steps. Publish notes about courses and libraies. Why this blog is named connecting dots? In childhood, I was fond of the game Connect the dots. It seems magic to me that drawing lines between numbered dots gradually reveals the actual shape hidden behind. Sometimes it's tough to predict what you will arrive at simply by looking at the outline of the unconnected dots and therefore finishing the game always brings me surprise and excitement. As I grew older, I thought about the ultimate philosophical questions: Who am I? Where am I heading? Reading lots of biographies did not offer me a satisfactory answer, as I found that most of the time, people aren't quite sure where they will be taken to by their actions. It struck me one day that life is just like the game I enjoyed in my childhood. Finishing school, completing projects, and entering a relationship are all actions that create a 'dot' on the canvas of our life. It is not until some point in life when we look back, that we see a clear picture of our past by connecting the 'dots' we created. Therefore, I named my blog after my favourite childhood game to record the dots I made in my life and remind me to constantly review where these dots may take me.","categories":[],"tags":[]},{"title":"Basic Blog Operations","date":"2021-08-17","path":"2021/08/17/hello-world/","excerpt":"Welcome to Hexo! This is your very\nfirst post. Check documentation for\nmore info. If you get any problems when using Hexo, you can find the\nanswer in troubleshooting or\nyou can ask me on GitHub.","content":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick Start Create a new post 1$ hexo new &quot;My New Post&quot; More info: Writing Run server 1$ hexo server More info: Server Generate static files 1$ hexo generate More info: Generating Deploy to remote sites 1$ hexo deploy More info: Deployment","categories":[],"tags":["blog"]},{"title":"Operating System Lecture Notes - Introduction","date":"2020-10-04","path":"2020/10/04/OSC Lecture Notes - Introduction/","excerpt":"In this note, you could find the basic definition of Operating\nSystems and the general architecture of computer.","content":"In this note, you could find the basic definition of Operating Systems and the general architecture of computer. Defining Operating Systems What can an OS do for me? File systems: where is the file physically written on the disk and how is it retrieved? Abstraction: why looks the instruction the same independent of the device? Concurrency: what if multiple programs access the same file simultaneously? What if an other process starts running? Security: why is the access denied? Where in memory will the array be stored and how is it protected from unauthorised access? What if the array requires more memory than physically available? What if only part of the array is currently in use ? What is part of the operating system? Memory management, CPU scheduling, file system, communication, memory management, interrupt handling, GUI, . . . A resource manager Many modern operating systems use multi-programming to improve user experience and maximize resource utilization Disks are slow: without multi-programming, CPU time is wasted while waiting for I/O requests Imagine a CPU running at 3.2 GHz (approx. 3:2 \\(\\times\\) 109 instructions per second) Imagine a disk rotating at 7200 RPM, taking 4.2 ms to rotate half a track I/O is slow, we are missing out on 3.2 \\(\\times\\) 4.2 \\(\\times\\) \\(10^6\\) instructions (13.44m)! The implementation of multi-programming has important consequences for operating system design The operating system must allocate/share resources (including CPU, memory, I/O devices) fairly and safely between competing processes: In time, e.g. CPUs and printers In space, e.g., memory and disks The execution of multiple programs (processes) needs to be interleaved with one another: This requires context switches and process scheduling ) \\(\\Rightarrow\\) mutual exclusion, deadlock avoidance, protection, . . Origin In the early days, programmers had to deal directly with the hardware Real computer hardware is ugly Hardware is extremely difficult to manipulate/program An operating system is a layer of indirection on top of the hardware: It provide abstractions for application programs (e.g., file systems) It provides a cleaner and easier interface to the hardware and hides the complexity of ‚Äúbare metal‚Äù It allows the programmer to be lazy by using common routines :-) Why study operating system? The programs that we write use operating system functionality How are the operating system‚Äôs services/abstractions implemented Computer Architecture Simplified computer model (Tanenbaum, 2014) CPU design CPU‚Äôs basic cycle consist of fetch, decode, and execute (pipelines, or superscalar) Every CPU has his own instruction set A CPU has a set of registers (extremely fast memory close to the CPU ‚Äúcore‚Äù) Registers are used to store data and for special functions (e.g. program counter, program status word ‚Äì mode bit) The compiler/programmer decides what to keep in the registers Context switching must save and restore the CPU‚Äôs internal state, including its registers image-20201004100845955 Memory management Unit There are two different address spaces: the logical address space seen by the process and used by the compiler the physical address space seen by the hardware/OS When compiling code, memory addresses must be assigned to variables and instructions, the compiler does not know what memory addresses will be available in physical memory It will just assume that the code will start running at address 0 when generating the machine code On some rare occasions, the process may run at physical address 0 physical address = logical address + 0 On other occasions, it will be running at a completely different location in physical memory and an offset is added physical address = logical address + offset The memory management unit(MMU) is responsible for address translation (‚Äúadding the offset‚Äù) Different processes require different address translation (offsets) Context switching requires the MMU to be updated (and registers, cache, ...) Example 1234567891011#include &lt;stdio.h&gt;int iVar = 0;void main() &#123; int i = 0; while(i &lt; 10) &#123; iVar++; sleep(2); printf(&quot;Address:%u; Value:%d\\n&quot;,&amp;iVar, iVar); i++; &#125;&#125; The same addresses will be displayed for iVar. The address printed on the screen is the logical address The value for iVar in the first run doesn‚Äôt influence the second run‚Äôs value Moore‚Äôs Law ‚ÄúThe number of transistors on an integrated circuit (chip) doubles roughly every two years‚Äù Closely linked, but not necessarily related to performance Moore‚Äôs still continuing, but the ‚Äúpower wall‚Äù slows performance improvements of single core/single processor systems A few cores for multiple ‚Äúprograms‚Äù is easy to justify How to use massively parallel computers/CPUs/many core machines Can we extract parallelism automatically, can we implement parallelism at the lowest level (similar to multiprogramming) Lead to multi-core / parallel development Multi-core, hyperthreaded processors Modern CPUs contain multiple ","categories":["Notes"],"tags":["Computer Science","Operating System"]}]